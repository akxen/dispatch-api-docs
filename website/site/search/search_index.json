{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dispatch API Documentation The Dispatch API allows users to interact with a mathematical program that approximates Australia's National Electricity Market Dispatch Engine (NEMDE). The model is formulated as a single period economic dispatch problem that seeks to dispatch generators and loads such that demand is met at the lowest cost while respecting unit, network, and system constraints. The API can be used to investigate relationships between system parameters and dispatch outcomes, with possible applications including ex-post scenario and sensitivity analyses, or the tool's integration within forecasting frameworks. Features and known limitations The model used to approximate the NEMDE includes the following components: generator and load bids (FCAS and energy market); market network service provider (MNSP) bids; interconnector loss models with SOS2 constraints; Basslink loss model; generic constraints; FCAS constraints; two pass solution algorithm and inflexibility profiles for fast-start units; tie-breaking model for price-tied energy offers. The model validation section describes the data-driven approach used to assess the Dispatch API's ability to emulate NEMDE outputs. Excellent correspondence is observed between solutions reported by the Dispatch API and those reported by the NEMDE. However, users should note the Dispatch API is subject to some important limitations: FCAS prices are not reported; generic constraint right-hand side (RHS) values are obtained from historical NEMDE solutions rather than computed from SCADA values; intervention pricing runs are not supported; prices are not adjusted to the market price floor or cap if these thresholds are exceeded; constraint relaxation algorithms are not implemented. The above list represents known material limitations associated with the model. Work is underway to address each of these points, with updates likely to be incorporated within future versions of the Dispatch API. How it works The Dispatch API allows users to interact with an online queue that coordinates the process of formulating and solving a model which approximates the NEMDE. Users first prepare parameters describing the National Electricity Market's state in the form of a case file. Parameters include: offers and bids made by generators and loads; initial conditions for units, interconnectors, and regions; interconnector loss model factors; generic constraint terms. See the parameter reference page for more details regarding the data that can be submitted via the API. Once a case file has been prepared, it can be submitted to an online queue via the Dispatch API. A pool of workers constantly monitor the queue for new case files. If a worker is idle when a case file enters the queue it will use the parameters submitted by the user to formulate and solve a model approximating the NEMDE. If all workers are occupied when the case file is submitted, the case file will 'wait' in the queue until a worker is available. Upon solving the model the worker posts its results back to queue, which can then be retrieved by the user. Results remain within the queue for a limited time (2 hours) at which point they are deleted. The following diagram illustrates the workflow used when solving a model using the Dispatch API. Multiple workers can monitor the queue simultaneously, allowing models to be solved in parallel. This capability allows large-scale scenario anlayses to be underaken. Cloud computing resources can be customised to meet user requirements (email contact@envector.com for more information). Getting started Obtain a token Token authentication is used to control access to the Dispatch API. A valid token must be present when making requests (e.g. when submitting a case file to the queue, or attempting to retrieve results). Requests will fail if a valid token is not included. If you would like to arrange a trial please email contact@envector.com . Tutorials The tutorials section gives an overview of the Dispatch API's features and provides examples on how to setup scenario analyses and associated workflows. The Running a Model tutorial is the recommended starting point for new users. Case file reference The parameter reference page shows the parameters that can be meaningfully updated when modifying or constructing case files. Model validation See how the solution returned by the Dispatch API compares to results obtained from NEMDE in the model validation section . Case studies See potential applications of the Dispatch API via case studies . Google Sheets interface Interact with the Dispatch API via a spreadsheet - no programming required. Load data via the click of a button, update case file parameters, run a scenario, and explore results. Examine and update trader parameters and offers. Run scenarios using modified parameters, load results, and explore dispatch outcomes.","title":"Home"},{"location":"#dispatch-api-documentation","text":"The Dispatch API allows users to interact with a mathematical program that approximates Australia's National Electricity Market Dispatch Engine (NEMDE). The model is formulated as a single period economic dispatch problem that seeks to dispatch generators and loads such that demand is met at the lowest cost while respecting unit, network, and system constraints. The API can be used to investigate relationships between system parameters and dispatch outcomes, with possible applications including ex-post scenario and sensitivity analyses, or the tool's integration within forecasting frameworks.","title":"Dispatch API Documentation"},{"location":"#features-and-known-limitations","text":"The model used to approximate the NEMDE includes the following components: generator and load bids (FCAS and energy market); market network service provider (MNSP) bids; interconnector loss models with SOS2 constraints; Basslink loss model; generic constraints; FCAS constraints; two pass solution algorithm and inflexibility profiles for fast-start units; tie-breaking model for price-tied energy offers. The model validation section describes the data-driven approach used to assess the Dispatch API's ability to emulate NEMDE outputs. Excellent correspondence is observed between solutions reported by the Dispatch API and those reported by the NEMDE. However, users should note the Dispatch API is subject to some important limitations: FCAS prices are not reported; generic constraint right-hand side (RHS) values are obtained from historical NEMDE solutions rather than computed from SCADA values; intervention pricing runs are not supported; prices are not adjusted to the market price floor or cap if these thresholds are exceeded; constraint relaxation algorithms are not implemented. The above list represents known material limitations associated with the model. Work is underway to address each of these points, with updates likely to be incorporated within future versions of the Dispatch API.","title":"Features and known limitations"},{"location":"#how-it-works","text":"The Dispatch API allows users to interact with an online queue that coordinates the process of formulating and solving a model which approximates the NEMDE. Users first prepare parameters describing the National Electricity Market's state in the form of a case file. Parameters include: offers and bids made by generators and loads; initial conditions for units, interconnectors, and regions; interconnector loss model factors; generic constraint terms. See the parameter reference page for more details regarding the data that can be submitted via the API. Once a case file has been prepared, it can be submitted to an online queue via the Dispatch API. A pool of workers constantly monitor the queue for new case files. If a worker is idle when a case file enters the queue it will use the parameters submitted by the user to formulate and solve a model approximating the NEMDE. If all workers are occupied when the case file is submitted, the case file will 'wait' in the queue until a worker is available. Upon solving the model the worker posts its results back to queue, which can then be retrieved by the user. Results remain within the queue for a limited time (2 hours) at which point they are deleted. The following diagram illustrates the workflow used when solving a model using the Dispatch API. Multiple workers can monitor the queue simultaneously, allowing models to be solved in parallel. This capability allows large-scale scenario anlayses to be underaken. Cloud computing resources can be customised to meet user requirements (email contact@envector.com for more information).","title":"How it works"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#obtain-a-token","text":"Token authentication is used to control access to the Dispatch API. A valid token must be present when making requests (e.g. when submitting a case file to the queue, or attempting to retrieve results). Requests will fail if a valid token is not included. If you would like to arrange a trial please email contact@envector.com .","title":"Obtain a token"},{"location":"#tutorials","text":"The tutorials section gives an overview of the Dispatch API's features and provides examples on how to setup scenario analyses and associated workflows. The Running a Model tutorial is the recommended starting point for new users.","title":"Tutorials"},{"location":"#case-file-reference","text":"The parameter reference page shows the parameters that can be meaningfully updated when modifying or constructing case files.","title":"Case file reference"},{"location":"#model-validation","text":"See how the solution returned by the Dispatch API compares to results obtained from NEMDE in the model validation section .","title":"Model validation"},{"location":"#case-studies","text":"See potential applications of the Dispatch API via case studies .","title":"Case studies"},{"location":"#google-sheets-interface","text":"Interact with the Dispatch API via a spreadsheet - no programming required. Load data via the click of a button, update case file parameters, run a scenario, and explore results. Examine and update trader parameters and offers. Run scenarios using modified parameters, load results, and explore dispatch outcomes.","title":"Google Sheets interface"},{"location":"parameter-reference/","text":"Case file parameters Case files submitted via the Dispatch API follow the same data structure as NEMDE case files (see this tutorial to learn how to convert historical NEMDE case files into a format that can be consumed by the Dispatch API). This assists development efforts as historical case files provide an excellent foundation on which new features can be built. However, there are limitations that arise from this approach. For instance, the Dispatch API only uses a subset of the data contained within historical case files when formulating a mathematical program. Ambiguities may also arise when inspecting case files as some parameters are duplicated while others may be ignored. The following sections seek to address these ambiguities by explicitly outlining the parameters used when formulating a mathematical program via the Dispatch API. Updates made to these parameters will be reflected in the formulated model, while changes to all other parameters are ignored and will have no effect. Paths to parameters within a JSON case file document are provided. Filters may need to be used when referencing specific elements (e.g. to identify a specific trader, interconnector, region, or constraint). Where practical, tables are used to summarise possible values for these query parameters. Note that this document may be updated over time as additional information is incorporated into the model used by the Dispatch API. Case NEMSPDCaseFile . NemSpdInputs . Case . @VoLL NEMSPDCaseFile . NemSpdInputs . Case . @EnergyDeficitPrice NEMSPDCaseFile . NemSpdInputs . Case . @EnergySurplusPrice NEMSPDCaseFile . NemSpdInputs . Case . @RampRatePrice NEMSPDCaseFile . NemSpdInputs . Case . @InterconnectorPrice NEMSPDCaseFile . NemSpdInputs . Case . @CapacityPrice NEMSPDCaseFile . NemSpdInputs . Case . @OfferPrice NEMSPDCaseFile . NemSpdInputs . Case . @TieBreakPrice NEMSPDCaseFile . NemSpdInputs . Case . @MNSPOfferPrice NEMSPDCaseFile . NemSpdInputs . Case . @MNSPRampRatePrice NEMSPDCaseFile . NemSpdInputs . Case . @MNSPCapacityPrice NEMSPDCaseFile . NemSpdInputs . Case . @FastStartPrice NEMSPDCaseFile . NemSpdInputs . Case . @UIGFSurplusPrice NEMSPDCaseFile . NemSpdInputs . Case . @ASMaxAvailPrice NEMSPDCaseFile . NemSpdInputs . Case . @ASEnablementMinPrice NEMSPDCaseFile . NemSpdInputs . Case . @ASEnablementMaxPrice NEMSPDCaseFile . NemSpdInputs . Case . @FastStartThreshold Regions Initial conditions NEMSPDCaseFile . NemSpdInputs . RegionCollection . Region [ ? ( @RegionID = \"region_id\" )] . RegionInitialConditionCollection . RegionInitialCondition [ ? ( @InitialConditionID = \"initial_condition_id\" })] . @Value region_id Description SA1 South Australia VIC1 Victoria TAS1 Tasmania NSW1 New South Wales QLD1 Queensland initial_condition_id Description ADE Aggregate dispatch error at start of dispatch interval (MW) InitialDemand Demand at start of dispatch interval (MW) Demand Forecast The Demand Forecast ( @DF ) parameter denotes the difference between anticipated region demand at the end of the dispatch interval and region demand at the start of the interval. For example, if @DF=20 it indicates demand is expected to be 20MW higher at the end of the interval relative to the start of the interval. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . RegionPeriodCollection . RegionPeriod [ ? ( @RegionID = \"region_id\" )] . @DF Traders Metadata From TraderCollection: NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @TraderID NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @TraderType NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @SemiDispatch Key Description @TraderID Unique trader ID. Same as Dispatchable Unit Identifier (DUID). @TraderType Either \"GENERATOR\", \"LOAD\", or \"NORMALLY_ON_LOAD\" @SemiDispatch Flag indicating if unit is semi-dispatchable. \"1\"=semi-dispatchable unit (e.g. wind / solar), \"0\"=dispatchable unit From TraderPeriodCollection: NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . @RegionID Key Description @RegionID Region in which trader is located Initial conditions NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TraderInitialConditionCollection . TraderInitialCondition [ ? ( @InitialConditionID = \"initial_condition_id\" )] . @Value initial_condition_id Description AGCStatus Unit AGC status ('1'=AGC enabled, '0'=AGC disabled) HMW Max output from SCADA telemetry (MW) InitialMW Trader output at start of dispatch interval (MW) LMW Min output from SCADA telemetry (MW) WhatIfInitialMW Trader initial MW value to use if intervention pricing run (MW) SCADARampDnRate Max ramp down rate reported by SCADA telemetry (MW/hour) SCADARampUpRate Max ramp up rate reported by SCADA telemetry (MW/hour) Price bands NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @TradeType NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand1 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand2 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand3 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand4 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand5 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand6 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand7 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand8 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand9 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand10 trade_type Description ENOF Generator energy market offer LDOF Load energy market offer R6SE Contingency FCAS raise 6s offer R60S Contingency FCAS raise 60s offer R5MI Contingency FCAS raise 5min offer R5RE Regulation FCAS raise offer L6SE Contingency FCAS lower 6s offer L60S Contingency FCAS lower 60s offer L5MI Contingency FCAS lower 5min offer L5RE Regulation FCAS lower offer Quantity bands Quantity bands and max availability for a given @TradeType: NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @TradeType NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @MaxAvail NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail1 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail2 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail3 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail4 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail5 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail6 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail7 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail8 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail9 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail10 Ramp rate parameters must be included for energy market offers (i.e. @TradeType is either ENOF or LDOF): NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @RampUpRate NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @RampDnRate FCAS trapezium parameters must be included for FCAS offers (i.e. @TradeType is in [R6SE, R60S, R6MI, R5RE, L6SE, L60S, L5MI, L5RE]): NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @EnablementMin NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @EnablementMax NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @LowBreakpoint NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @HighBreakpoint UIGF The Unconstrained Intermittent Generation Forecast (UIGF) is defined for semi-scheduled units. The parameter denotes a unit's forecast max power output at the end of a dispatch interval. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . @UIGF Fast-start unit parameters The following parameters describe the inflexibility profile fast-start units are subject to once they come online. NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @FastStart NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @MinLoadingMW NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @CurrentMode NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @CurrentModeTime NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T1 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T2 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T3 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T4 Interconnectors Metadata NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @InterconnectorID NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @MNSP NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @FromRegion NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @ToRegion Key Description @InterconnectorID Unique identifier for interconnector @MNSP Flag indicating if interconnector is a Market Network Service Provider (MNSP). \"1\"=is a MNSP, \"0\"=not an MNSP. @FromRegion Interconnector's notional 'from' region @ToRegion Interconnector's notional 'to' region interconnector_id Name N-Q-MNSP1 Terranora NSW1-QLD1 New South Wales to Queensland VIC1-NSW1 Victoria to New South Wales T-V-MNSP1 Basslink V-SA Heywood V-S-MNSP1 Murraylink Interconnectors connect NEM regions. The @FromRegion and @ToRegion parameters define the direction of positive power flow over the interconnector. A net transfer out of @FromRegion into @ToRegion results in a positive flow value, while negative values correspond to a net transfer out of @ToRegion into @FromRegion. Power flow limits NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @LowerLimit NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @UpperLimit Key Description @LowerLimit Max flow in the direction @ToRegion \u2192 @FromRegion (MW) @UpperLimit Max flow in the direction @FromRegion \u2192 @ToRegion (MW) Initial conditions NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . InterconnectorInitialConditionCollection . InterconnectorInitialCondition [ ? ( @InitialConditionID = \"initial_condition_id\" )] . @Value initial_condition_id Description InitialMW Power flow over interconnector at start of dispatch interval (MW) WhatIfInitialMW Initial power flow value to use if intervention pricing run (MW) Loss model NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . @LossLowerLimit NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . @LossShare Key Description @LossLowerLimit Left most edge of loss function curve (MW) @LossShare Interconnector losses are allocated to @FromRegion and @ToRegion in proportion to @LossShare. @LossShare denotes the proportion of interconnector losses assigned to @FromRegion. (1 - @LossShare) x InterconnectorLoss is assigned to @ToRegion. The interconnector loss model uses a piecewise linear function to describe interconnector losses as a function of interconnector power flow. Loss model segments denote marginal losses for each interval of the piecewise linear function. NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . SegmentCollection . Segment [ n ] . @Limit NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . SegmentCollection . Segment [ n ] . @Factor Key Description @Limit Power flow value at right edge of segment bin (MW) @Factor Marginal loss over segment Basslink Market network service providers submit offers into the market for energy much like traders. Offers are made in the @FromRegion and @ToRegion for the interconnector. Price bands NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @RegionID NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand1 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand2 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand3 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand4 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand5 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand6 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand7 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand8 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand9 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand10 Quantity bands NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @RegionID NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail1 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail2 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail3 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail4 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail5 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail6 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail7 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail8 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail9 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail10 Ramp rates and max availability NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @MaxAvail NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @RampUpRate NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @RampDnRate Key Description @MaxAvail Max offer quantity (MW) @RampUpRate Max ramp up rate (MW/hr) @RampDnRate Max ramp down rate (MW/hr) Additional loss model parameters In addition to losses arising from power flow over the interconnector, there are also losses associated with power flow between the MNSP's connection points and their correspoding regional reference nodes. These marginal loss factors depend on the direction of power flow, with different factors used if the interconnector is importing or exporting power. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @FromRegionLFImport NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @FromRegionLFExport NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @ToRegionLFImport NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @ToRegionLFExport Generic constraints Metadata From GenericConstraintCollection: NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . @ConstraintID NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . @Type NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . @ViolationPrice Key Description @ConstraintID Unique constraint ID @Type Type of constraint. Either \"LE\" (less than or equal to <=), \"GE\" (greater than or equal to >=), or \"EQ\" (equality constraint ==). @ViolationPrice Constraint violation price Intervention indicator The @Intervention flag denotes whether a constraint is associated with an intervention interval, or if it is a regular generic constraint (\"1\"=intervention constraint, \"0\"=regular generic constraint). While all generic constraints are used to identify dispatch targets, only constraints with @Intervention=\"0\" are used when undertaking the pricing run for the intervention interval. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . GenericConstraintPeriodCollection . GenericConstraintPeriod [ ? ( @ConstraintID = \"constraint_id\" )] . @ConstraintID NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . GenericConstraintPeriodCollection . GenericConstraintPeriod [ ? ( @ConstraintID = \"constraint_id\" )] . @Intervention Left-hand side (LHS) factor collection The LHS of a generic constraint can consist of trader, region, and interconnector variables. NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . LHSFactorCollection . TraderFactor NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . LHSFactorCollection . RegionFactor NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . LHSFactorCollection . InterconnectorFactor Example trader factors: \"TraderFactor\" : { \"@Factor\" : \"1\" , \"@TradeType\" : \"ENOF\" , \"@TraderID\" : \"LK_ECHO\" } Example interconnector factors: \"InterconnectorFactor\" : { \"@Factor\" : \"1\" , \"@InterconnectorID\" : \"V-S-MNSP1\" } Example region factors: \"RegionFactor\" : [ { \"@Factor\" : \"1\" , \"@TradeType\" : \"R5MI\" , \"@RegionID\" : \"NSW1\" }, ... , ] Right-hand side (RHS) This is parameter is obtained from NEMDE outputs. This is a limitation of the Dispatch API, as the NEMDE uses SCADA values to compute RHS values. Functionality to compute RHS values from SCADA values is under active development. NEMSPDCaseFile . NemSpdOutputs . ConstraintSolution [ ? ( @ConstraintID = \"constraint_id\" && @Intervention = \"intervention\" )] . @RHS","title":"Case file parameters"},{"location":"parameter-reference/#case-file-parameters","text":"Case files submitted via the Dispatch API follow the same data structure as NEMDE case files (see this tutorial to learn how to convert historical NEMDE case files into a format that can be consumed by the Dispatch API). This assists development efforts as historical case files provide an excellent foundation on which new features can be built. However, there are limitations that arise from this approach. For instance, the Dispatch API only uses a subset of the data contained within historical case files when formulating a mathematical program. Ambiguities may also arise when inspecting case files as some parameters are duplicated while others may be ignored. The following sections seek to address these ambiguities by explicitly outlining the parameters used when formulating a mathematical program via the Dispatch API. Updates made to these parameters will be reflected in the formulated model, while changes to all other parameters are ignored and will have no effect. Paths to parameters within a JSON case file document are provided. Filters may need to be used when referencing specific elements (e.g. to identify a specific trader, interconnector, region, or constraint). Where practical, tables are used to summarise possible values for these query parameters. Note that this document may be updated over time as additional information is incorporated into the model used by the Dispatch API.","title":"Case file parameters"},{"location":"parameter-reference/#case","text":"NEMSPDCaseFile . NemSpdInputs . Case . @VoLL NEMSPDCaseFile . NemSpdInputs . Case . @EnergyDeficitPrice NEMSPDCaseFile . NemSpdInputs . Case . @EnergySurplusPrice NEMSPDCaseFile . NemSpdInputs . Case . @RampRatePrice NEMSPDCaseFile . NemSpdInputs . Case . @InterconnectorPrice NEMSPDCaseFile . NemSpdInputs . Case . @CapacityPrice NEMSPDCaseFile . NemSpdInputs . Case . @OfferPrice NEMSPDCaseFile . NemSpdInputs . Case . @TieBreakPrice NEMSPDCaseFile . NemSpdInputs . Case . @MNSPOfferPrice NEMSPDCaseFile . NemSpdInputs . Case . @MNSPRampRatePrice NEMSPDCaseFile . NemSpdInputs . Case . @MNSPCapacityPrice NEMSPDCaseFile . NemSpdInputs . Case . @FastStartPrice NEMSPDCaseFile . NemSpdInputs . Case . @UIGFSurplusPrice NEMSPDCaseFile . NemSpdInputs . Case . @ASMaxAvailPrice NEMSPDCaseFile . NemSpdInputs . Case . @ASEnablementMinPrice NEMSPDCaseFile . NemSpdInputs . Case . @ASEnablementMaxPrice NEMSPDCaseFile . NemSpdInputs . Case . @FastStartThreshold","title":"Case"},{"location":"parameter-reference/#regions","text":"","title":"Regions"},{"location":"parameter-reference/#initial-conditions","text":"NEMSPDCaseFile . NemSpdInputs . RegionCollection . Region [ ? ( @RegionID = \"region_id\" )] . RegionInitialConditionCollection . RegionInitialCondition [ ? ( @InitialConditionID = \"initial_condition_id\" })] . @Value region_id Description SA1 South Australia VIC1 Victoria TAS1 Tasmania NSW1 New South Wales QLD1 Queensland initial_condition_id Description ADE Aggregate dispatch error at start of dispatch interval (MW) InitialDemand Demand at start of dispatch interval (MW)","title":"Initial conditions"},{"location":"parameter-reference/#demand-forecast","text":"The Demand Forecast ( @DF ) parameter denotes the difference between anticipated region demand at the end of the dispatch interval and region demand at the start of the interval. For example, if @DF=20 it indicates demand is expected to be 20MW higher at the end of the interval relative to the start of the interval. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . RegionPeriodCollection . RegionPeriod [ ? ( @RegionID = \"region_id\" )] . @DF","title":"Demand Forecast"},{"location":"parameter-reference/#traders","text":"","title":"Traders"},{"location":"parameter-reference/#metadata","text":"From TraderCollection: NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @TraderID NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @TraderType NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @SemiDispatch Key Description @TraderID Unique trader ID. Same as Dispatchable Unit Identifier (DUID). @TraderType Either \"GENERATOR\", \"LOAD\", or \"NORMALLY_ON_LOAD\" @SemiDispatch Flag indicating if unit is semi-dispatchable. \"1\"=semi-dispatchable unit (e.g. wind / solar), \"0\"=dispatchable unit From TraderPeriodCollection: NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . @RegionID Key Description @RegionID Region in which trader is located","title":"Metadata"},{"location":"parameter-reference/#initial-conditions_1","text":"NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TraderInitialConditionCollection . TraderInitialCondition [ ? ( @InitialConditionID = \"initial_condition_id\" )] . @Value initial_condition_id Description AGCStatus Unit AGC status ('1'=AGC enabled, '0'=AGC disabled) HMW Max output from SCADA telemetry (MW) InitialMW Trader output at start of dispatch interval (MW) LMW Min output from SCADA telemetry (MW) WhatIfInitialMW Trader initial MW value to use if intervention pricing run (MW) SCADARampDnRate Max ramp down rate reported by SCADA telemetry (MW/hour) SCADARampUpRate Max ramp up rate reported by SCADA telemetry (MW/hour)","title":"Initial conditions"},{"location":"parameter-reference/#price-bands","text":"NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @TradeType NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand1 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand2 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand3 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand4 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand5 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand6 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand7 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand8 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand9 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . TradePriceStructureCollection . TradePriceStructure . [ ? ( @TradeType = \"trade_type\" )] . @PriceBand10 trade_type Description ENOF Generator energy market offer LDOF Load energy market offer R6SE Contingency FCAS raise 6s offer R60S Contingency FCAS raise 60s offer R5MI Contingency FCAS raise 5min offer R5RE Regulation FCAS raise offer L6SE Contingency FCAS lower 6s offer L60S Contingency FCAS lower 60s offer L5MI Contingency FCAS lower 5min offer L5RE Regulation FCAS lower offer","title":"Price bands"},{"location":"parameter-reference/#quantity-bands","text":"Quantity bands and max availability for a given @TradeType: NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @TradeType NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @MaxAvail NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail1 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail2 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail3 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail4 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail5 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail6 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail7 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail8 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail9 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @BandAvail10 Ramp rate parameters must be included for energy market offers (i.e. @TradeType is either ENOF or LDOF): NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @RampUpRate NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @RampDnRate FCAS trapezium parameters must be included for FCAS offers (i.e. @TradeType is in [R6SE, R60S, R6MI, R5RE, L6SE, L60S, L5MI, L5RE]): NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @EnablementMin NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @EnablementMax NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @LowBreakpoint NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . TradeCollection . Trade [ @TradeType = \"trade_type\" ] . @HighBreakpoint","title":"Quantity bands"},{"location":"parameter-reference/#uigf","text":"The Unconstrained Intermittent Generation Forecast (UIGF) is defined for semi-scheduled units. The parameter denotes a unit's forecast max power output at the end of a dispatch interval. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . TraderPeriodCollection . TraderPeriod [ ? ( @TraderID = \"trader_id\" )] . @UIGF","title":"UIGF"},{"location":"parameter-reference/#fast-start-unit-parameters","text":"The following parameters describe the inflexibility profile fast-start units are subject to once they come online. NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @FastStart NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @MinLoadingMW NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @CurrentMode NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @CurrentModeTime NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T1 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T2 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T3 NEMSPDCaseFile . NemSpdInputs . TraderCollection . Trader [ ? ( @TraderID = \"trader_id\" )] . @T4","title":"Fast-start unit parameters"},{"location":"parameter-reference/#interconnectors","text":"","title":"Interconnectors"},{"location":"parameter-reference/#metadata_1","text":"NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @InterconnectorID NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @MNSP NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @FromRegion NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @ToRegion Key Description @InterconnectorID Unique identifier for interconnector @MNSP Flag indicating if interconnector is a Market Network Service Provider (MNSP). \"1\"=is a MNSP, \"0\"=not an MNSP. @FromRegion Interconnector's notional 'from' region @ToRegion Interconnector's notional 'to' region interconnector_id Name N-Q-MNSP1 Terranora NSW1-QLD1 New South Wales to Queensland VIC1-NSW1 Victoria to New South Wales T-V-MNSP1 Basslink V-SA Heywood V-S-MNSP1 Murraylink Interconnectors connect NEM regions. The @FromRegion and @ToRegion parameters define the direction of positive power flow over the interconnector. A net transfer out of @FromRegion into @ToRegion results in a positive flow value, while negative values correspond to a net transfer out of @ToRegion into @FromRegion.","title":"Metadata"},{"location":"parameter-reference/#power-flow-limits","text":"NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @LowerLimit NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @UpperLimit Key Description @LowerLimit Max flow in the direction @ToRegion \u2192 @FromRegion (MW) @UpperLimit Max flow in the direction @FromRegion \u2192 @ToRegion (MW)","title":"Power flow limits"},{"location":"parameter-reference/#initial-conditions_2","text":"NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . InterconnectorInitialConditionCollection . InterconnectorInitialCondition [ ? ( @InitialConditionID = \"initial_condition_id\" )] . @Value initial_condition_id Description InitialMW Power flow over interconnector at start of dispatch interval (MW) WhatIfInitialMW Initial power flow value to use if intervention pricing run (MW)","title":"Initial conditions"},{"location":"parameter-reference/#loss-model","text":"NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . @LossLowerLimit NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . @LossShare Key Description @LossLowerLimit Left most edge of loss function curve (MW) @LossShare Interconnector losses are allocated to @FromRegion and @ToRegion in proportion to @LossShare. @LossShare denotes the proportion of interconnector losses assigned to @FromRegion. (1 - @LossShare) x InterconnectorLoss is assigned to @ToRegion. The interconnector loss model uses a piecewise linear function to describe interconnector losses as a function of interconnector power flow. Loss model segments denote marginal losses for each interval of the piecewise linear function. NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . SegmentCollection . Segment [ n ] . @Limit NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . LossModelCollection . LossModelCollection . SegmentCollection . Segment [ n ] . @Factor Key Description @Limit Power flow value at right edge of segment bin (MW) @Factor Marginal loss over segment","title":"Loss model"},{"location":"parameter-reference/#basslink","text":"Market network service providers submit offers into the market for energy much like traders. Offers are made in the @FromRegion and @ToRegion for the interconnector.","title":"Basslink"},{"location":"parameter-reference/#price-bands_1","text":"NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @RegionID NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand1 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand2 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand3 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand4 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand5 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand6 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand7 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand8 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand9 NEMSPDCaseFile . NemSpdInputs . InterconnectorCollection . Interconnector [ ? ( @InterconnectorID = \"interconnector_id\" ] . MNSPPriceStructureCollection . MNSPPriceStructure . MNSPRegionPriceStructureCollection . MNSPRegionPriceStructure [ ? ( @RegionID = \"region_id\" )] . @PriceBand10","title":"Price bands"},{"location":"parameter-reference/#quantity-bands_1","text":"NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @RegionID NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail1 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail2 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail3 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail4 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail5 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail6 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail7 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail8 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail9 NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @BandAvail10","title":"Quantity bands"},{"location":"parameter-reference/#ramp-rates-and-max-availability","text":"NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @MaxAvail NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @RampUpRate NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . MNSPOfferCollection . MNSPOffer [ ? ( @RegionID = \"region_id\" )] . @RampDnRate Key Description @MaxAvail Max offer quantity (MW) @RampUpRate Max ramp up rate (MW/hr) @RampDnRate Max ramp down rate (MW/hr)","title":"Ramp rates and max availability"},{"location":"parameter-reference/#additional-loss-model-parameters","text":"In addition to losses arising from power flow over the interconnector, there are also losses associated with power flow between the MNSP's connection points and their correspoding regional reference nodes. These marginal loss factors depend on the direction of power flow, with different factors used if the interconnector is importing or exporting power. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @FromRegionLFImport NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @FromRegionLFExport NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @ToRegionLFImport NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . InterconnectorPeriodCollection . InterconnectorPeriod [ ? ( @InterconnectorID = \"interconnector_id\" )] . @ToRegionLFExport","title":"Additional loss model parameters"},{"location":"parameter-reference/#generic-constraints","text":"","title":"Generic constraints"},{"location":"parameter-reference/#metadata_2","text":"From GenericConstraintCollection: NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . @ConstraintID NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . @Type NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . @ViolationPrice Key Description @ConstraintID Unique constraint ID @Type Type of constraint. Either \"LE\" (less than or equal to <=), \"GE\" (greater than or equal to >=), or \"EQ\" (equality constraint ==). @ViolationPrice Constraint violation price","title":"Metadata"},{"location":"parameter-reference/#intervention-indicator","text":"The @Intervention flag denotes whether a constraint is associated with an intervention interval, or if it is a regular generic constraint (\"1\"=intervention constraint, \"0\"=regular generic constraint). While all generic constraints are used to identify dispatch targets, only constraints with @Intervention=\"0\" are used when undertaking the pricing run for the intervention interval. NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . GenericConstraintPeriodCollection . GenericConstraintPeriod [ ? ( @ConstraintID = \"constraint_id\" )] . @ConstraintID NEMSPDCaseFile . NemSpdInputs . PeriodCollection . Period . GenericConstraintPeriodCollection . GenericConstraintPeriod [ ? ( @ConstraintID = \"constraint_id\" )] . @Intervention","title":"Intervention indicator"},{"location":"parameter-reference/#left-hand-side-lhs-factor-collection","text":"The LHS of a generic constraint can consist of trader, region, and interconnector variables. NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . LHSFactorCollection . TraderFactor NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . LHSFactorCollection . RegionFactor NEMSPDCaseFile . NemSpdInputs . GenericConstraintCollection . GenericConstraint [ ? ( @ConstraintID = \"constraint_id\" )] . LHSFactorCollection . InterconnectorFactor Example trader factors: \"TraderFactor\" : { \"@Factor\" : \"1\" , \"@TradeType\" : \"ENOF\" , \"@TraderID\" : \"LK_ECHO\" } Example interconnector factors: \"InterconnectorFactor\" : { \"@Factor\" : \"1\" , \"@InterconnectorID\" : \"V-S-MNSP1\" } Example region factors: \"RegionFactor\" : [ { \"@Factor\" : \"1\" , \"@TradeType\" : \"R5MI\" , \"@RegionID\" : \"NSW1\" }, ... , ]","title":"Left-hand side (LHS) factor collection"},{"location":"parameter-reference/#right-hand-side-rhs","text":"This is parameter is obtained from NEMDE outputs. This is a limitation of the Dispatch API, as the NEMDE uses SCADA values to compute RHS values. Functionality to compute RHS values from SCADA values is under active development. NEMSPDCaseFile . NemSpdOutputs . ConstraintSolution [ ? ( @ConstraintID = \"constraint_id\" && @Intervention = \"intervention\" )] . @RHS","title":"Right-hand side (RHS)"},{"location":"case-studies/case-studies/","text":"Case studies Price volatility The Dispatch API is used to investigate the underlying causes for a period of volatile dispatch prices in South Australia. Click here . Rebid analysis Changing plant / system conditions often require traders to rebid a generator or load's availability. The following case study uses the Dispatch API to estimate the impact a rebid has on spot prices. Click here .","title":"Case studies"},{"location":"case-studies/case-studies/#case-studies","text":"","title":"Case studies"},{"location":"case-studies/case-studies/#price-volatility","text":"The Dispatch API is used to investigate the underlying causes for a period of volatile dispatch prices in South Australia. Click here .","title":"Price volatility"},{"location":"case-studies/case-studies/#rebid-analysis","text":"Changing plant / system conditions often require traders to rebid a generator or load's availability. The following case study uses the Dispatch API to estimate the impact a rebid has on spot prices. Click here .","title":"Rebid analysis"},{"location":"case-studies/price-volatility/price-volatility/","text":"Price volatility Overview Over the span of two hours on 17 November 2020 South Australian dispatch prices increased from 45 $/MWh to over 250 $/MWh before falling to 62 $/MWh. The following analysis uses the Dispatch API to explore the underlying factors responsible for this price volatility. Analysis Dispatch prices for the period under investigation are shown in Figure 1. When examining the historical price series from 5.10pm to 5.45pm there appears be no indication that South Australian dispatch prices are on the verge of experiencing significant volatility over the following hour. Were the price movements from 5.50pm to 6.45pm due to a contingency event, or were there changes occurring to system dynamics in the lead up to 5.50pm that only began to be reflected in prices at 5.55pm? Sensitivity analyses can assist in answering these questions by estimating the prices that would be realised under different operating scenarios. Understanding the relationship between demand and dispatch prices is particularly important as it can help exposit underlying dynamics relating to changes in the system's state. The Dispatch API is used to investigate this relationship by incrementally augmenting the Demand Forecast (DF) parameter for each dispatch interval and observing the resulting dispatch price. The DF parameter corresponds to the amount by which demand is expected to change over a dispatch interval. For example, a value of 10 MW denotes that demand is expected to be 10 MW higher at the end of a dispatch interval relative to the start of the interval. Scenarios are constructed by varying the DF parameter from -500MW to 500MW at 25 MW incremenets for each interval from 5.10pm to 7.00pm, with the results shown in Figure 2. Each dispatch interval is represented by a column comprised of rectangles. Each rectangle represents a demand forecast scenario, with the colour of the rectangle denoting the price observed for the scenario - lighter colours correspond to higher prices. These columns illustrate the relationship between demand and dispatch prices for each interval. Overlaying the historical price series and realised demand forecast values in Figure 3 we can see how these price sensitivities change over the window under investigation. From 5.10pm to 6.05pm there is a downward shift in lighter coloured rectangles - the system is moving closer to a region where higher prices are likely to be observed. The DF parameter is typically in the order of 10's of MW, as shown by the red curve which denotes historical DF parameters observed for each interval. The intersection of the historical DF curve and colour of the rectangle it passes through corresponds to the historical price observed for that dispatch interval. The red curve begins in a dark blue rectangle indicating a relatively low price, but then intersects lighter coloured rectangles during the period of price volatility. By running scenarios over a wide range of demand forecast parameters we are forewarned of the price increase as we can see the lighter coloured rectangles approaching the red curve from 5.10pm to 5.55pm. The price dynamics observed between 5.10pm and 5.55pm are analogous to walking near the edge of a cliff - the ground is flat until reaching the precipice. Similarly, prices remain relatively steady until reaching a critical level at which point they quickly increase. If we simply look at a historical prices we are walking with our eyes closed. By running scenarios with different DF parameters we are able to see our surroundings, in particular the location of the cliff's edge. Attention now turns to identifying drivers of the price volatility observed from 5.55pm to 6.45pm. Examining demand and supply over the window under investigation is a natural starting point. The amount by which demand and semi-scheduled output change over the window under investigation is shown in Figure 4. Plotted values denote the change observed relative to 5.10pm. Demand is approximatley 300 MW higher at the end of the window relative to the start, while semi-scheduled output has fallen by a similar amount. For reference, total demand in South Australia is 1086 MW at 5.10pm. This rapid increase in demand coupled with a reduction in supply results in a move up the supply curve, illustrated by the downward movement of yellow and green rectangles from 5.10pm to 6.05pm in Figure 3. Net generation and demand relative to the start of the window under investigation can also be compared, with Figure 5 showing regional demand outpacing net generation. The following animation illustrates how prices become more sensitive to changes in demand before price volatility materialises. At 5.55pm demand intersects within a steep section of the supply curve, resulting in a sudden price increase. Note the supply curve has been constructed using the same information found in Figure 3. Gradual shifts in the supply curve from 5.10pm to 5.55pm, coupled with the rapid increase in demand and reduction in output from semi-scheduled plant provides preliminary evidence suggesting demand and supply dynamics are the primary drivers of the price volatility observed. The impact of interconnector capabilities, generator availabilities, and generic constraints on South Australian dispatch prices could also be assessed, but is beyond the scope of this analysis. Summary The Dispatch API allows otherwise unobservable relationships between system parameters and dispatch outcomes to be investigated. While this analysis has examined how changes to demand in South Australia affect dispatch prices in the same region, the Dispatch API can also be used to explore how other parameters such as interconnector capabilities, generator availabilities, or output from wind and solar plant impact dispatch outcomes. If you would like to learn more about the Dispatch API please email contact@envector.com .","title":"Price volatility"},{"location":"case-studies/price-volatility/price-volatility/#price-volatility","text":"","title":"Price volatility"},{"location":"case-studies/price-volatility/price-volatility/#overview","text":"Over the span of two hours on 17 November 2020 South Australian dispatch prices increased from 45 $/MWh to over 250 $/MWh before falling to 62 $/MWh. The following analysis uses the Dispatch API to explore the underlying factors responsible for this price volatility.","title":"Overview"},{"location":"case-studies/price-volatility/price-volatility/#analysis","text":"Dispatch prices for the period under investigation are shown in Figure 1. When examining the historical price series from 5.10pm to 5.45pm there appears be no indication that South Australian dispatch prices are on the verge of experiencing significant volatility over the following hour. Were the price movements from 5.50pm to 6.45pm due to a contingency event, or were there changes occurring to system dynamics in the lead up to 5.50pm that only began to be reflected in prices at 5.55pm? Sensitivity analyses can assist in answering these questions by estimating the prices that would be realised under different operating scenarios. Understanding the relationship between demand and dispatch prices is particularly important as it can help exposit underlying dynamics relating to changes in the system's state. The Dispatch API is used to investigate this relationship by incrementally augmenting the Demand Forecast (DF) parameter for each dispatch interval and observing the resulting dispatch price. The DF parameter corresponds to the amount by which demand is expected to change over a dispatch interval. For example, a value of 10 MW denotes that demand is expected to be 10 MW higher at the end of a dispatch interval relative to the start of the interval. Scenarios are constructed by varying the DF parameter from -500MW to 500MW at 25 MW incremenets for each interval from 5.10pm to 7.00pm, with the results shown in Figure 2. Each dispatch interval is represented by a column comprised of rectangles. Each rectangle represents a demand forecast scenario, with the colour of the rectangle denoting the price observed for the scenario - lighter colours correspond to higher prices. These columns illustrate the relationship between demand and dispatch prices for each interval. Overlaying the historical price series and realised demand forecast values in Figure 3 we can see how these price sensitivities change over the window under investigation. From 5.10pm to 6.05pm there is a downward shift in lighter coloured rectangles - the system is moving closer to a region where higher prices are likely to be observed. The DF parameter is typically in the order of 10's of MW, as shown by the red curve which denotes historical DF parameters observed for each interval. The intersection of the historical DF curve and colour of the rectangle it passes through corresponds to the historical price observed for that dispatch interval. The red curve begins in a dark blue rectangle indicating a relatively low price, but then intersects lighter coloured rectangles during the period of price volatility. By running scenarios over a wide range of demand forecast parameters we are forewarned of the price increase as we can see the lighter coloured rectangles approaching the red curve from 5.10pm to 5.55pm. The price dynamics observed between 5.10pm and 5.55pm are analogous to walking near the edge of a cliff - the ground is flat until reaching the precipice. Similarly, prices remain relatively steady until reaching a critical level at which point they quickly increase. If we simply look at a historical prices we are walking with our eyes closed. By running scenarios with different DF parameters we are able to see our surroundings, in particular the location of the cliff's edge. Attention now turns to identifying drivers of the price volatility observed from 5.55pm to 6.45pm. Examining demand and supply over the window under investigation is a natural starting point. The amount by which demand and semi-scheduled output change over the window under investigation is shown in Figure 4. Plotted values denote the change observed relative to 5.10pm. Demand is approximatley 300 MW higher at the end of the window relative to the start, while semi-scheduled output has fallen by a similar amount. For reference, total demand in South Australia is 1086 MW at 5.10pm. This rapid increase in demand coupled with a reduction in supply results in a move up the supply curve, illustrated by the downward movement of yellow and green rectangles from 5.10pm to 6.05pm in Figure 3. Net generation and demand relative to the start of the window under investigation can also be compared, with Figure 5 showing regional demand outpacing net generation. The following animation illustrates how prices become more sensitive to changes in demand before price volatility materialises. At 5.55pm demand intersects within a steep section of the supply curve, resulting in a sudden price increase. Note the supply curve has been constructed using the same information found in Figure 3. Gradual shifts in the supply curve from 5.10pm to 5.55pm, coupled with the rapid increase in demand and reduction in output from semi-scheduled plant provides preliminary evidence suggesting demand and supply dynamics are the primary drivers of the price volatility observed. The impact of interconnector capabilities, generator availabilities, and generic constraints on South Australian dispatch prices could also be assessed, but is beyond the scope of this analysis.","title":"Analysis"},{"location":"case-studies/price-volatility/price-volatility/#summary","text":"The Dispatch API allows otherwise unobservable relationships between system parameters and dispatch outcomes to be investigated. While this analysis has examined how changes to demand in South Australia affect dispatch prices in the same region, the Dispatch API can also be used to explore how other parameters such as interconnector capabilities, generator availabilities, or output from wind and solar plant impact dispatch outcomes. If you would like to learn more about the Dispatch API please email contact@envector.com .","title":"Summary"},{"location":"case-studies/rebid-analysis/rebid-analysis/","text":"Rebid Analysis The following sections demonstrate how the Dispatch API can be used estimate the contribution of a rebid to a change in dispatch prices. Overview On 27 November 2020 at 4.15pm the dispatch price in NSW was approximately 96 $/MWh. Dispatch prices increased to 290 $/MWh in the following interval at 4.20pm before falling to 93 $/MWh at 4.25pm. Approximately 2 minutes before the interval in which the price spike occurred a unit at Bayswater power station (trader ID BW01) submitted a rebid which indicated the unit's max available capacity was 130 MW less than previously anticipated. The following figure plots the power output and max availability for this unit, along with NSW dispatch prices. When analysing historical data it is difficult to estimate the extent to which a change in max availbility for BW01 contributed to the price movement at 4.20pm. The Dispatch API addresses this limitation by allowing users to estimate dispatch outcomes under counterfactual scenarios. For instance, a scenario can be constructed in which BW01 does not reduce its max availability at 4.20pm. Dispatch prices for this scenario can then be compared to historical outputs. As all other system parameters are kept constant, it is possible to isolate the rebid's contribution to the change in dispatch prices. Aims and scope The following analysis investigates how the rebid submitted by BW01 impacted dispatch prices observed at 4.20pm on 27 Novermber 2020. First, model validation is undertaken to assess the Dispatch API's ability to emulate NEMDE outputs for the interval under investigation. If close correspondence is observed between Dispatch API and NEMDE solutions then counterfactual scenarios will be constructed to estimate dispatch prices that would have arisen if BW01 had not rebid its capacity. Validation Historical NEMDE case files include the outputs returned by NEMDE when run for a given set of inputs describing the NEM's state. Model validation is performed by passing the same parameters to the Dispatch API as were passed to NEMDE, and comparing the Dispatch API's solution to historical NEMDE outputs. The degree to which solutions obtained from the Dispatch API correspond with NEMDE outputs indicates the Dispatch API's ability to emulate NEMDE for the dispatch interval under investigation. If close correspondence between the two solutions is observed then it is appropriate to proceed with the counterfactual scenario analysis. The following sections summarise the difference between the results obtained from the Dispatch API and historical NEMDE outputs for the dispatch interval ending at 4.20pm on 27 November 2020 - the interval for which the price spike is observed. Trader solution Summary statistics are computed for the difference between the Dispatch API's solution and NEMDE outputs, with the difference defined as follows: Solution Difference = Dispatch API Solution - NEMDE Solution. Statistics for the difference between the trader solution obtained from the Dispatch API and NEMDE are shown below. key count mean std min 25% 50% 75% max @EnergyTarget 340 4.92941e-08 1.20878e-06 -4.24e-06 0 0 0 2e-05 @FSTargetMode 74 0.0135135 0.116248 0 0 0 0 1 @L5RegTarget 340 8.82353e-10 1.69762e-07 -2e-06 0 0 0 2.4e-06 @L5RegViolation 340 0 0 0 0 0 0 0 @L5Target 340 5.22458e-18 3.84048e-07 -5e-06 0 0 0 5e-06 @L5Violation 340 0 0 0 0 0 0 0 @L60Target 340 5.88235e-09 2.42822e-07 -2e-06 0 0 0 4e-06 @L60Violation 340 0 0 0 0 0 0 0 @L6Target 340 4.11765e-09 1.51806 -20 0 0 0 17.9348 @L6Violation 340 0 0 0 0 0 0 0 @R5RegTarget 340 6.47059e-10 1.16308e-07 -1.6e-06 0 0 0 1.34e-06 @R5RegViolation 340 0 0 0 0 0 0 0 @R5Target 340 -1.55882e-08 2.27902e-07 -4e-06 0 0 0 0 @R5Violation 340 0 0 0 0 0 0 0 @R60Target 340 2.05882e-08 0.397291 -5.17241 0 0 0 5.17241 @R60Violation 340 0 0 0 0 0 0 0 @R6Target 340 -8.52941e-09 3.7803e-07 -3.3e-06 0 0 0 5e-06 @R6Violation 340 0 0 0 0 0 0 0 @RampDnRate 325 -0.000115572 0.000664364 -0.00499714 0 0 0 0.00286621 @RampUpRate 325 -0.000129432 0.000710994 -0.00499714 0 0 0 0.00229698 The following figures visualise the correspondence between the dispatch targets obtained from the Dispatch API and those returned by NEMDE for each trade type. Each point represents a dispatch target for a given trader. The horizontal axis denotes the solution obtained from the Dispatch API, while the vertical axis denotes the solution obtained from NEMDE. The dashed line has a slope of one, and indicates perfect correspondence between the Dispatch API and NEMDE solutions. There is excellent correpondence between the two models with respect to dispatch targets. The symmetric dispersion of points around the dashed line for the L6Target is likely due to the absence of tie-breaking constraints for FCAS offers. Region solution Summary statistics are presented for region solution metrics. key count mean std min 25% 50% 75% max @ClearedDemand 5 0.00134777 0.00385127 -0.00432637 -0.000960905 0.00368311 0.00372296 0.00462005 @DispatchedGeneration 5 -0.000654648 0.002728 -0.004063 -0.0026 -0.00066124 0.002015 0.002036 @DispatchedLoad 5 0 0 0 0 0 0 0 @EnergyPrice 5 5.38e-05 0.0001203 0 0 0 0 0.000269 @FixedDemand 5 -0.000361337 0.00269196 -0.00409289 -0.00115808 -0.000441503 0.00056413 0.00332166 @L5Dispatch 5 0.00078 0.00216607 -0.000715 0 0 0 0.004615 @L5RegDispatch 5 6e-08 0.00312693 -0.004422 0 0 0 0.0044223 @L60Dispatch 5 -0.0006936 0.00155094 -0.003468 0 0 0 0 @L6Dispatch 5 -0.00069372 15.8944 -20 -4.33 0 0 24.3265 @NetExport 5 -0.000290892 0.00397442 -0.00463117 -0.003894 -0.000218443 0.00320717 0.00408198 @R5Dispatch 5 0.00100694 0.00162969 0 0 0 0.0012887 0.003746 @R5RegDispatch 5 -0.00199996 0.00238176 -0.00499952 -0.0041116 -0.00088866 0 0 @R60Dispatch 5 0.0015334 0.00160367 0 0 0.0012887 0.003045 0.0033333 @R6Dispatch 5 0.00153342 0.0016037 0 0 0.0012887 0.003045 0.0033334 @SurplusGeneration 5 0 0 0 0 0 0 0 There is good correspondence with respect to energy prices for the two models - an important requirement if seeking to estimate the contribution of a rebid to a change in dispatch prices. Interconnector solution Summary statistics are also presented for interconnector solution metrics. key count mean std min 25% 50% 75% max @Deficit 6 0 0 0 0 0 0 0 @Flow 6 1.66667e-06 4.08248e-06 0 0 0 0 1e-05 @Losses 6 -1.66667e-07 3.14494e-06 -4e-06 -2.625e-06 -2.5e-07 2.425e-06 3.6e-06 Validation summary Close correpsondence is observed between the Dispatch API's solution and outputs obtained from NEMDE, suggesting it is appropriate to undertake counterfactual scenario analysis for the interval in question. Contribution of rebid to region price change The bid for BW01 at 4.15pm is compared with the bid at 4.20pm in the following table. 2020-11-27 16:15:00 2020-11-27 16:20:00 Difference (MW) MAXAVAIL 590 460 -130 BANDAVAIL1 330 330 0 BANDAVAIL2 0 0 0 BANDAVAIL3 0 0 0 BANDAVAIL4 330 330 0 BANDAVAIL5 0 0 0 BANDAVAIL6 0 0 0 BANDAVAIL7 0 0 0 BANDAVAIL8 0 0 0 BANDAVAIL9 40 40 0 BANDAVAIL10 0 0 0 The case file corresponding to the 4.20pm dispatch interval is updated such that the bid for BW01 applying at 4.15pm also applies at 4.20pm (the MaxAvail parameter for BW01 is set to 590MW for the 4.20pm case file). The Dispatch API is used to run the augmented case file, with region solution metrics corresponding to this scenario shown in the following table. @RegionID @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 288.246 9184.13 0 9820.01 -635.875 0 183 129 92 40.125 1 61 51.9093 35.3844 9808.92 QLD1 278.971 7879.54 0 7538.32 341.223 0 72.3333 28.3333 49.2037 47.5659 5 5 5 25 7537.47 SA1 329.865 1922.82 0 2315.5 -392.685 0 155 170 103 198 175 106 90 50 2319.48 TAS1 75.5221 1523.41 0 1090.25 433.166 0 14.603 14.603 0 0 24.3265 72.0265 50.3846 50 1106.66 VIC1 299.5 7223.44 10 6930.94 282.501 0 112.241 195.241 79.2413 64.3091 15 82 55 49.6156 6960.81 The Dispatch API is then used to run the base case scenario in which no changes are made to the historical case file. Note excellent correspondence was observed between NEMDE and Dispatch API energy prices in the model validation section. Region solution results for the base case are shown below. @RegionID @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 290.951 9171.51 0 9820.01 -648.5 0 183 129 92 40.125 1 61 51.9093 35.3844 9808.69 QLD1 281.589 7879.54 0 7538.32 341.223 0 72.3333 28.3333 49.2037 47.5659 5 5 5 25 7537.47 SA1 329.865 1922.82 0 2315.5 -392.685 0 155 170 103 198 175 106 90 50 2319.48 TAS1 73.1068 1523.41 0 1090.25 433.166 0 14.603 14.603 0 0 24.3265 72.0265 50.3846 50 1106.66 VIC1 299.5 7235.69 10 6930.94 294.744 0 112.241 195.241 79.2413 64.3091 15 82 55 49.6156 6960.66 The difference between the counterfactual scenario and the base case is as follows. @RegionID @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 -2.7049 12.625 0 0 12.625 0 0 0 0 0 0 0 0 0 0.225084 QLD1 -2.61786 0 0 0 0 0 0 0 0 0 0 0 0 0 0 SA1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 TAS1 2.41522 0 0 0 0 0 0 0 0 0 0 0 0 0 0 VIC1 0 -12.2435 0 0 -12.2435 0 0 0 0 0 0 0 0 0 0.156414 The analysis suggests the rebid led to slightly higher prices in New South Wales and Queensland, but reduced prices in Tasmania. These price differences are small relative to the magnitude of the price spike, suggesting the rebid made by BW01 was not a determinative factor in the large price change observed. Summary The Dispatch API has been used to estimate dispatch prices that would arise if BW01 had not rebid its max availability. Model validation is first performed to assess the Dispatch API's ability to emulate NEMDE outputs for the dispatch interval in question, with close correspondence between the Dispatch API's solution and NEMDE outputs observed. A counterfactual scenario is then constructed which assumes no reduction in max availablity for BW01 at 4.20pm. This scenario is compared with the base case in which BW01 does rebid its capacity, with the results suggesting the rebid has a negligible impact on prices at 4:20pm - it is likely other factors, unrelated to the rebid submitted by BW01, are driving the price movement in this dispatch interval.","title":"Rebid Analysis"},{"location":"case-studies/rebid-analysis/rebid-analysis/#rebid-analysis","text":"The following sections demonstrate how the Dispatch API can be used estimate the contribution of a rebid to a change in dispatch prices.","title":"Rebid Analysis"},{"location":"case-studies/rebid-analysis/rebid-analysis/#overview","text":"On 27 November 2020 at 4.15pm the dispatch price in NSW was approximately 96 $/MWh. Dispatch prices increased to 290 $/MWh in the following interval at 4.20pm before falling to 93 $/MWh at 4.25pm. Approximately 2 minutes before the interval in which the price spike occurred a unit at Bayswater power station (trader ID BW01) submitted a rebid which indicated the unit's max available capacity was 130 MW less than previously anticipated. The following figure plots the power output and max availability for this unit, along with NSW dispatch prices. When analysing historical data it is difficult to estimate the extent to which a change in max availbility for BW01 contributed to the price movement at 4.20pm. The Dispatch API addresses this limitation by allowing users to estimate dispatch outcomes under counterfactual scenarios. For instance, a scenario can be constructed in which BW01 does not reduce its max availability at 4.20pm. Dispatch prices for this scenario can then be compared to historical outputs. As all other system parameters are kept constant, it is possible to isolate the rebid's contribution to the change in dispatch prices.","title":"Overview"},{"location":"case-studies/rebid-analysis/rebid-analysis/#aims-and-scope","text":"The following analysis investigates how the rebid submitted by BW01 impacted dispatch prices observed at 4.20pm on 27 Novermber 2020. First, model validation is undertaken to assess the Dispatch API's ability to emulate NEMDE outputs for the interval under investigation. If close correspondence is observed between Dispatch API and NEMDE solutions then counterfactual scenarios will be constructed to estimate dispatch prices that would have arisen if BW01 had not rebid its capacity.","title":"Aims and scope"},{"location":"case-studies/rebid-analysis/rebid-analysis/#validation","text":"Historical NEMDE case files include the outputs returned by NEMDE when run for a given set of inputs describing the NEM's state. Model validation is performed by passing the same parameters to the Dispatch API as were passed to NEMDE, and comparing the Dispatch API's solution to historical NEMDE outputs. The degree to which solutions obtained from the Dispatch API correspond with NEMDE outputs indicates the Dispatch API's ability to emulate NEMDE for the dispatch interval under investigation. If close correspondence between the two solutions is observed then it is appropriate to proceed with the counterfactual scenario analysis. The following sections summarise the difference between the results obtained from the Dispatch API and historical NEMDE outputs for the dispatch interval ending at 4.20pm on 27 November 2020 - the interval for which the price spike is observed.","title":"Validation"},{"location":"case-studies/rebid-analysis/rebid-analysis/#trader-solution","text":"Summary statistics are computed for the difference between the Dispatch API's solution and NEMDE outputs, with the difference defined as follows: Solution Difference = Dispatch API Solution - NEMDE Solution. Statistics for the difference between the trader solution obtained from the Dispatch API and NEMDE are shown below. key count mean std min 25% 50% 75% max @EnergyTarget 340 4.92941e-08 1.20878e-06 -4.24e-06 0 0 0 2e-05 @FSTargetMode 74 0.0135135 0.116248 0 0 0 0 1 @L5RegTarget 340 8.82353e-10 1.69762e-07 -2e-06 0 0 0 2.4e-06 @L5RegViolation 340 0 0 0 0 0 0 0 @L5Target 340 5.22458e-18 3.84048e-07 -5e-06 0 0 0 5e-06 @L5Violation 340 0 0 0 0 0 0 0 @L60Target 340 5.88235e-09 2.42822e-07 -2e-06 0 0 0 4e-06 @L60Violation 340 0 0 0 0 0 0 0 @L6Target 340 4.11765e-09 1.51806 -20 0 0 0 17.9348 @L6Violation 340 0 0 0 0 0 0 0 @R5RegTarget 340 6.47059e-10 1.16308e-07 -1.6e-06 0 0 0 1.34e-06 @R5RegViolation 340 0 0 0 0 0 0 0 @R5Target 340 -1.55882e-08 2.27902e-07 -4e-06 0 0 0 0 @R5Violation 340 0 0 0 0 0 0 0 @R60Target 340 2.05882e-08 0.397291 -5.17241 0 0 0 5.17241 @R60Violation 340 0 0 0 0 0 0 0 @R6Target 340 -8.52941e-09 3.7803e-07 -3.3e-06 0 0 0 5e-06 @R6Violation 340 0 0 0 0 0 0 0 @RampDnRate 325 -0.000115572 0.000664364 -0.00499714 0 0 0 0.00286621 @RampUpRate 325 -0.000129432 0.000710994 -0.00499714 0 0 0 0.00229698 The following figures visualise the correspondence between the dispatch targets obtained from the Dispatch API and those returned by NEMDE for each trade type. Each point represents a dispatch target for a given trader. The horizontal axis denotes the solution obtained from the Dispatch API, while the vertical axis denotes the solution obtained from NEMDE. The dashed line has a slope of one, and indicates perfect correspondence between the Dispatch API and NEMDE solutions. There is excellent correpondence between the two models with respect to dispatch targets. The symmetric dispersion of points around the dashed line for the L6Target is likely due to the absence of tie-breaking constraints for FCAS offers.","title":"Trader solution"},{"location":"case-studies/rebid-analysis/rebid-analysis/#region-solution","text":"Summary statistics are presented for region solution metrics. key count mean std min 25% 50% 75% max @ClearedDemand 5 0.00134777 0.00385127 -0.00432637 -0.000960905 0.00368311 0.00372296 0.00462005 @DispatchedGeneration 5 -0.000654648 0.002728 -0.004063 -0.0026 -0.00066124 0.002015 0.002036 @DispatchedLoad 5 0 0 0 0 0 0 0 @EnergyPrice 5 5.38e-05 0.0001203 0 0 0 0 0.000269 @FixedDemand 5 -0.000361337 0.00269196 -0.00409289 -0.00115808 -0.000441503 0.00056413 0.00332166 @L5Dispatch 5 0.00078 0.00216607 -0.000715 0 0 0 0.004615 @L5RegDispatch 5 6e-08 0.00312693 -0.004422 0 0 0 0.0044223 @L60Dispatch 5 -0.0006936 0.00155094 -0.003468 0 0 0 0 @L6Dispatch 5 -0.00069372 15.8944 -20 -4.33 0 0 24.3265 @NetExport 5 -0.000290892 0.00397442 -0.00463117 -0.003894 -0.000218443 0.00320717 0.00408198 @R5Dispatch 5 0.00100694 0.00162969 0 0 0 0.0012887 0.003746 @R5RegDispatch 5 -0.00199996 0.00238176 -0.00499952 -0.0041116 -0.00088866 0 0 @R60Dispatch 5 0.0015334 0.00160367 0 0 0.0012887 0.003045 0.0033333 @R6Dispatch 5 0.00153342 0.0016037 0 0 0.0012887 0.003045 0.0033334 @SurplusGeneration 5 0 0 0 0 0 0 0 There is good correspondence with respect to energy prices for the two models - an important requirement if seeking to estimate the contribution of a rebid to a change in dispatch prices.","title":"Region solution"},{"location":"case-studies/rebid-analysis/rebid-analysis/#interconnector-solution","text":"Summary statistics are also presented for interconnector solution metrics. key count mean std min 25% 50% 75% max @Deficit 6 0 0 0 0 0 0 0 @Flow 6 1.66667e-06 4.08248e-06 0 0 0 0 1e-05 @Losses 6 -1.66667e-07 3.14494e-06 -4e-06 -2.625e-06 -2.5e-07 2.425e-06 3.6e-06","title":"Interconnector solution"},{"location":"case-studies/rebid-analysis/rebid-analysis/#validation-summary","text":"Close correpsondence is observed between the Dispatch API's solution and outputs obtained from NEMDE, suggesting it is appropriate to undertake counterfactual scenario analysis for the interval in question.","title":"Validation summary"},{"location":"case-studies/rebid-analysis/rebid-analysis/#contribution-of-rebid-to-region-price-change","text":"The bid for BW01 at 4.15pm is compared with the bid at 4.20pm in the following table. 2020-11-27 16:15:00 2020-11-27 16:20:00 Difference (MW) MAXAVAIL 590 460 -130 BANDAVAIL1 330 330 0 BANDAVAIL2 0 0 0 BANDAVAIL3 0 0 0 BANDAVAIL4 330 330 0 BANDAVAIL5 0 0 0 BANDAVAIL6 0 0 0 BANDAVAIL7 0 0 0 BANDAVAIL8 0 0 0 BANDAVAIL9 40 40 0 BANDAVAIL10 0 0 0 The case file corresponding to the 4.20pm dispatch interval is updated such that the bid for BW01 applying at 4.15pm also applies at 4.20pm (the MaxAvail parameter for BW01 is set to 590MW for the 4.20pm case file). The Dispatch API is used to run the augmented case file, with region solution metrics corresponding to this scenario shown in the following table. @RegionID @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 288.246 9184.13 0 9820.01 -635.875 0 183 129 92 40.125 1 61 51.9093 35.3844 9808.92 QLD1 278.971 7879.54 0 7538.32 341.223 0 72.3333 28.3333 49.2037 47.5659 5 5 5 25 7537.47 SA1 329.865 1922.82 0 2315.5 -392.685 0 155 170 103 198 175 106 90 50 2319.48 TAS1 75.5221 1523.41 0 1090.25 433.166 0 14.603 14.603 0 0 24.3265 72.0265 50.3846 50 1106.66 VIC1 299.5 7223.44 10 6930.94 282.501 0 112.241 195.241 79.2413 64.3091 15 82 55 49.6156 6960.81 The Dispatch API is then used to run the base case scenario in which no changes are made to the historical case file. Note excellent correspondence was observed between NEMDE and Dispatch API energy prices in the model validation section. Region solution results for the base case are shown below. @RegionID @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 290.951 9171.51 0 9820.01 -648.5 0 183 129 92 40.125 1 61 51.9093 35.3844 9808.69 QLD1 281.589 7879.54 0 7538.32 341.223 0 72.3333 28.3333 49.2037 47.5659 5 5 5 25 7537.47 SA1 329.865 1922.82 0 2315.5 -392.685 0 155 170 103 198 175 106 90 50 2319.48 TAS1 73.1068 1523.41 0 1090.25 433.166 0 14.603 14.603 0 0 24.3265 72.0265 50.3846 50 1106.66 VIC1 299.5 7235.69 10 6930.94 294.744 0 112.241 195.241 79.2413 64.3091 15 82 55 49.6156 6960.66 The difference between the counterfactual scenario and the base case is as follows. @RegionID @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 -2.7049 12.625 0 0 12.625 0 0 0 0 0 0 0 0 0 0.225084 QLD1 -2.61786 0 0 0 0 0 0 0 0 0 0 0 0 0 0 SA1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 TAS1 2.41522 0 0 0 0 0 0 0 0 0 0 0 0 0 0 VIC1 0 -12.2435 0 0 -12.2435 0 0 0 0 0 0 0 0 0 0.156414 The analysis suggests the rebid led to slightly higher prices in New South Wales and Queensland, but reduced prices in Tasmania. These price differences are small relative to the magnitude of the price spike, suggesting the rebid made by BW01 was not a determinative factor in the large price change observed.","title":"Contribution of rebid to region price change"},{"location":"case-studies/rebid-analysis/rebid-analysis/#summary","text":"The Dispatch API has been used to estimate dispatch prices that would arise if BW01 had not rebid its max availability. Model validation is first performed to assess the Dispatch API's ability to emulate NEMDE outputs for the dispatch interval in question, with close correspondence between the Dispatch API's solution and NEMDE outputs observed. A counterfactual scenario is then constructed which assumes no reduction in max availablity for BW01 at 4.20pm. This scenario is compared with the base case in which BW01 does rebid its capacity, with the results suggesting the rebid has a negligible impact on prices at 4:20pm - it is likely other factors, unrelated to the rebid submitted by BW01, are driving the price movement in this dispatch interval.","title":"Summary"},{"location":"model-validation/202011/model-validation/","text":"Model validation Historical NEMDE case files contain the inputs passed to the NEMDE, along with the outputs (dispatch targets and prices) returned by the program. Backtesting involves passing these same data to the Dispatch API's model and then comparing the outputs to those returned by the NEMDE. The degree to which the Dispatch API's solutions correspond to NEMDE outputs gives an indication as to the model's accuracy - the smaller the difference, the more accurate the approximation. Sample Backtests are performed for all dispatch intervals between 2020-11-01 4:05:00 and 2020-12-01 4:00:00 (8640 dispatch intervals in total). Metrics Unless otherwise specified, summary statistics are computed for the difference between the Dispatch API's solution and NEMDE outputs, with the solution difference given by the following formula Solution difference = Model solution - NEMDE solution. Tables presenting summary statistics consist of columns corresponding to the key for which the solution difference has been computed, while rows display different metrics, the definitions of which are given in the following table: Name Description count Sample size mean Mean value std Standard deviation min Minimum value in sample X % X percentile max Maxiumum value in sample The raw data used to generate the following summary statistics can be downloaded here . Period solution Summary statistics for aggregate constraint violations and objective function values are shown in the following table. @TotalFastStartViolation @TotalGenericViolation @TotalInterconnectorViolation @TotalMNSPCapacityViolation @TotalMNSPOfferViolation @TotalMNSPRampRateViolation @TotalObjective @TotalRampRateViolation @TotalUIGFViolation @TotalUnitMWCapacityViolation count 8640 8640 8640 8640 8640 8640 8640 8640 8640 8640 mean -2.66204e-09 -3.94163e-05 0 0 0 0 21604.9 0.000784722 -3.56428e-07 1.38405e-06 std 1.70432e-07 0.06064 0 0 0 0 977610 0.0518644 5.60465e-05 9.27706e-05 min -1.3e-05 -5.12495 0 0 0 0 -2906.24 -3.51e-06 -0.0005 -0.00050139 0.1% 0 -0.000499 0 0 0 0 -49.0013 0 -0.000491361 -0.00049817 1% 0 -0.000336013 0 0 0 0 -35.5117 0 -0.000244 -0.000401464 10% 0 0 0 0 0 0 -19.8157 0 0 -5.4932e-06 25% 0 0 0 0 0 0 -16.7323 0 0 -1.526e-06 50% 0 0 0 0 0 0 -14.3888 0 0 0 75% 0 0 0 0 0 0 -12.7336 0 0 3.05e-06 90% 0 0 0 0 0 0 -11.2564 0 0 1.53129e-05 99% 0 0.000320183 0 0 0 0 3.51863 0 0.000238 0.000415138 99.9% 0 0.0005 0 0 0 0 856.863 0 0.0004939 0.000498936 max 0 1.56666 0 0 0 0 6.49689e+07 3.75001 0.0005 0.00050153 The @TotalObjective metric is of particular interest. Small perturbations to input parameters or constraint formulations can lead to large changes in the objective function's value at optimality. As there can be considerable variability with respect to the magnitude of this metric additional context is provided by normalising the difference using the following formula: Normalised Difference = (Dispatch API Total Objective - NEMDE Total Objective) / NEMDE Total Objective . Summary statistics for this normalised metric are shown below: @TotalObjectiveNormalisedDifference count 8640 mean -0.00120053 std 0.0897907 min -6.57816 0.1% -8.19001e-05 1% -4.5126e-06 10% -4.69115e-07 25% -3.98848e-08 50% 1.14175e-06 75% 1.51136e-06 90% 1.94025e-06 99% 6.20242e-06 99.9% 0.000120712 max 2.33033 The mean relative difference is -0.12%, suggesting excellent correspondence for a vast majority of the dispatch intervals investigated. The following histograms plot the normalised difference. Figure 1a indicates excellent correspondence between the Dispatch API's solution and the NEMDE solution. Outliers are identified for approximately seven dispatch intervals (0.081% of the sample), which are resolved in Figure 1b. Regions The difference between region solutions obtained from the Dispatch API and NEMDE are shown in the following table: @ClearedDemand @DispatchedGeneration @DispatchedLoad @EnergyPrice @FixedDemand @L5Dispatch @L5RegDispatch @L60Dispatch @L6Dispatch @NetExport @R5Dispatch @R5RegDispatch @R60Dispatch @R6Dispatch @SurplusGeneration count 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 mean -0.00104562 -0.00106376 -0.000813725 28.6958 -1.40473e-06 0.000650245 -0.000693923 -0.00038178 -0.0466299 -0.000215906 -0.390474 -6.63012e-05 -0.000222241 -0.00119391 0 std 0.185128 0.485221 0.145322 3232.45 0.00288172 0.463755 0.793445 0.367114 3.23334 0.501924 5.74301 0.375522 5.02648 1.37914 0 min -26.6615 -42.1148 -28 -449.565 -0.00499974 -28.0018 -20 -18.823 -55.4723 -42.107 -102.559 -15.7004 -75.3844 -32.7827 0 0.1% -0.0565752 -0.00819657 -0.00406594 -0.0044204 -0.00498888 -5 -10 -4.12015 -25 -0.0137336 -59 -3.68602 -46.0901 -13.9506 0 1% -0.00491602 -0.0049712 -2e-06 -0.00095801 -0.00489918 -0.00482201 -0.00499952 -0.004797 -14.9977 -0.00491321 -24 -0.005 -19.5606 -3.99976 0 10% -0.00399913 -0.004 0 -5e-05 -0.00399597 -0.0018103 -2e-06 -0.002078 -0.003333 -0.00394509 -0.00497246 -0.0023333 -0.00442946 -0.00358525 0 25% -0.00244773 -0.00252178 0 -2e-06 -0.00249715 0 0 0 0 -0.00233497 -0.000172 0 -0.000643147 -0.00013415 0 50% 2.93107e-05 1.725e-05 0 0 -1.90567e-05 0 0 0 0 0 0 0 0 0 0 75% 0.00252805 0.00253 0 3e-06 0.00247741 0 0 0 0.000475325 0.00243253 0 0 0 0 0 90% 0.00406472 0.004015 0 0.000181 0.00400988 0.00191068 2e-06 0.00207637 0.003333 0.00401836 0.00412814 0.00180679 0.003544 0.0033011 0 99% 0.00495861 0.00498101 0.000765991 0.00174 0.0048998 0.0048305 0.0049928 0.0048049 13 0.00495717 13 0.0048983 19.56 4 0 99.9% 0.034818 0.0370505 0.00377879 0.00953348 0.0049877 5 10 3.974 21.5878 0.0368679 42 3.63741 46.0934 13.5238 0 max 11.0937 35.3238 2.85348 572603 0.00499912 28 20 21.72 53.0024 35.3321 61 30.0033 65.3625 44.8793 0 The @EnergyPrice metric is of particular interest. The mean difference for this metric is relatively high, yet excellent corresponce is reported over the 0.1-99.9th percentiles, suggesting outliers are responsible for this discrepancy. These outliers likely correspond to dispatch intervals when constraint violation penalty factors set prices. Note the Dispatch API does not ajdust prices to the price floor or ceiling if these thresholds are exceeded. Interconnectors Summary statistics for the difference between interconnector solutions obtained from the Dispatch API and NEMDE outputs are shown in the following table: @Deficit @Flow @Losses count 51840 51840 51840 mean 0 0.00318055 -0.000197088 std 0 1.53926 0.175861 min 0 -148.801 -21.5008 0.1% 0 -0.0308726 -0.00162513 1% 0 -5e-06 -5e-06 10% 0 0 -4e-06 25% 0 0 -2.68e-06 50% 0 0 0 75% 0 0 2.5e-06 90% 0 0 3.95e-06 99% 0 5.627e-06 5e-06 99.9% 0 0.0193116 0.0320136 max 0 160 16.2771 Traders Summary statistics for the difference between trader solutions obtained from the Dispatch API and outputs reported by the NEMDE are shown below: @EnergyTarget @FSTargetMode @L5RegTarget @L5RegViolation @L5Target @L5Violation @L60Target @L60Violation @L6Target @L6Violation @R5RegTarget @R5RegViolation @R5Target @R5Violation @R60Target @R60Violation @R6Target @R6Violation @RampDnRate @RampUpRate count 2.91048e+06 639360 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.78328e+06 2.78328e+06 mean -2.78505e-05 0.00141235 -1.00648e-05 -3.43587e-06 9.7026e-06 -1.37435e-06 -5.73738e-06 -1.37435e-06 -0.00069639 -2.74869e-06 -3.61178e-08 -1.37435e-06 -0.00579463 -1.37435e-06 -1.13507e-06 -1.37435e-06 -1.64888e-05 -1.37435e-06 -0.000125728 -0.000138799 std 0.187107 0.172947 0.258997 0.00586163 0.532339 0.00117232 0.735048 0.00117232 0.530282 0.0026214 0.300822 0.00117232 1.63017 0.00117232 0.969267 0.00117232 0.637123 0.00117232 0.000727952 0.000808648 min -99.9589 -3 -50.0001 -10 -77.5019 -1 -91.7043 -1 -44.8113 -4 -49.5063 -1 -96.2397 -1 -99.3684 -1 -41.3333 -1 -0.005 -0.005 0.1% -5e-06 -2 -3 0 -3.8649 0 -5 0 -5 0 -2 0 -19.2345 0 -10 0 -7.81775 0 -0.005 -0.005 1% -2e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -0.00374714 -0.00376144 10% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 25% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 50% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 75% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 90% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99% 2e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1.43051e-06 2.86102e-06 99.9% 5e-06 4 3 0 3.91676 0 5 0 5 0 2 0 15.5191 0 8.98624 0 6.70383 0 0.00472534 0.00499995 max 79.983 4 43.6 0 87.3195 0 116.54 0 45.5015 0 50.0001 0 102.2 0 117 0 53.4618 0 0.00499995 0.00499995 Energy market dispatch targets obtained from the Dispatch API correpsond closely to those within NEMDE outputs, illustrated by the following histograms: Figure 2a demonstrates excellent correpsondence between @EnergyTarget solutions obtained from the Dispatch API and NEMDE outputs. Material differences are only observed for a small proportion of observations, which are shown in Figure 2b where a log scale has been used for the y-axis. Reasons for differences Differences between solutions obtained from the Dispatch API and the NEMDE may be due to several factors. As the Dispatch API is an approximation of the NEMDE, it is possible omitted features may give rise to these differences. However, there are also other factors, unrelated to model accuracy, that may explain some of these discrepancies. For instance, there is no guarantee the dispatch solution produced by the NEMDE is unique - it is possible an alternative combination of dispatch targets could meet demand and satisfy network constraints at the same cost . Such situations may arise when the marginal unit of demand can be satisfied by multiple generators, each having the same offer price. The following stylised example illustrates the concept. Consider a simple system with only two generators that have the following marginal costs and offer quantities. Generator Marginal Cost ($/MWh) Offer (MW) A 20 100 B 30 80 Assume system demand is 120 MW and there are no network constraints. The market operator seeks to dispatch these generators such that demand is met at the lowest cost. In this scenario Generator A would be dispatched first (as it is the cheaper unit), followed by Generator B for the portion of demand that cannot be met by Generator A. This would lead to the following dispatch targets: Generator Target (MW) A 100 B 20 The solution here is unique - the market operator will always seek to use the cheaper unit (Generator A) to the greatest extent possible before moving on to more expensive units. But what happens if two units have the same marginal cost? For example: Generator Marginal Cost ($/MWh) Offer (MW) A 20 100 B 20 80 How should the market operator decide upon dispatch targets for each generator? So long as total generation meets demand, the market operator is indifferent as to how generation targets are allocated to each unit - the total cost will always be the same, and the dispatch solution is no longer unique. The NEMDE addresses the issue of price-tied generators by using a tie-breaking model which seeks to dispatch price-tied generators in proportion to their offer quantities. In the example above, this feature of the NEMDE would motivate the following dispatch outcomes: Generator Target (MW) A (100 / 180) * 120 = 66.67 B (80 / 180) * 120 = 53.33 While a tie-breaking model is used in the energy market, the NEMDE does not apply a tie-breaking model to offers made in FCAS markets . Consequently, there is no guarantee the NEMDE will return a unique FCAS solution. This means identical formulations of the NEMDE run on different computers may return different results. Factors such as solver settings, floating point precision, and even computer hardware may result in different dispatch targets. This can make it difficult to interpret the differences observed when reviewing backtest results as discrepancies could be due to innaccuraricies in the approximated model, or a result of innate mathematical properties associated with the NEMDE's formulation. Summary Backtest results demonstrate close correspondence between solutions obtained from the Dispatch API and NEMDE outputs. Consilience can be observed in the evidence presented as multiple solution attributes are in excellent agreement. However, there are a handful of dispatch intervals for which outliers exist. These may due to deficiencies in the model used by the Dispatch API, or a consequence of innate properties relating to the NEMDE's mathematical formulation. Additional diagnostic analysis is underway to identify the cause of these discrepancies, which will inform efforts to further improve the Dispatch API's performance.","title":"Model validation"},{"location":"model-validation/202011/model-validation/#model-validation","text":"Historical NEMDE case files contain the inputs passed to the NEMDE, along with the outputs (dispatch targets and prices) returned by the program. Backtesting involves passing these same data to the Dispatch API's model and then comparing the outputs to those returned by the NEMDE. The degree to which the Dispatch API's solutions correspond to NEMDE outputs gives an indication as to the model's accuracy - the smaller the difference, the more accurate the approximation.","title":"Model validation"},{"location":"model-validation/202011/model-validation/#sample","text":"Backtests are performed for all dispatch intervals between 2020-11-01 4:05:00 and 2020-12-01 4:00:00 (8640 dispatch intervals in total).","title":"Sample"},{"location":"model-validation/202011/model-validation/#metrics","text":"Unless otherwise specified, summary statistics are computed for the difference between the Dispatch API's solution and NEMDE outputs, with the solution difference given by the following formula Solution difference = Model solution - NEMDE solution. Tables presenting summary statistics consist of columns corresponding to the key for which the solution difference has been computed, while rows display different metrics, the definitions of which are given in the following table: Name Description count Sample size mean Mean value std Standard deviation min Minimum value in sample X % X percentile max Maxiumum value in sample The raw data used to generate the following summary statistics can be downloaded here .","title":"Metrics"},{"location":"model-validation/202011/model-validation/#period-solution","text":"Summary statistics for aggregate constraint violations and objective function values are shown in the following table. @TotalFastStartViolation @TotalGenericViolation @TotalInterconnectorViolation @TotalMNSPCapacityViolation @TotalMNSPOfferViolation @TotalMNSPRampRateViolation @TotalObjective @TotalRampRateViolation @TotalUIGFViolation @TotalUnitMWCapacityViolation count 8640 8640 8640 8640 8640 8640 8640 8640 8640 8640 mean -2.66204e-09 -3.94163e-05 0 0 0 0 21604.9 0.000784722 -3.56428e-07 1.38405e-06 std 1.70432e-07 0.06064 0 0 0 0 977610 0.0518644 5.60465e-05 9.27706e-05 min -1.3e-05 -5.12495 0 0 0 0 -2906.24 -3.51e-06 -0.0005 -0.00050139 0.1% 0 -0.000499 0 0 0 0 -49.0013 0 -0.000491361 -0.00049817 1% 0 -0.000336013 0 0 0 0 -35.5117 0 -0.000244 -0.000401464 10% 0 0 0 0 0 0 -19.8157 0 0 -5.4932e-06 25% 0 0 0 0 0 0 -16.7323 0 0 -1.526e-06 50% 0 0 0 0 0 0 -14.3888 0 0 0 75% 0 0 0 0 0 0 -12.7336 0 0 3.05e-06 90% 0 0 0 0 0 0 -11.2564 0 0 1.53129e-05 99% 0 0.000320183 0 0 0 0 3.51863 0 0.000238 0.000415138 99.9% 0 0.0005 0 0 0 0 856.863 0 0.0004939 0.000498936 max 0 1.56666 0 0 0 0 6.49689e+07 3.75001 0.0005 0.00050153 The @TotalObjective metric is of particular interest. Small perturbations to input parameters or constraint formulations can lead to large changes in the objective function's value at optimality. As there can be considerable variability with respect to the magnitude of this metric additional context is provided by normalising the difference using the following formula: Normalised Difference = (Dispatch API Total Objective - NEMDE Total Objective) / NEMDE Total Objective . Summary statistics for this normalised metric are shown below: @TotalObjectiveNormalisedDifference count 8640 mean -0.00120053 std 0.0897907 min -6.57816 0.1% -8.19001e-05 1% -4.5126e-06 10% -4.69115e-07 25% -3.98848e-08 50% 1.14175e-06 75% 1.51136e-06 90% 1.94025e-06 99% 6.20242e-06 99.9% 0.000120712 max 2.33033 The mean relative difference is -0.12%, suggesting excellent correspondence for a vast majority of the dispatch intervals investigated. The following histograms plot the normalised difference. Figure 1a indicates excellent correspondence between the Dispatch API's solution and the NEMDE solution. Outliers are identified for approximately seven dispatch intervals (0.081% of the sample), which are resolved in Figure 1b.","title":"Period solution"},{"location":"model-validation/202011/model-validation/#regions","text":"The difference between region solutions obtained from the Dispatch API and NEMDE are shown in the following table: @ClearedDemand @DispatchedGeneration @DispatchedLoad @EnergyPrice @FixedDemand @L5Dispatch @L5RegDispatch @L60Dispatch @L6Dispatch @NetExport @R5Dispatch @R5RegDispatch @R60Dispatch @R6Dispatch @SurplusGeneration count 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 mean -0.00104562 -0.00106376 -0.000813725 28.6958 -1.40473e-06 0.000650245 -0.000693923 -0.00038178 -0.0466299 -0.000215906 -0.390474 -6.63012e-05 -0.000222241 -0.00119391 0 std 0.185128 0.485221 0.145322 3232.45 0.00288172 0.463755 0.793445 0.367114 3.23334 0.501924 5.74301 0.375522 5.02648 1.37914 0 min -26.6615 -42.1148 -28 -449.565 -0.00499974 -28.0018 -20 -18.823 -55.4723 -42.107 -102.559 -15.7004 -75.3844 -32.7827 0 0.1% -0.0565752 -0.00819657 -0.00406594 -0.0044204 -0.00498888 -5 -10 -4.12015 -25 -0.0137336 -59 -3.68602 -46.0901 -13.9506 0 1% -0.00491602 -0.0049712 -2e-06 -0.00095801 -0.00489918 -0.00482201 -0.00499952 -0.004797 -14.9977 -0.00491321 -24 -0.005 -19.5606 -3.99976 0 10% -0.00399913 -0.004 0 -5e-05 -0.00399597 -0.0018103 -2e-06 -0.002078 -0.003333 -0.00394509 -0.00497246 -0.0023333 -0.00442946 -0.00358525 0 25% -0.00244773 -0.00252178 0 -2e-06 -0.00249715 0 0 0 0 -0.00233497 -0.000172 0 -0.000643147 -0.00013415 0 50% 2.93107e-05 1.725e-05 0 0 -1.90567e-05 0 0 0 0 0 0 0 0 0 0 75% 0.00252805 0.00253 0 3e-06 0.00247741 0 0 0 0.000475325 0.00243253 0 0 0 0 0 90% 0.00406472 0.004015 0 0.000181 0.00400988 0.00191068 2e-06 0.00207637 0.003333 0.00401836 0.00412814 0.00180679 0.003544 0.0033011 0 99% 0.00495861 0.00498101 0.000765991 0.00174 0.0048998 0.0048305 0.0049928 0.0048049 13 0.00495717 13 0.0048983 19.56 4 0 99.9% 0.034818 0.0370505 0.00377879 0.00953348 0.0049877 5 10 3.974 21.5878 0.0368679 42 3.63741 46.0934 13.5238 0 max 11.0937 35.3238 2.85348 572603 0.00499912 28 20 21.72 53.0024 35.3321 61 30.0033 65.3625 44.8793 0 The @EnergyPrice metric is of particular interest. The mean difference for this metric is relatively high, yet excellent corresponce is reported over the 0.1-99.9th percentiles, suggesting outliers are responsible for this discrepancy. These outliers likely correspond to dispatch intervals when constraint violation penalty factors set prices. Note the Dispatch API does not ajdust prices to the price floor or ceiling if these thresholds are exceeded.","title":"Regions"},{"location":"model-validation/202011/model-validation/#interconnectors","text":"Summary statistics for the difference between interconnector solutions obtained from the Dispatch API and NEMDE outputs are shown in the following table: @Deficit @Flow @Losses count 51840 51840 51840 mean 0 0.00318055 -0.000197088 std 0 1.53926 0.175861 min 0 -148.801 -21.5008 0.1% 0 -0.0308726 -0.00162513 1% 0 -5e-06 -5e-06 10% 0 0 -4e-06 25% 0 0 -2.68e-06 50% 0 0 0 75% 0 0 2.5e-06 90% 0 0 3.95e-06 99% 0 5.627e-06 5e-06 99.9% 0 0.0193116 0.0320136 max 0 160 16.2771","title":"Interconnectors"},{"location":"model-validation/202011/model-validation/#traders","text":"Summary statistics for the difference between trader solutions obtained from the Dispatch API and outputs reported by the NEMDE are shown below: @EnergyTarget @FSTargetMode @L5RegTarget @L5RegViolation @L5Target @L5Violation @L60Target @L60Violation @L6Target @L6Violation @R5RegTarget @R5RegViolation @R5Target @R5Violation @R60Target @R60Violation @R6Target @R6Violation @RampDnRate @RampUpRate count 2.91048e+06 639360 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.91048e+06 2.78328e+06 2.78328e+06 mean -2.78505e-05 0.00141235 -1.00648e-05 -3.43587e-06 9.7026e-06 -1.37435e-06 -5.73738e-06 -1.37435e-06 -0.00069639 -2.74869e-06 -3.61178e-08 -1.37435e-06 -0.00579463 -1.37435e-06 -1.13507e-06 -1.37435e-06 -1.64888e-05 -1.37435e-06 -0.000125728 -0.000138799 std 0.187107 0.172947 0.258997 0.00586163 0.532339 0.00117232 0.735048 0.00117232 0.530282 0.0026214 0.300822 0.00117232 1.63017 0.00117232 0.969267 0.00117232 0.637123 0.00117232 0.000727952 0.000808648 min -99.9589 -3 -50.0001 -10 -77.5019 -1 -91.7043 -1 -44.8113 -4 -49.5063 -1 -96.2397 -1 -99.3684 -1 -41.3333 -1 -0.005 -0.005 0.1% -5e-06 -2 -3 0 -3.8649 0 -5 0 -5 0 -2 0 -19.2345 0 -10 0 -7.81775 0 -0.005 -0.005 1% -2e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -0.00374714 -0.00376144 10% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 25% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 50% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 75% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 90% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99% 2e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1.43051e-06 2.86102e-06 99.9% 5e-06 4 3 0 3.91676 0 5 0 5 0 2 0 15.5191 0 8.98624 0 6.70383 0 0.00472534 0.00499995 max 79.983 4 43.6 0 87.3195 0 116.54 0 45.5015 0 50.0001 0 102.2 0 117 0 53.4618 0 0.00499995 0.00499995 Energy market dispatch targets obtained from the Dispatch API correpsond closely to those within NEMDE outputs, illustrated by the following histograms: Figure 2a demonstrates excellent correpsondence between @EnergyTarget solutions obtained from the Dispatch API and NEMDE outputs. Material differences are only observed for a small proportion of observations, which are shown in Figure 2b where a log scale has been used for the y-axis.","title":"Traders"},{"location":"model-validation/202011/model-validation/#reasons-for-differences","text":"Differences between solutions obtained from the Dispatch API and the NEMDE may be due to several factors. As the Dispatch API is an approximation of the NEMDE, it is possible omitted features may give rise to these differences. However, there are also other factors, unrelated to model accuracy, that may explain some of these discrepancies. For instance, there is no guarantee the dispatch solution produced by the NEMDE is unique - it is possible an alternative combination of dispatch targets could meet demand and satisfy network constraints at the same cost . Such situations may arise when the marginal unit of demand can be satisfied by multiple generators, each having the same offer price. The following stylised example illustrates the concept. Consider a simple system with only two generators that have the following marginal costs and offer quantities. Generator Marginal Cost ($/MWh) Offer (MW) A 20 100 B 30 80 Assume system demand is 120 MW and there are no network constraints. The market operator seeks to dispatch these generators such that demand is met at the lowest cost. In this scenario Generator A would be dispatched first (as it is the cheaper unit), followed by Generator B for the portion of demand that cannot be met by Generator A. This would lead to the following dispatch targets: Generator Target (MW) A 100 B 20 The solution here is unique - the market operator will always seek to use the cheaper unit (Generator A) to the greatest extent possible before moving on to more expensive units. But what happens if two units have the same marginal cost? For example: Generator Marginal Cost ($/MWh) Offer (MW) A 20 100 B 20 80 How should the market operator decide upon dispatch targets for each generator? So long as total generation meets demand, the market operator is indifferent as to how generation targets are allocated to each unit - the total cost will always be the same, and the dispatch solution is no longer unique. The NEMDE addresses the issue of price-tied generators by using a tie-breaking model which seeks to dispatch price-tied generators in proportion to their offer quantities. In the example above, this feature of the NEMDE would motivate the following dispatch outcomes: Generator Target (MW) A (100 / 180) * 120 = 66.67 B (80 / 180) * 120 = 53.33 While a tie-breaking model is used in the energy market, the NEMDE does not apply a tie-breaking model to offers made in FCAS markets . Consequently, there is no guarantee the NEMDE will return a unique FCAS solution. This means identical formulations of the NEMDE run on different computers may return different results. Factors such as solver settings, floating point precision, and even computer hardware may result in different dispatch targets. This can make it difficult to interpret the differences observed when reviewing backtest results as discrepancies could be due to innaccuraricies in the approximated model, or a result of innate mathematical properties associated with the NEMDE's formulation.","title":"Reasons for differences"},{"location":"model-validation/202011/model-validation/#summary","text":"Backtest results demonstrate close correspondence between solutions obtained from the Dispatch API and NEMDE outputs. Consilience can be observed in the evidence presented as multiple solution attributes are in excellent agreement. However, there are a handful of dispatch intervals for which outliers exist. These may due to deficiencies in the model used by the Dispatch API, or a consequence of innate properties relating to the NEMDE's mathematical formulation. Additional diagnostic analysis is underway to identify the cause of these discrepancies, which will inform efforts to further improve the Dispatch API's performance.","title":"Summary"},{"location":"model-validation/202104/model-validation/","text":"Model validation Historical NEMDE case files contain the inputs passed to the NEMDE, along with the outputs (dispatch targets and prices) returned by the program. Backtesting involves passing these same data to the Dispatch API's model and then comparing the outputs to those returned by the NEMDE. The degree to which the Dispatch API's solutions correspond to NEMDE outputs gives an indication as to the model's accuracy - the smaller the difference, the more accurate the approximation. Sample Backtests are performed for all dispatch intervals between 2021-04-01 4:05:00 and 2021-05-01 4:00:00 (8640 dispatch intervals in total). Metrics Unless otherwise specified, summary statistics are computed for the difference between the Dispatch API's solution and NEMDE outputs, with the solution difference given by the following formula Solution difference = Model solution - NEMDE solution. Tables presenting summary statistics consist of columns corresponding to the key for which the solution difference has been computed, while rows display different metrics, the definitions of which are given in the following table: Name Description count Sample size mean Mean value std Standard deviation min Minimum value in sample X % X percentile max Maxiumum value in sample The raw data used to generate the following summary statistics can be downloaded here . Period solution Summary statistics for aggregate constraint violations and objective function values are shown in the following table. @TotalFastStartViolation @TotalGenericViolation @TotalInterconnectorViolation @TotalMNSPCapacityViolation @TotalMNSPOfferViolation @TotalMNSPRampRateViolation @TotalObjective @TotalRampRateViolation @TotalUIGFViolation @TotalUnitMWCapacityViolation count 8640 8640 8640 8640 8640 8640 8640 8640 8640 8640 mean -5.78704e-10 -0.000230032 0 0 0 0 -5.24741 -2.87037e-08 -4.6573e-07 -1.49676e-06 std 3.87875e-08 0.0213337 0 0 0 0 804.892 2.66806e-06 5.65038e-05 0.000107749 min -3e-06 -1.983 0 0 0 0 -8196.99 -0.000248 -0.0005 -0.0005 0.1% 0 -0.000482083 0 0 0 0 -46.2393 0 -0.000494 -0.000499 1% 0 -1.8e-05 0 0 0 0 -34.3667 0 -0.00025 -0.000440561 10% 0 0 0 0 0 0 -20.0326 0 0 -8e-06 25% 0 0 0 0 0 0 -17.5938 0 0 -3.59e-06 50% 0 0 0 0 0 0 -15.3853 0 0 0 75% 0 0 0 0 0 0 -13.1249 0 0 0 90% 0 0 0 0 0 0 -11.3609 0 0 8e-06 99% 0 1.2122e-05 0 0 0 0 7.45146 0 0.0002439 0.000426899 99.9% 0 0.000423971 0 0 0 0 706.385 0 0.000493936 0.000494574 max 0 0.0004973 0 0 0 0 74021.6 0 0.0005 0.00050146 The @TotalObjective metric is of particular interest. Small perturbations to input parameters or constraint formulations can lead to large changes in the objective function's value at optimality. As there can be considerable variability with respect to the magnitude of this metric additional context is provided by normalising the difference using the following formula: Normalised Difference = (Dispatch API Total Objective - NEMDE Total Objective) / NEMDE Total Objective . Summary statistics for this normalised metric are shown below: @TotalObjectiveNormalisedDifference count 8640 mean 8.7459e-07 std 2.13632e-05 min -0.000545912 0.1% -6.55193e-05 1% -3.78768e-06 10% -3.54142e-07 25% -4.97563e-08 50% 1.04533e-06 75% 1.38992e-06 90% 1.74495e-06 99% 6.26676e-06 99.9% 4.17993e-05 max 0.00120749 The mean relative difference is 0.000087%, suggesting excellent correspondence for a vast majority of the dispatch intervals investigated. The following histograms plot the normalised difference. /home/compo/miniconda3/envs/dispatch-api-tutorials/lib/python3.9/site-packages/pandas/plotting/_matplotlib/tools.py:400: MatplotlibDeprecationWarning: The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead. if ax.is_first_col(): Regions The difference between region solutions obtained from the Dispatch API and NEMDE are shown in the following table: @ClearedDemand @DispatchedGeneration @DispatchedLoad @EnergyPrice @FixedDemand @L5Dispatch @L5RegDispatch @L60Dispatch @L6Dispatch @NetExport @R5Dispatch @R5RegDispatch @R60Dispatch @R6Dispatch @SurplusGeneration count 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 mean -0.00726389 -0.00724513 0.000256479 -0.0549102 -1.28787e-05 -0.0469272 7.34422e-06 -0.0928329 -0.0659896 -0.0075605 -0.181868 -0.000211147 -0.0129342 0.000143315 0 std 0.230423 3.11459 0.0441242 4.28704 0.00288432 1.5733 0.742168 1.95298 7.22621 3.12331 5.11396 0.771209 3.09734 1.77893 0 min -15.8901 -170.276 -5 -576.211 -0.00499998 -72 -40 -62 -70 -170.278 -117 -33 -84 -46 0 0.1% -2.89466 -20.0235 -0.00360901 -6.61755 -0.00499061 -21.0438 -9 -43.801 -40.0042 -21.1914 -65.0777 -9.40064 -30.9064 -18.9885 0 1% -0.0049563 -0.00497 0 -0.00136307 -0.0049087 -1.71042 -0.00499952 -0.00487 -25 -0.00492488 -10.0038 -0.0049756 -9.99378 -3 0 10% -0.00404488 -0.004 0 -2.23e-05 -0.00399141 -0.0016932 -2e-06 -0.0019 -0.004616 -0.003945 -0.003317 -0.00089856 -0.0039411 -0.0033334 0 25% -0.00249697 -0.00248 0 -1e-06 -0.0025206 0 0 0 0 -0.00230016 0 0 -0.000548 0 0 50% 3.69658e-05 4.335e-05 0 0 -1.47997e-05 0 0 0 0 -5.52071e-05 0 0 0 0 0 75% 0.00255456 0.00259803 0 4e-06 0.00246805 0 0 0 0 0.00244 0 0 0.000228425 0 0 90% 0.00409419 0.00406955 0 0.00024791 0.00399658 0.00149863 2e-06 0.00201015 0.00416214 0.00401877 0.003097 0.0007324 0.003333 0.0031746 0 99% 0.00594889 0.00553584 0 0.00150106 0.00490659 0.796617 0.005 0.0048288 29.6966 0.00627672 10 0.0049268 8.96169 2.22 0 99.9% 0.307791 18.8761 0.00317649 0.0632088 0.00499133 9.25666 9 0.005 49.5024 18.8804 39 9.5 30.0037 23.9121 0 max 8.62209 205.594 5 85.3612 0.00499974 23 55 23.16 70 205.593 100 33 50.5 46.0023 0 Interconnectors Summary statistics for the difference between interconnector solutions obtained from the Dispatch API and NEMDE outputs are shown in the following table: @Deficit @Flow @Losses count 51840 51840 51840 mean 0 0.043914 -0.00630429 std 0 3.57264 0.340097 min 0 -188.532 -27.7887 0.1% 0 -9.47514 -2.74303 1% 0 -1e-05 -5e-06 10% 0 0 -4e-06 25% 0 0 -2.5e-06 50% 0 0 0 75% 0 0 2.2625e-06 90% 0 0 3.95e-06 99% 0 1e-05 0.00911366 99.9% 0 29.9524 0.401957 max 0 215.551 22.8728 Traders Summary statistics for the difference between trader solutions obtained from the Dispatch API and outputs reported by the NEMDE are shown below: @EnergyTarget @FSTargetMode @L5RegTarget @L5RegViolation @L5Target @L5Violation @L60Target @L60Violation @L6Target @L6Violation @R5RegTarget @R5RegViolation @R5Target @R5Violation @R60Target @R60Violation @R6Target @R6Violation @RampDnRate @RampUpRate count 3.0648e+06 630694 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 2.90928e+06 2.90928e+06 mean -9.88134e-05 0.00117965 -1.03417e-09 0 -0.000661336 0 -0.00130888 0 -0.000930919 0 -2.73462e-06 0 -0.00256321 0 -0.000180932 0 2.43402e-06 0 -0.000100076 -9.80774e-05 std 0.390342 0.166714 0.310275 0 0.795769 0 1.1752 0 1.06659 0 0.31334 0 1.25552 0 0.722973 0 0.591007 0 0.000727775 0.0007142 min -146.461 -4 -50.0001 0 -116.757 0 -124.716 0 -115.321 0 -36.707 0 -107.657 0 -92.4525 0 -33 0 -0.005 -0.005 0.1% -7.12462e-06 -1 -2 0 -3.93637 0 -6.73891 0 -14 0 -1.34313 0 -13.4952 0 -5.71423 0 -5 0 -0.00499993 -0.00499993 1% -1.1e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -0.00372711 -0.00372711 10% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 25% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 50% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 75% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 90% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99% 1e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9.15527e-05 5.72205e-06 99.9% 5.5603e-06 4 1.89784 0 3.75162 0 6.26603 0 12 0 1.4188 0 10 0 5.74791 0 5 0 0.00497025 0.00499995 max 175 4 50.0001 0 80 0 124 0 68.1516 0 42.375 0 83.5758 0 97.5939 0 49.5355 0 0.00499828 0.00499996 Energy market dispatch targets obtained from the Dispatch API correpsond closely to those within NEMDE outputs, illustrated by the following histograms:","title":"Model validation"},{"location":"model-validation/202104/model-validation/#model-validation","text":"Historical NEMDE case files contain the inputs passed to the NEMDE, along with the outputs (dispatch targets and prices) returned by the program. Backtesting involves passing these same data to the Dispatch API's model and then comparing the outputs to those returned by the NEMDE. The degree to which the Dispatch API's solutions correspond to NEMDE outputs gives an indication as to the model's accuracy - the smaller the difference, the more accurate the approximation.","title":"Model validation"},{"location":"model-validation/202104/model-validation/#sample","text":"Backtests are performed for all dispatch intervals between 2021-04-01 4:05:00 and 2021-05-01 4:00:00 (8640 dispatch intervals in total).","title":"Sample"},{"location":"model-validation/202104/model-validation/#metrics","text":"Unless otherwise specified, summary statistics are computed for the difference between the Dispatch API's solution and NEMDE outputs, with the solution difference given by the following formula Solution difference = Model solution - NEMDE solution. Tables presenting summary statistics consist of columns corresponding to the key for which the solution difference has been computed, while rows display different metrics, the definitions of which are given in the following table: Name Description count Sample size mean Mean value std Standard deviation min Minimum value in sample X % X percentile max Maxiumum value in sample The raw data used to generate the following summary statistics can be downloaded here .","title":"Metrics"},{"location":"model-validation/202104/model-validation/#period-solution","text":"Summary statistics for aggregate constraint violations and objective function values are shown in the following table. @TotalFastStartViolation @TotalGenericViolation @TotalInterconnectorViolation @TotalMNSPCapacityViolation @TotalMNSPOfferViolation @TotalMNSPRampRateViolation @TotalObjective @TotalRampRateViolation @TotalUIGFViolation @TotalUnitMWCapacityViolation count 8640 8640 8640 8640 8640 8640 8640 8640 8640 8640 mean -5.78704e-10 -0.000230032 0 0 0 0 -5.24741 -2.87037e-08 -4.6573e-07 -1.49676e-06 std 3.87875e-08 0.0213337 0 0 0 0 804.892 2.66806e-06 5.65038e-05 0.000107749 min -3e-06 -1.983 0 0 0 0 -8196.99 -0.000248 -0.0005 -0.0005 0.1% 0 -0.000482083 0 0 0 0 -46.2393 0 -0.000494 -0.000499 1% 0 -1.8e-05 0 0 0 0 -34.3667 0 -0.00025 -0.000440561 10% 0 0 0 0 0 0 -20.0326 0 0 -8e-06 25% 0 0 0 0 0 0 -17.5938 0 0 -3.59e-06 50% 0 0 0 0 0 0 -15.3853 0 0 0 75% 0 0 0 0 0 0 -13.1249 0 0 0 90% 0 0 0 0 0 0 -11.3609 0 0 8e-06 99% 0 1.2122e-05 0 0 0 0 7.45146 0 0.0002439 0.000426899 99.9% 0 0.000423971 0 0 0 0 706.385 0 0.000493936 0.000494574 max 0 0.0004973 0 0 0 0 74021.6 0 0.0005 0.00050146 The @TotalObjective metric is of particular interest. Small perturbations to input parameters or constraint formulations can lead to large changes in the objective function's value at optimality. As there can be considerable variability with respect to the magnitude of this metric additional context is provided by normalising the difference using the following formula: Normalised Difference = (Dispatch API Total Objective - NEMDE Total Objective) / NEMDE Total Objective . Summary statistics for this normalised metric are shown below: @TotalObjectiveNormalisedDifference count 8640 mean 8.7459e-07 std 2.13632e-05 min -0.000545912 0.1% -6.55193e-05 1% -3.78768e-06 10% -3.54142e-07 25% -4.97563e-08 50% 1.04533e-06 75% 1.38992e-06 90% 1.74495e-06 99% 6.26676e-06 99.9% 4.17993e-05 max 0.00120749 The mean relative difference is 0.000087%, suggesting excellent correspondence for a vast majority of the dispatch intervals investigated. The following histograms plot the normalised difference. /home/compo/miniconda3/envs/dispatch-api-tutorials/lib/python3.9/site-packages/pandas/plotting/_matplotlib/tools.py:400: MatplotlibDeprecationWarning: The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead. if ax.is_first_col():","title":"Period solution"},{"location":"model-validation/202104/model-validation/#regions","text":"The difference between region solutions obtained from the Dispatch API and NEMDE are shown in the following table: @ClearedDemand @DispatchedGeneration @DispatchedLoad @EnergyPrice @FixedDemand @L5Dispatch @L5RegDispatch @L60Dispatch @L6Dispatch @NetExport @R5Dispatch @R5RegDispatch @R60Dispatch @R6Dispatch @SurplusGeneration count 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 43200 mean -0.00726389 -0.00724513 0.000256479 -0.0549102 -1.28787e-05 -0.0469272 7.34422e-06 -0.0928329 -0.0659896 -0.0075605 -0.181868 -0.000211147 -0.0129342 0.000143315 0 std 0.230423 3.11459 0.0441242 4.28704 0.00288432 1.5733 0.742168 1.95298 7.22621 3.12331 5.11396 0.771209 3.09734 1.77893 0 min -15.8901 -170.276 -5 -576.211 -0.00499998 -72 -40 -62 -70 -170.278 -117 -33 -84 -46 0 0.1% -2.89466 -20.0235 -0.00360901 -6.61755 -0.00499061 -21.0438 -9 -43.801 -40.0042 -21.1914 -65.0777 -9.40064 -30.9064 -18.9885 0 1% -0.0049563 -0.00497 0 -0.00136307 -0.0049087 -1.71042 -0.00499952 -0.00487 -25 -0.00492488 -10.0038 -0.0049756 -9.99378 -3 0 10% -0.00404488 -0.004 0 -2.23e-05 -0.00399141 -0.0016932 -2e-06 -0.0019 -0.004616 -0.003945 -0.003317 -0.00089856 -0.0039411 -0.0033334 0 25% -0.00249697 -0.00248 0 -1e-06 -0.0025206 0 0 0 0 -0.00230016 0 0 -0.000548 0 0 50% 3.69658e-05 4.335e-05 0 0 -1.47997e-05 0 0 0 0 -5.52071e-05 0 0 0 0 0 75% 0.00255456 0.00259803 0 4e-06 0.00246805 0 0 0 0 0.00244 0 0 0.000228425 0 0 90% 0.00409419 0.00406955 0 0.00024791 0.00399658 0.00149863 2e-06 0.00201015 0.00416214 0.00401877 0.003097 0.0007324 0.003333 0.0031746 0 99% 0.00594889 0.00553584 0 0.00150106 0.00490659 0.796617 0.005 0.0048288 29.6966 0.00627672 10 0.0049268 8.96169 2.22 0 99.9% 0.307791 18.8761 0.00317649 0.0632088 0.00499133 9.25666 9 0.005 49.5024 18.8804 39 9.5 30.0037 23.9121 0 max 8.62209 205.594 5 85.3612 0.00499974 23 55 23.16 70 205.593 100 33 50.5 46.0023 0","title":"Regions"},{"location":"model-validation/202104/model-validation/#interconnectors","text":"Summary statistics for the difference between interconnector solutions obtained from the Dispatch API and NEMDE outputs are shown in the following table: @Deficit @Flow @Losses count 51840 51840 51840 mean 0 0.043914 -0.00630429 std 0 3.57264 0.340097 min 0 -188.532 -27.7887 0.1% 0 -9.47514 -2.74303 1% 0 -1e-05 -5e-06 10% 0 0 -4e-06 25% 0 0 -2.5e-06 50% 0 0 0 75% 0 0 2.2625e-06 90% 0 0 3.95e-06 99% 0 1e-05 0.00911366 99.9% 0 29.9524 0.401957 max 0 215.551 22.8728","title":"Interconnectors"},{"location":"model-validation/202104/model-validation/#traders","text":"Summary statistics for the difference between trader solutions obtained from the Dispatch API and outputs reported by the NEMDE are shown below: @EnergyTarget @FSTargetMode @L5RegTarget @L5RegViolation @L5Target @L5Violation @L60Target @L60Violation @L6Target @L6Violation @R5RegTarget @R5RegViolation @R5Target @R5Violation @R60Target @R60Violation @R6Target @R6Violation @RampDnRate @RampUpRate count 3.0648e+06 630694 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 3.0648e+06 2.90928e+06 2.90928e+06 mean -9.88134e-05 0.00117965 -1.03417e-09 0 -0.000661336 0 -0.00130888 0 -0.000930919 0 -2.73462e-06 0 -0.00256321 0 -0.000180932 0 2.43402e-06 0 -0.000100076 -9.80774e-05 std 0.390342 0.166714 0.310275 0 0.795769 0 1.1752 0 1.06659 0 0.31334 0 1.25552 0 0.722973 0 0.591007 0 0.000727775 0.0007142 min -146.461 -4 -50.0001 0 -116.757 0 -124.716 0 -115.321 0 -36.707 0 -107.657 0 -92.4525 0 -33 0 -0.005 -0.005 0.1% -7.12462e-06 -1 -2 0 -3.93637 0 -6.73891 0 -14 0 -1.34313 0 -13.4952 0 -5.71423 0 -5 0 -0.00499993 -0.00499993 1% -1.1e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -0.00372711 -0.00372711 10% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 25% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 50% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 75% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 90% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99% 1e-06 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9.15527e-05 5.72205e-06 99.9% 5.5603e-06 4 1.89784 0 3.75162 0 6.26603 0 12 0 1.4188 0 10 0 5.74791 0 5 0 0.00497025 0.00499995 max 175 4 50.0001 0 80 0 124 0 68.1516 0 42.375 0 83.5758 0 97.5939 0 49.5355 0 0.00499828 0.00499996 Energy market dispatch targets obtained from the Dispatch API correpsond closely to those within NEMDE outputs, illustrated by the following histograms:","title":"Traders"},{"location":"tutorials/converting-a-case-file/","text":"Converting a case file Historical NEMDE case files are easily converted into a format that can be consumed by the Dispatch API by using the following code snippet. import xmltodict def convert_casefile ( path_to_file ): \"\"\"Load a historical NEMDE case file and convert it to a dict\"\"\" # Read case file contents with open ( path_to_file , 'r' ) as f : casefile = f . read () # Force these nodes to always return lists force_list = ( 'Trade' , 'TradeTypePriceStructure' ,) return xmltodict . parse ( casefile , force_list = force_list ) # Example NEMDE case file path_to_file = 'data/NEMSPDOutputs_2020110100100.loaded' # Case file loaded as a Python dictionary converted_casefile = convert_casefile ( path_to_file = path_to_file ) converted_casefile . get ( 'NEMSPDCaseFile' ) . keys () odict_keys(['NemSpdInputs', 'NemSpdOutputs', 'SolutionAnalysis']) Note that historical case files have a .loaded suffix, with data within these files organised in XML format.","title":"Converting a case file"},{"location":"tutorials/converting-a-case-file/#converting-a-case-file","text":"Historical NEMDE case files are easily converted into a format that can be consumed by the Dispatch API by using the following code snippet. import xmltodict def convert_casefile ( path_to_file ): \"\"\"Load a historical NEMDE case file and convert it to a dict\"\"\" # Read case file contents with open ( path_to_file , 'r' ) as f : casefile = f . read () # Force these nodes to always return lists force_list = ( 'Trade' , 'TradeTypePriceStructure' ,) return xmltodict . parse ( casefile , force_list = force_list ) # Example NEMDE case file path_to_file = 'data/NEMSPDOutputs_2020110100100.loaded' # Case file loaded as a Python dictionary converted_casefile = convert_casefile ( path_to_file = path_to_file ) converted_casefile . get ( 'NEMSPDCaseFile' ) . keys () odict_keys(['NemSpdInputs', 'NemSpdOutputs', 'SolutionAnalysis']) Note that historical case files have a .loaded suffix, with data within these files organised in XML format.","title":"Converting a case file"},{"location":"tutorials/modifying-a-case-file/","text":"Modifying a case file The Dispatch API allows users to perform numerical experiments. By augmenting a selected case file parameter, while keeping all other parameters constant, the relationship between dispatch outcomes and the parameter under investigation can be examined. The following sections discuss strategies that can be used to modify case files. While this notebook uses Python, it's possible to use other programming languages and workflows. The Dispatch API simply expects data in JSON format - so long as the inputs are correctly structured, the API is agnostic as to the technology used to edit and submit the case file. Imports and authentication import os import json import requests import pandas as pd from dotenv import load_dotenv from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # A valid API token must be included when making requests headers = { 'Authorization' : f 'Token { TOKEN } ' } # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/' Approach Case files contain tens of thousands of parameters. While it's possible to design a completely customised case file, users should note the Dispatch API expects case files to be submitted in a standard format. Errors introduced when constructing a case file will almost certainly result in the model failing to return a solution. For now let's use data from a historical case file and only modify selected components. We can proceed by first downloading a case file via the Dispatch API. def download_casefile ( base_url , headers , case_id ): \"\"\" Download a case file Parameters ---------- base_url : str Base URL for the Dispatch API headers : dict Contains auth token used to authenticate requests case_id : str Case ID to download e.g. '20201101001'. The format is as follows {year}{month}{day}{interval_id} where interval_id is in [001, ..., 288] Returns ------- casefile : dict Parameters describing the system's state \"\"\" url = base_url + f 'data/casefile/ { case_id } ' print ( \"Case file endpoint\" , url ) response = requests . get ( url = url , headers = headers ) # Load JSON response as Python dictionary casefile = response . json () return casefile # Download case file and save it to disk case_id = '20201101001' casefile = download_casefile ( base_url = base_url , headers = headers , case_id = case_id ) Case file endpoint https://dispatch.envector.com/api/v1/data/casefile/20201101001 Method 1 - Traverse dictionary The simplest strategy is to traverse the case file dictionary and update parameters directly. The parameter reference page can be used to see which parameters can be meaningfully updated. Let's update the Demand Forecast ( @DF ) parameter for South Australia as an example. This parameter corresponds to the amount by which demand is expected to change over the dispatch interval. From the parameter reference page we can see the path to this parameter is as follows: NEMSPDCaseFile.NemSpdInputs.PeriodCollection.Period.RegionPeriodCollection.RegionPeriod[?(@RegionID=\"{region_id}\")].@DF Using this path we can traverse nodes within the dictionary: regions = ( casefile . get ( 'NEMSPDCaseFile' ) . get ( 'NemSpdInputs' ) . get ( 'PeriodCollection' ) . get ( 'Period' ) . get ( 'RegionPeriodCollection' ) . get ( 'RegionPeriod' )) regions [{'@RegionID': 'NSW1', '@DF': '-6.88232421875', '@DemandForecast': '5661.46337890625', '@Suspension_Schedule_Energy_Price': '35.88', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'QLD1', '@DF': '10.572998046875', '@DemandForecast': '5113.60864257812', '@Suspension_Schedule_Energy_Price': '29.97', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '5.22', '@Suspension_Schedule_L60_Price': '7.35', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'SA1', '@DF': '0.441221952438354', '@DemandForecast': '1096.76959109306', '@Suspension_Schedule_Energy_Price': '22.08', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'TAS1', '@DF': '3.51705932617188', '@DemandForecast': '950.733245849609', '@Suspension_Schedule_Energy_Price': '40.55', '@Suspension_Schedule_R6_Price': '3.42', '@Suspension_Schedule_R60_Price': '2.92', '@Suspension_Schedule_R5_Price': '0.9', '@Suspension_Schedule_RReg_Price': '8.6', '@Suspension_Schedule_L6_Price': '1.56', '@Suspension_Schedule_L60_Price': '1.17', '@Suspension_Schedule_L5_Price': '0.78', '@Suspension_Schedule_LReg_Price': '4.17'}, {'@RegionID': 'VIC1', '@DF': '15.550048828125', '@DemandForecast': '3611.78051757812', '@Suspension_Schedule_Energy_Price': '18.48', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}] Once we reach the RegionPeriod node we encounter a list of dictionaries describing parameters for each region. We can loop through the list and update the @DF parameter for South Australia (i.e. the dictionary with @RegionID == 'SA1' ). # Updating the @DF parameter for South Australia for i in regions : if i . get ( '@RegionID' ) == 'SA1' : i [ '@DF' ] = 20 Note: By default all values within a case file are of type 'string'. Strings, floats or integers can be used when updating case file parameters as types are converted in a preprocessing step before formulating a mathematical program from the inputs. Strings should be used when updating flags e.g. parameters that take on a value of '1' or '0'. Checking the value has been updated. ( casefile . get ( 'NEMSPDCaseFile' ) . get ( 'NemSpdInputs' ) . get ( 'PeriodCollection' ) . get ( 'Period' ) . get ( 'RegionPeriodCollection' ) . get ( 'RegionPeriod' )) [{'@RegionID': 'NSW1', '@DF': '-6.88232421875', '@DemandForecast': '5661.46337890625', '@Suspension_Schedule_Energy_Price': '35.88', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'QLD1', '@DF': '10.572998046875', '@DemandForecast': '5113.60864257812', '@Suspension_Schedule_Energy_Price': '29.97', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '5.22', '@Suspension_Schedule_L60_Price': '7.35', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'SA1', '@DF': 20, '@DemandForecast': '1096.76959109306', '@Suspension_Schedule_Energy_Price': '22.08', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'TAS1', '@DF': '3.51705932617188', '@DemandForecast': '950.733245849609', '@Suspension_Schedule_Energy_Price': '40.55', '@Suspension_Schedule_R6_Price': '3.42', '@Suspension_Schedule_R60_Price': '2.92', '@Suspension_Schedule_R5_Price': '0.9', '@Suspension_Schedule_RReg_Price': '8.6', '@Suspension_Schedule_L6_Price': '1.56', '@Suspension_Schedule_L60_Price': '1.17', '@Suspension_Schedule_L5_Price': '0.78', '@Suspension_Schedule_LReg_Price': '4.17'}, {'@RegionID': 'VIC1', '@DF': '15.550048828125', '@DemandForecast': '3611.78051757812', '@Suspension_Schedule_Energy_Price': '18.48', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}] Submitting a modified case file The same steps outlined in the previous tutorial can be followed to submit a job using the modified case file. An option can also be included to return the (augmented) case file. def submit_casefile ( base_url , headers , casefile ): \"\"\"Submit case file to job queue\"\"\" # Construct request body and URL body = { 'casefile' : casefile , 'options' : { 'return_casefile' : True } } url = base_url + 'jobs/create' # Send job to queue and return job meta data response = requests . post ( url = url , headers = headers , json = body ) return response . json () # Submit job and inspect job info job_info = submit_casefile ( base_url = base_url , headers = headers , casefile = casefile ) job_info {'job_id': 'ae49d40f-c25f-4107-8bdb-e78c84c3b3d9', 'created_at': '2021-03-29T13:58:43.872325Z', 'enqueued_at': '2021-03-29T13:58:43.983535Z', 'timeout': 180, 'status': 'queued', 'label': None} Once the model has finished solving we can access the results. def get_job_results ( base_url , headers , job_id ): \"\"\"Extract job results from queue\"\"\" url = base_url + f 'jobs/ { job_id } /results' response = requests . get ( url = url , headers = headers ) return response . json () # Get job results from the queue job_id = job_info . get ( 'job_id' ) job_results = get_job_results ( base_url = base_url , headers = headers , job_id = job_id ) The results key returns two nested objects: input corresponds to the case file submitted to the queue, while output is the solution returned by the worker. job_results . get ( 'results' ) . keys () dict_keys(['input', 'output']) We can verify the updated case file was passed to the worker by inspecting the value corresponding to input . ( job_results . get ( 'results' ) . get ( 'input' ) . get ( 'NEMSPDCaseFile' ) . get ( 'NemSpdInputs' ) . get ( 'PeriodCollection' ) . get ( 'Period' ) . get ( 'RegionPeriodCollection' ) . get ( 'RegionPeriod' )) [{'@RegionID': 'NSW1', '@DF': '-6.88232421875', '@DemandForecast': '5661.46337890625', '@Suspension_Schedule_Energy_Price': '35.88', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'QLD1', '@DF': '10.572998046875', '@DemandForecast': '5113.60864257812', '@Suspension_Schedule_Energy_Price': '29.97', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '5.22', '@Suspension_Schedule_L60_Price': '7.35', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'SA1', '@DF': 20, '@DemandForecast': '1096.76959109306', '@Suspension_Schedule_Energy_Price': '22.08', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'TAS1', '@DF': '3.51705932617188', '@DemandForecast': '950.733245849609', '@Suspension_Schedule_Energy_Price': '40.55', '@Suspension_Schedule_R6_Price': '3.42', '@Suspension_Schedule_R60_Price': '2.92', '@Suspension_Schedule_R5_Price': '0.9', '@Suspension_Schedule_RReg_Price': '8.6', '@Suspension_Schedule_L6_Price': '1.56', '@Suspension_Schedule_L60_Price': '1.17', '@Suspension_Schedule_L5_Price': '0.78', '@Suspension_Schedule_LReg_Price': '4.17'}, {'@RegionID': 'VIC1', '@DF': '15.550048828125', '@DemandForecast': '3611.78051757812', '@Suspension_Schedule_Energy_Price': '18.48', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}] We can see our update is reflected in the case file consumed by the worker. Method 2 - Using JSON path syntax While the previous method is quite intuitive, it is not very robust - it's to lose track of which values have been updated when using loops. An alternative is to search and update the case file dictionary using JSON path syntax. Rather than loop through a list, expressions can be specified to find and update specific elements. See jsonpath-ng to learn more about the syntax. An expression targeting the @DF parameter for South Australia can be formulated as follows: # Path to South Australia region period parameters expression = ( \"NEMSPDCaseFile \\ .NemSpdInputs \\ .PeriodCollection \\ .Period \\ .RegionPeriodCollection \\ .RegionPeriod[?(@RegionID=='SA1')] \\ .@DF\" ) Note this expression corresponds to the path outlined on the parameter reference page . When seeking to update parameters users can consult this document to find paths corresponding to parameters of interest. The following functions can be used to get and update parameters using a JSON path expression. def get_casefile_parameter ( casefile , expression ): \"\"\" Get parameter given a case file and JSON path expression Parameters ---------- casefile : dict System parameters expression : str JSON path expression to value or object that should be extracted Returns ------- Value corresponding to JSON path expression. \"\"\" jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( casefile )] # Check only one match found if len ( values ) != 1 : raise Exception ( f 'Expected 1 match, encountered { len ( values ) } ' ) return values [ 0 ] def update_casefile_parameter ( casefile , expression , new_value ): \"\"\" Update case file parameter Parameters ---------- casefile : dict System parameters expression : str JSON path to value or object that should be updated new_value : str, float, or int New value for parameter Returns ------- casefile : dict Updated case file \"\"\" jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( casefile )] # Check only one match found if len ( values ) != 1 : raise Exception ( f 'Expected 1 match, encountered { len ( values ) } ' ) # Update case file jsonpath_expr . update ( casefile , new_value ) return casefile Let's get the value of South Australia's @DF parameter. get_casefile_parameter ( casefile = casefile , expression = expression ) 20 Similarly, we can update values given an expression. # Update @DF parameter for SA1 - set @DF = 60 casefile = update_casefile_parameter ( casefile = casefile , expression = expression , new_value = 60 ) # Check the value has been updated get_casefile_parameter ( casefile = casefile , expression = expression ) 60 Summary We've explored two ways to update case file parameters. The first method can be useful if seeking to explore a case file's structure, and augment parameters in an ad hoc manner. The second method is more precise in its ability to target specific parameters within a case file as it avoids the use of loops. The following tutorials will build upon these tools when conducting scenario analyses using the Dispatch API.","title":"Modifying a case file"},{"location":"tutorials/modifying-a-case-file/#modifying-a-case-file","text":"The Dispatch API allows users to perform numerical experiments. By augmenting a selected case file parameter, while keeping all other parameters constant, the relationship between dispatch outcomes and the parameter under investigation can be examined. The following sections discuss strategies that can be used to modify case files. While this notebook uses Python, it's possible to use other programming languages and workflows. The Dispatch API simply expects data in JSON format - so long as the inputs are correctly structured, the API is agnostic as to the technology used to edit and submit the case file.","title":"Modifying a case file"},{"location":"tutorials/modifying-a-case-file/#imports-and-authentication","text":"import os import json import requests import pandas as pd from dotenv import load_dotenv from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # A valid API token must be included when making requests headers = { 'Authorization' : f 'Token { TOKEN } ' } # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/'","title":"Imports and authentication"},{"location":"tutorials/modifying-a-case-file/#approach","text":"Case files contain tens of thousands of parameters. While it's possible to design a completely customised case file, users should note the Dispatch API expects case files to be submitted in a standard format. Errors introduced when constructing a case file will almost certainly result in the model failing to return a solution. For now let's use data from a historical case file and only modify selected components. We can proceed by first downloading a case file via the Dispatch API. def download_casefile ( base_url , headers , case_id ): \"\"\" Download a case file Parameters ---------- base_url : str Base URL for the Dispatch API headers : dict Contains auth token used to authenticate requests case_id : str Case ID to download e.g. '20201101001'. The format is as follows {year}{month}{day}{interval_id} where interval_id is in [001, ..., 288] Returns ------- casefile : dict Parameters describing the system's state \"\"\" url = base_url + f 'data/casefile/ { case_id } ' print ( \"Case file endpoint\" , url ) response = requests . get ( url = url , headers = headers ) # Load JSON response as Python dictionary casefile = response . json () return casefile # Download case file and save it to disk case_id = '20201101001' casefile = download_casefile ( base_url = base_url , headers = headers , case_id = case_id ) Case file endpoint https://dispatch.envector.com/api/v1/data/casefile/20201101001","title":"Approach"},{"location":"tutorials/modifying-a-case-file/#method-1-traverse-dictionary","text":"The simplest strategy is to traverse the case file dictionary and update parameters directly. The parameter reference page can be used to see which parameters can be meaningfully updated. Let's update the Demand Forecast ( @DF ) parameter for South Australia as an example. This parameter corresponds to the amount by which demand is expected to change over the dispatch interval. From the parameter reference page we can see the path to this parameter is as follows: NEMSPDCaseFile.NemSpdInputs.PeriodCollection.Period.RegionPeriodCollection.RegionPeriod[?(@RegionID=\"{region_id}\")].@DF Using this path we can traverse nodes within the dictionary: regions = ( casefile . get ( 'NEMSPDCaseFile' ) . get ( 'NemSpdInputs' ) . get ( 'PeriodCollection' ) . get ( 'Period' ) . get ( 'RegionPeriodCollection' ) . get ( 'RegionPeriod' )) regions [{'@RegionID': 'NSW1', '@DF': '-6.88232421875', '@DemandForecast': '5661.46337890625', '@Suspension_Schedule_Energy_Price': '35.88', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'QLD1', '@DF': '10.572998046875', '@DemandForecast': '5113.60864257812', '@Suspension_Schedule_Energy_Price': '29.97', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '5.22', '@Suspension_Schedule_L60_Price': '7.35', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'SA1', '@DF': '0.441221952438354', '@DemandForecast': '1096.76959109306', '@Suspension_Schedule_Energy_Price': '22.08', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'TAS1', '@DF': '3.51705932617188', '@DemandForecast': '950.733245849609', '@Suspension_Schedule_Energy_Price': '40.55', '@Suspension_Schedule_R6_Price': '3.42', '@Suspension_Schedule_R60_Price': '2.92', '@Suspension_Schedule_R5_Price': '0.9', '@Suspension_Schedule_RReg_Price': '8.6', '@Suspension_Schedule_L6_Price': '1.56', '@Suspension_Schedule_L60_Price': '1.17', '@Suspension_Schedule_L5_Price': '0.78', '@Suspension_Schedule_LReg_Price': '4.17'}, {'@RegionID': 'VIC1', '@DF': '15.550048828125', '@DemandForecast': '3611.78051757812', '@Suspension_Schedule_Energy_Price': '18.48', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}] Once we reach the RegionPeriod node we encounter a list of dictionaries describing parameters for each region. We can loop through the list and update the @DF parameter for South Australia (i.e. the dictionary with @RegionID == 'SA1' ). # Updating the @DF parameter for South Australia for i in regions : if i . get ( '@RegionID' ) == 'SA1' : i [ '@DF' ] = 20 Note: By default all values within a case file are of type 'string'. Strings, floats or integers can be used when updating case file parameters as types are converted in a preprocessing step before formulating a mathematical program from the inputs. Strings should be used when updating flags e.g. parameters that take on a value of '1' or '0'. Checking the value has been updated. ( casefile . get ( 'NEMSPDCaseFile' ) . get ( 'NemSpdInputs' ) . get ( 'PeriodCollection' ) . get ( 'Period' ) . get ( 'RegionPeriodCollection' ) . get ( 'RegionPeriod' )) [{'@RegionID': 'NSW1', '@DF': '-6.88232421875', '@DemandForecast': '5661.46337890625', '@Suspension_Schedule_Energy_Price': '35.88', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'QLD1', '@DF': '10.572998046875', '@DemandForecast': '5113.60864257812', '@Suspension_Schedule_Energy_Price': '29.97', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '5.22', '@Suspension_Schedule_L60_Price': '7.35', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'SA1', '@DF': 20, '@DemandForecast': '1096.76959109306', '@Suspension_Schedule_Energy_Price': '22.08', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'TAS1', '@DF': '3.51705932617188', '@DemandForecast': '950.733245849609', '@Suspension_Schedule_Energy_Price': '40.55', '@Suspension_Schedule_R6_Price': '3.42', '@Suspension_Schedule_R60_Price': '2.92', '@Suspension_Schedule_R5_Price': '0.9', '@Suspension_Schedule_RReg_Price': '8.6', '@Suspension_Schedule_L6_Price': '1.56', '@Suspension_Schedule_L60_Price': '1.17', '@Suspension_Schedule_L5_Price': '0.78', '@Suspension_Schedule_LReg_Price': '4.17'}, {'@RegionID': 'VIC1', '@DF': '15.550048828125', '@DemandForecast': '3611.78051757812', '@Suspension_Schedule_Energy_Price': '18.48', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}]","title":"Method 1 - Traverse dictionary"},{"location":"tutorials/modifying-a-case-file/#submitting-a-modified-case-file","text":"The same steps outlined in the previous tutorial can be followed to submit a job using the modified case file. An option can also be included to return the (augmented) case file. def submit_casefile ( base_url , headers , casefile ): \"\"\"Submit case file to job queue\"\"\" # Construct request body and URL body = { 'casefile' : casefile , 'options' : { 'return_casefile' : True } } url = base_url + 'jobs/create' # Send job to queue and return job meta data response = requests . post ( url = url , headers = headers , json = body ) return response . json () # Submit job and inspect job info job_info = submit_casefile ( base_url = base_url , headers = headers , casefile = casefile ) job_info {'job_id': 'ae49d40f-c25f-4107-8bdb-e78c84c3b3d9', 'created_at': '2021-03-29T13:58:43.872325Z', 'enqueued_at': '2021-03-29T13:58:43.983535Z', 'timeout': 180, 'status': 'queued', 'label': None} Once the model has finished solving we can access the results. def get_job_results ( base_url , headers , job_id ): \"\"\"Extract job results from queue\"\"\" url = base_url + f 'jobs/ { job_id } /results' response = requests . get ( url = url , headers = headers ) return response . json () # Get job results from the queue job_id = job_info . get ( 'job_id' ) job_results = get_job_results ( base_url = base_url , headers = headers , job_id = job_id ) The results key returns two nested objects: input corresponds to the case file submitted to the queue, while output is the solution returned by the worker. job_results . get ( 'results' ) . keys () dict_keys(['input', 'output']) We can verify the updated case file was passed to the worker by inspecting the value corresponding to input . ( job_results . get ( 'results' ) . get ( 'input' ) . get ( 'NEMSPDCaseFile' ) . get ( 'NemSpdInputs' ) . get ( 'PeriodCollection' ) . get ( 'Period' ) . get ( 'RegionPeriodCollection' ) . get ( 'RegionPeriod' )) [{'@RegionID': 'NSW1', '@DF': '-6.88232421875', '@DemandForecast': '5661.46337890625', '@Suspension_Schedule_Energy_Price': '35.88', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'QLD1', '@DF': '10.572998046875', '@DemandForecast': '5113.60864257812', '@Suspension_Schedule_Energy_Price': '29.97', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '5.22', '@Suspension_Schedule_L60_Price': '7.35', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'SA1', '@DF': 20, '@DemandForecast': '1096.76959109306', '@Suspension_Schedule_Energy_Price': '22.08', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}, {'@RegionID': 'TAS1', '@DF': '3.51705932617188', '@DemandForecast': '950.733245849609', '@Suspension_Schedule_Energy_Price': '40.55', '@Suspension_Schedule_R6_Price': '3.42', '@Suspension_Schedule_R60_Price': '2.92', '@Suspension_Schedule_R5_Price': '0.9', '@Suspension_Schedule_RReg_Price': '8.6', '@Suspension_Schedule_L6_Price': '1.56', '@Suspension_Schedule_L60_Price': '1.17', '@Suspension_Schedule_L5_Price': '0.78', '@Suspension_Schedule_LReg_Price': '4.17'}, {'@RegionID': 'VIC1', '@DF': '15.550048828125', '@DemandForecast': '3611.78051757812', '@Suspension_Schedule_Energy_Price': '18.48', '@Suspension_Schedule_R6_Price': '2.13', '@Suspension_Schedule_R60_Price': '2.79', '@Suspension_Schedule_R5_Price': '0.88', '@Suspension_Schedule_RReg_Price': '7.18', '@Suspension_Schedule_L6_Price': '3.41', '@Suspension_Schedule_L60_Price': '6.04', '@Suspension_Schedule_L5_Price': '4.38', '@Suspension_Schedule_LReg_Price': '9.02'}] We can see our update is reflected in the case file consumed by the worker.","title":"Submitting a modified case file"},{"location":"tutorials/modifying-a-case-file/#method-2-using-json-path-syntax","text":"While the previous method is quite intuitive, it is not very robust - it's to lose track of which values have been updated when using loops. An alternative is to search and update the case file dictionary using JSON path syntax. Rather than loop through a list, expressions can be specified to find and update specific elements. See jsonpath-ng to learn more about the syntax. An expression targeting the @DF parameter for South Australia can be formulated as follows: # Path to South Australia region period parameters expression = ( \"NEMSPDCaseFile \\ .NemSpdInputs \\ .PeriodCollection \\ .Period \\ .RegionPeriodCollection \\ .RegionPeriod[?(@RegionID=='SA1')] \\ .@DF\" ) Note this expression corresponds to the path outlined on the parameter reference page . When seeking to update parameters users can consult this document to find paths corresponding to parameters of interest. The following functions can be used to get and update parameters using a JSON path expression. def get_casefile_parameter ( casefile , expression ): \"\"\" Get parameter given a case file and JSON path expression Parameters ---------- casefile : dict System parameters expression : str JSON path expression to value or object that should be extracted Returns ------- Value corresponding to JSON path expression. \"\"\" jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( casefile )] # Check only one match found if len ( values ) != 1 : raise Exception ( f 'Expected 1 match, encountered { len ( values ) } ' ) return values [ 0 ] def update_casefile_parameter ( casefile , expression , new_value ): \"\"\" Update case file parameter Parameters ---------- casefile : dict System parameters expression : str JSON path to value or object that should be updated new_value : str, float, or int New value for parameter Returns ------- casefile : dict Updated case file \"\"\" jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( casefile )] # Check only one match found if len ( values ) != 1 : raise Exception ( f 'Expected 1 match, encountered { len ( values ) } ' ) # Update case file jsonpath_expr . update ( casefile , new_value ) return casefile Let's get the value of South Australia's @DF parameter. get_casefile_parameter ( casefile = casefile , expression = expression ) 20 Similarly, we can update values given an expression. # Update @DF parameter for SA1 - set @DF = 60 casefile = update_casefile_parameter ( casefile = casefile , expression = expression , new_value = 60 ) # Check the value has been updated get_casefile_parameter ( casefile = casefile , expression = expression ) 60","title":"Method 2 - Using JSON path syntax"},{"location":"tutorials/modifying-a-case-file/#summary","text":"We've explored two ways to update case file parameters. The first method can be useful if seeking to explore a case file's structure, and augment parameters in an ad hoc manner. The second method is more precise in its ability to target specific parameters within a case file as it avoids the use of loops. The following tutorials will build upon these tools when conducting scenario analyses using the Dispatch API.","title":"Summary"},{"location":"tutorials/running-a-model/","text":"Running a model An online queue is used to coordinate the task of formulating and solving mathematical programs. Users submit parameters to the queue via the Dispatch API, which creates a new 'job' within the queue. A pool of 'workers' monitor this queue for new jobs. If a worker is available (i.e. it is not currently processing a job) it will pick the job off the queue and then formulate and solve a mathematical program using the inputs provided. The worker then posts the optimisation model's results back to the queue, and marks the job as 'finished'. Results can then be accessed by the user. This notebook describes how to obtain historical data describing the NEM's state via the Dispatch API, along with the process of submitting a job to, and retrieving results from, the online queue. Imports and authentication import os import json import requests import pandas as pd from dotenv import load_dotenv import IPython.display as display A valid API token is required to use the Dispatch API, and must be included within the headers section of each request. Email contact@envector.com if you would like to arrange a trial. # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # Request headers are used to authenticate users via their access token headers = { 'Authorization' : f 'Token { TOKEN } ' } # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/' Download a case file Case files contain parameters used by the NEMDE when determining dispatch targets for generators and loads. The Dispatch API uses selected inputs from these case files when formulating a mathematical program that approximates the NEMDE's operation (see the parameter reference page for a description of the inputs used). A limited library of case files containing historical data is accessible via the Dispatch API. Each case file is identified by a case ID, e.g. 20201101001 , which has the following format: {year}{month}{day}{interval_id} Interval IDs range from 001-288 and are used to identify each 5 minute interval within a 24 hour period. As each trading day begins at 4.00am, the case ID 20201101001 corresponds to the trading interval which starts at 2020-11-01 04:00:00 and ends at 2020-11-01 04:05:00 . When NEMDE is run at approximately 04:00:00 it produces dispatch targets that generators and loads should meet at 04:05:00 . The following table illustrates the mapping between case IDs and the start and end times for selected dispatch intervals. Case ID Interval start Interval end 20201101001 2020-11-01 04:00:00 2020-11-01 04:05:00 20201101002 2020-11-01 04:05:00 2020-11-01 04:10:00 20201101003 2020-11-01 04:10:00 2020-11-01 04:15:00 ... ... ... 20201101287 2020-11-02 03:50:00 2020-11-02 03:55:00 20201101288 2020-11-02 03:55:00 2020-11-02 04:00:00 The following function downloads a case file, which is returned as a Python dictionary. def download_casefile ( base_url , headers , case_id ): \"\"\" Download a case file Parameters ---------- base_url : str Base URL for the Dispatch API headers : dict Contains auth token used to authenticate requests case_id : str Case ID to download e.g. '20201101001'. The format is as follows {year}{month}{day}{interval_id} where interval_id is in [001, ..., 288] Returns ------- casefile : dict Parameters describing the system's state \"\"\" url = base_url + f 'data/casefile/ { case_id } ' print ( \"Case file endpoint\" , url ) response = requests . get ( url = url , headers = headers ) # Load JSON response as Python dictionary casefile = response . json () return casefile # Download case file and save it to disk case_id = '20201101001' casefile = download_casefile ( base_url = base_url , headers = headers , case_id = case_id ) Case file endpoint https://dispatch.envector.com/api/v1/data/casefile/20201101001 Case file components Case files describe the state of the system at the start of a dispatch interval, and also include forecasts for demand and intermittent generation at the end of the interval. A nested data structure, in this case a Python dictionary, organises data into logical components. Those familiar with NEMDE case files in XML format may recognise the following data structure. In fact, the dictionary is obtained by converting a NEMDE case file in XML format to a Python dictionary. See this tutorial to learn how to convert your own NEMDE XML files into a format that can be consumed by the Dispatch API. At the dictionary's root there is a single key, NEMSPDCaseFile : casefile . keys () dict_keys(['NEMSPDCaseFile']) The dictionary can be traversed by 'getting' the value for a given key, in this case NEMSPDCaseFile , and looking at its constituent components. Here we can see there are three nested keys: casefile . get ( 'NEMSPDCaseFile' ) . keys () dict_keys(['NemSpdInputs', 'NemSpdOutputs', 'SolutionAnalysis']) Key Description NemSpdInputs Parameters describing the system's state NemSpdOutputs NEMDE solution for each trader (generator / load), generic constraint, interconnector, and region SolutionAnalysis Price setting results While NEMDE case files provide a convenient data structure describing parameters used to set dispatch targets, there are a limitations associated with their design. For instance, some parameters are duplicated, while others may be ignored. Users seeking to modify case files should consult the parameter reference page to see which parameters can be meaningfully modified when using the Dispatch API. Submitting a job For now let's run the case file without modifying any of its components. The body of the request is simply a dictionary with \"casefile\" as the key, and the case file dictionay as its corresponding value: body = {\"casefile\": casefile} A POST request is submitted to https://dispatch.envector.com/api/v1/jobs/create The response contains information pertaining to the newly created job, including a job ID which will be used when querying results once they become available. def submit_casefile ( base_url , headers , casefile ): \"\"\"Submit case file to the job queue\"\"\" # Construct request body and URL body = { 'casefile' : casefile } url = base_url + 'jobs/create' # Send job to queue and return job meta data response = requests . post ( url = url , headers = headers , json = body ) return response . json () # Submit job and inspect meta data job_info = submit_casefile ( base_url = base_url , headers = headers , casefile = casefile ) job_info {'job_id': 'b62fbf33-e73a-468e-8d1f-83f3a1f435d1', 'created_at': '2021-03-29T13:46:48.398280Z', 'enqueued_at': '2021-03-29T13:46:48.512861Z', 'timeout': 180, 'status': 'queued', 'label': None} A pool of workers monitor the queue to which the job is posted. If a worker is available it will formulate and run the optimisation model using the inputs provided. Results are then posted back to the queue for retrieval by the user. The following URLs become available once a job has been submitted, allowing users to check the job's status, examine job results, or delete the job: URL Description https://dispatch.envector.com/api/v1/jobs/{job_id}/status Get job status https://dispatch.envector.com/api/v1/jobs/{job_id}/results Get job results https://dispatch.envector.com/api/v1/jobs/{job_id}/delete Delete job For example, if the job ID is 04c66262-6144-444d-98bf-00c21cb955dd , the URL to get the job's status would be: https://dispatch.envector.com/api/v1/jobs/04c66262-6144-444d-98bf-00c21cb955dd/status Let's check the job's status. def check_job_status ( base_url , headers , job_id ): \"\"\"Check job status given a job ID\"\"\" url = base_url + f 'jobs/ { job_id } /status' return requests . get ( url = url , headers = headers ) . json () # Check job status job_id = job_info . get ( 'job_id' ) check_job_status ( base_url = base_url , headers = headers , job_id = job_id ) {'job_id': 'b62fbf33-e73a-468e-8d1f-83f3a1f435d1', 'status': 'started', 'created_at': '2021-03-29T13:46:48.398280', 'enqueued_at': '2021-03-29T13:46:48.512861', 'started_at': '2021-03-29T13:46:48.773524', 'ended_at': None, 'timeout': 180, 'label': None} We can see a worker has started to process the job. It typically takes 30s for a worker to complete a job once started. After waiting a short period we can check the status again. check_job_status ( base_url = base_url , headers = headers , job_id = job_id ) {'job_id': 'b62fbf33-e73a-468e-8d1f-83f3a1f435d1', 'status': 'finished', 'created_at': '2021-03-29T13:46:48.398280', 'enqueued_at': '2021-03-29T13:46:48.512861', 'started_at': '2021-03-29T13:46:48.887061', 'ended_at': '2021-03-29T13:47:13.268052', 'timeout': 180, 'label': None} Retrieving results Once the job has finished we can access its results. def get_job_results ( base_url , headers , job_id ): \"\"\"Extract job results from the queue\"\"\" url = base_url + f 'jobs/ { job_id } /results' response = requests . get ( url = url , headers = headers ) return response . json () # Get job results from the queue results = get_job_results ( base_url = base_url , headers = headers , job_id = job_id ) Note: completed jobs are only retained in the queue for 2 hours, at which point the job (and results) are deleted. The value corresponding to the results key contains the solution reported by the worker. Let's use Pandas to examine the output. region_solution = results . get ( 'results' ) . get ( 'output' ) . get ( 'RegionSolution' ) # Convert to markdown to display results region_solution_md = pd . DataFrame ( region_solution ) . to_markdown ( index = False ) display . Markdown ( region_solution_md ) @RegionID @CaseID @Intervention @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 20201101001 0 41.6999 5818.37 0 5654.29 164.078 0 213 196 68 118.172 112.354 173 78.968 34 5660.54 QLD1 20201101001 0 41.2282 5232.56 0 5113.69 118.868 0 34.9091 34.9091 23 103 0 0 0 40 5113.56 SA1 20201101001 0 45.44 1001.83 0 1096.91 -95.0743 0 115 75 55.5582 79 97 73 67 108 1096.83 TAS1 20201101001 0 44.8781 734.724 0 957.232 -222.507 0 40.4435 59.8479 23.3362 5 23.197 57.8819 52.0513 10 957.232 VIC1 20201101001 0 44.3783 3653.47 15 3596.2 42.2753 0 88.4044 126 59 49.8276 70 76 64 18 3612.8 interconnector_solution = results . get ( 'results' ) . get ( 'output' ) . get ( 'InterconnectorSolution' ) # Convert to markdown to display results interconnector_solution_md = pd . DataFrame ( interconnector_solution ) . to_markdown ( index = False ) display . Markdown ( interconnector_solution_md ) @InterconnectorID @CaseID @Intervention @Flow @Losses @Deficit N-Q-MNSP1 20201101001 0 -33 -0.591673 0 NSW1-QLD1 20201101001 0 -86.0011 0.306671 0 T-V-MNSP1 20201101001 0 -222.507 6.01955 0 V-S-MNSP1 20201101001 0 45 -0.856901 0 V-SA 20201101001 0 50 0.60394 0 VIC1-NSW1 20201101001 0 -276.834 10.8428 0 trader_solution = results . get ( 'results' ) . get ( 'output' ) . get ( 'TraderSolution' ) # Convert to markdown to display results trader_solution_md = pd . DataFrame ( trader_solution ) . head () . to_markdown ( index = False ) display . Markdown ( trader_solution_md ) @TraderID @CaseID @Intervention @EnergyTarget @R6Target @R60Target @R5Target @R5RegTarget @L6Target @L60Target @L5Target @L5RegTarget @R6Violation @R60Violation @R5Violation @R5RegViolation @L6Violation @L60Violation @L5Violation @L5RegViolation @RampUpRate @RampDnRate @FSTargetMode AGLHAL 20201101001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 720 720 0 AGLSOM 20201101001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 360 360 0 ANGAST1 20201101001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 840 840 nan APD01 20201101001 0 0 31 70 30 0 0 0 0 0 0 0 0 0 0 0 0 0 nan nan nan ARWF1 20201101001 0 126.114 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1200 600 nan Summary This tutorial demonstrates the basic functionality of the Dispatch API. Two key components have been introduced: the ability to access historical data using the API, and methods that facilitate interaction with an online queue. Future tutorials will discuss how to modify case files, perform scenario analyses, and also introduce more advanced workflows using additional Dispatch API features.","title":"Running a model"},{"location":"tutorials/running-a-model/#running-a-model","text":"An online queue is used to coordinate the task of formulating and solving mathematical programs. Users submit parameters to the queue via the Dispatch API, which creates a new 'job' within the queue. A pool of 'workers' monitor this queue for new jobs. If a worker is available (i.e. it is not currently processing a job) it will pick the job off the queue and then formulate and solve a mathematical program using the inputs provided. The worker then posts the optimisation model's results back to the queue, and marks the job as 'finished'. Results can then be accessed by the user. This notebook describes how to obtain historical data describing the NEM's state via the Dispatch API, along with the process of submitting a job to, and retrieving results from, the online queue.","title":"Running a model"},{"location":"tutorials/running-a-model/#imports-and-authentication","text":"import os import json import requests import pandas as pd from dotenv import load_dotenv import IPython.display as display A valid API token is required to use the Dispatch API, and must be included within the headers section of each request. Email contact@envector.com if you would like to arrange a trial. # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # Request headers are used to authenticate users via their access token headers = { 'Authorization' : f 'Token { TOKEN } ' } # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/'","title":"Imports and authentication"},{"location":"tutorials/running-a-model/#download-a-case-file","text":"Case files contain parameters used by the NEMDE when determining dispatch targets for generators and loads. The Dispatch API uses selected inputs from these case files when formulating a mathematical program that approximates the NEMDE's operation (see the parameter reference page for a description of the inputs used). A limited library of case files containing historical data is accessible via the Dispatch API. Each case file is identified by a case ID, e.g. 20201101001 , which has the following format: {year}{month}{day}{interval_id} Interval IDs range from 001-288 and are used to identify each 5 minute interval within a 24 hour period. As each trading day begins at 4.00am, the case ID 20201101001 corresponds to the trading interval which starts at 2020-11-01 04:00:00 and ends at 2020-11-01 04:05:00 . When NEMDE is run at approximately 04:00:00 it produces dispatch targets that generators and loads should meet at 04:05:00 . The following table illustrates the mapping between case IDs and the start and end times for selected dispatch intervals. Case ID Interval start Interval end 20201101001 2020-11-01 04:00:00 2020-11-01 04:05:00 20201101002 2020-11-01 04:05:00 2020-11-01 04:10:00 20201101003 2020-11-01 04:10:00 2020-11-01 04:15:00 ... ... ... 20201101287 2020-11-02 03:50:00 2020-11-02 03:55:00 20201101288 2020-11-02 03:55:00 2020-11-02 04:00:00 The following function downloads a case file, which is returned as a Python dictionary. def download_casefile ( base_url , headers , case_id ): \"\"\" Download a case file Parameters ---------- base_url : str Base URL for the Dispatch API headers : dict Contains auth token used to authenticate requests case_id : str Case ID to download e.g. '20201101001'. The format is as follows {year}{month}{day}{interval_id} where interval_id is in [001, ..., 288] Returns ------- casefile : dict Parameters describing the system's state \"\"\" url = base_url + f 'data/casefile/ { case_id } ' print ( \"Case file endpoint\" , url ) response = requests . get ( url = url , headers = headers ) # Load JSON response as Python dictionary casefile = response . json () return casefile # Download case file and save it to disk case_id = '20201101001' casefile = download_casefile ( base_url = base_url , headers = headers , case_id = case_id ) Case file endpoint https://dispatch.envector.com/api/v1/data/casefile/20201101001","title":"Download a case file"},{"location":"tutorials/running-a-model/#case-file-components","text":"Case files describe the state of the system at the start of a dispatch interval, and also include forecasts for demand and intermittent generation at the end of the interval. A nested data structure, in this case a Python dictionary, organises data into logical components. Those familiar with NEMDE case files in XML format may recognise the following data structure. In fact, the dictionary is obtained by converting a NEMDE case file in XML format to a Python dictionary. See this tutorial to learn how to convert your own NEMDE XML files into a format that can be consumed by the Dispatch API. At the dictionary's root there is a single key, NEMSPDCaseFile : casefile . keys () dict_keys(['NEMSPDCaseFile']) The dictionary can be traversed by 'getting' the value for a given key, in this case NEMSPDCaseFile , and looking at its constituent components. Here we can see there are three nested keys: casefile . get ( 'NEMSPDCaseFile' ) . keys () dict_keys(['NemSpdInputs', 'NemSpdOutputs', 'SolutionAnalysis']) Key Description NemSpdInputs Parameters describing the system's state NemSpdOutputs NEMDE solution for each trader (generator / load), generic constraint, interconnector, and region SolutionAnalysis Price setting results While NEMDE case files provide a convenient data structure describing parameters used to set dispatch targets, there are a limitations associated with their design. For instance, some parameters are duplicated, while others may be ignored. Users seeking to modify case files should consult the parameter reference page to see which parameters can be meaningfully modified when using the Dispatch API.","title":"Case file components"},{"location":"tutorials/running-a-model/#submitting-a-job","text":"For now let's run the case file without modifying any of its components. The body of the request is simply a dictionary with \"casefile\" as the key, and the case file dictionay as its corresponding value: body = {\"casefile\": casefile} A POST request is submitted to https://dispatch.envector.com/api/v1/jobs/create The response contains information pertaining to the newly created job, including a job ID which will be used when querying results once they become available. def submit_casefile ( base_url , headers , casefile ): \"\"\"Submit case file to the job queue\"\"\" # Construct request body and URL body = { 'casefile' : casefile } url = base_url + 'jobs/create' # Send job to queue and return job meta data response = requests . post ( url = url , headers = headers , json = body ) return response . json () # Submit job and inspect meta data job_info = submit_casefile ( base_url = base_url , headers = headers , casefile = casefile ) job_info {'job_id': 'b62fbf33-e73a-468e-8d1f-83f3a1f435d1', 'created_at': '2021-03-29T13:46:48.398280Z', 'enqueued_at': '2021-03-29T13:46:48.512861Z', 'timeout': 180, 'status': 'queued', 'label': None} A pool of workers monitor the queue to which the job is posted. If a worker is available it will formulate and run the optimisation model using the inputs provided. Results are then posted back to the queue for retrieval by the user. The following URLs become available once a job has been submitted, allowing users to check the job's status, examine job results, or delete the job: URL Description https://dispatch.envector.com/api/v1/jobs/{job_id}/status Get job status https://dispatch.envector.com/api/v1/jobs/{job_id}/results Get job results https://dispatch.envector.com/api/v1/jobs/{job_id}/delete Delete job For example, if the job ID is 04c66262-6144-444d-98bf-00c21cb955dd , the URL to get the job's status would be: https://dispatch.envector.com/api/v1/jobs/04c66262-6144-444d-98bf-00c21cb955dd/status Let's check the job's status. def check_job_status ( base_url , headers , job_id ): \"\"\"Check job status given a job ID\"\"\" url = base_url + f 'jobs/ { job_id } /status' return requests . get ( url = url , headers = headers ) . json () # Check job status job_id = job_info . get ( 'job_id' ) check_job_status ( base_url = base_url , headers = headers , job_id = job_id ) {'job_id': 'b62fbf33-e73a-468e-8d1f-83f3a1f435d1', 'status': 'started', 'created_at': '2021-03-29T13:46:48.398280', 'enqueued_at': '2021-03-29T13:46:48.512861', 'started_at': '2021-03-29T13:46:48.773524', 'ended_at': None, 'timeout': 180, 'label': None} We can see a worker has started to process the job. It typically takes 30s for a worker to complete a job once started. After waiting a short period we can check the status again. check_job_status ( base_url = base_url , headers = headers , job_id = job_id ) {'job_id': 'b62fbf33-e73a-468e-8d1f-83f3a1f435d1', 'status': 'finished', 'created_at': '2021-03-29T13:46:48.398280', 'enqueued_at': '2021-03-29T13:46:48.512861', 'started_at': '2021-03-29T13:46:48.887061', 'ended_at': '2021-03-29T13:47:13.268052', 'timeout': 180, 'label': None}","title":"Submitting a job"},{"location":"tutorials/running-a-model/#retrieving-results","text":"Once the job has finished we can access its results. def get_job_results ( base_url , headers , job_id ): \"\"\"Extract job results from the queue\"\"\" url = base_url + f 'jobs/ { job_id } /results' response = requests . get ( url = url , headers = headers ) return response . json () # Get job results from the queue results = get_job_results ( base_url = base_url , headers = headers , job_id = job_id ) Note: completed jobs are only retained in the queue for 2 hours, at which point the job (and results) are deleted. The value corresponding to the results key contains the solution reported by the worker. Let's use Pandas to examine the output. region_solution = results . get ( 'results' ) . get ( 'output' ) . get ( 'RegionSolution' ) # Convert to markdown to display results region_solution_md = pd . DataFrame ( region_solution ) . to_markdown ( index = False ) display . Markdown ( region_solution_md ) @RegionID @CaseID @Intervention @EnergyPrice @DispatchedGeneration @DispatchedLoad @FixedDemand @NetExport @SurplusGeneration @R6Dispatch @R60Dispatch @R5Dispatch @R5RegDispatch @L6Dispatch @L60Dispatch @L5Dispatch @L5RegDispatch @ClearedDemand NSW1 20201101001 0 41.6999 5818.37 0 5654.29 164.078 0 213 196 68 118.172 112.354 173 78.968 34 5660.54 QLD1 20201101001 0 41.2282 5232.56 0 5113.69 118.868 0 34.9091 34.9091 23 103 0 0 0 40 5113.56 SA1 20201101001 0 45.44 1001.83 0 1096.91 -95.0743 0 115 75 55.5582 79 97 73 67 108 1096.83 TAS1 20201101001 0 44.8781 734.724 0 957.232 -222.507 0 40.4435 59.8479 23.3362 5 23.197 57.8819 52.0513 10 957.232 VIC1 20201101001 0 44.3783 3653.47 15 3596.2 42.2753 0 88.4044 126 59 49.8276 70 76 64 18 3612.8 interconnector_solution = results . get ( 'results' ) . get ( 'output' ) . get ( 'InterconnectorSolution' ) # Convert to markdown to display results interconnector_solution_md = pd . DataFrame ( interconnector_solution ) . to_markdown ( index = False ) display . Markdown ( interconnector_solution_md ) @InterconnectorID @CaseID @Intervention @Flow @Losses @Deficit N-Q-MNSP1 20201101001 0 -33 -0.591673 0 NSW1-QLD1 20201101001 0 -86.0011 0.306671 0 T-V-MNSP1 20201101001 0 -222.507 6.01955 0 V-S-MNSP1 20201101001 0 45 -0.856901 0 V-SA 20201101001 0 50 0.60394 0 VIC1-NSW1 20201101001 0 -276.834 10.8428 0 trader_solution = results . get ( 'results' ) . get ( 'output' ) . get ( 'TraderSolution' ) # Convert to markdown to display results trader_solution_md = pd . DataFrame ( trader_solution ) . head () . to_markdown ( index = False ) display . Markdown ( trader_solution_md ) @TraderID @CaseID @Intervention @EnergyTarget @R6Target @R60Target @R5Target @R5RegTarget @L6Target @L60Target @L5Target @L5RegTarget @R6Violation @R60Violation @R5Violation @R5RegViolation @L6Violation @L60Violation @L5Violation @L5RegViolation @RampUpRate @RampDnRate @FSTargetMode AGLHAL 20201101001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 720 720 0 AGLSOM 20201101001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 360 360 0 ANGAST1 20201101001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 840 840 nan APD01 20201101001 0 0 31 70 30 0 0 0 0 0 0 0 0 0 0 0 0 0 nan nan nan ARWF1 20201101001 0 126.114 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1200 600 nan","title":"Retrieving results"},{"location":"tutorials/running-a-model/#summary","text":"This tutorial demonstrates the basic functionality of the Dispatch API. Two key components have been introduced: the ability to access historical data using the API, and methods that facilitate interaction with an online queue. Future tutorials will discuss how to modify case files, perform scenario analyses, and also introduce more advanced workflows using additional Dispatch API features.","title":"Summary"},{"location":"tutorials/scenario-analysis-heatmap/","text":"Scenario analysis - creating a heatmap The following sections extend the analysis presented in the previous tutorial . Instead of examining relationships between a single system parameter and a single system variable it is also worthwhile exploring how the joint interaction of two or more system parameters affects dispatch outcomes. Building on the preceeding tutorial, in addition to augmenting the Demand Forecast for South Australia, the Demand Forecast for Victoria will also be modified. The goal of the analysis is to investigate how jointly varying these parameters would likely impact power flow over the Heywood interconnector, and also energy prices in South Australia. Results will be presented in the form of heatmaps, allowing the data to be visually represented in three dimensions. Note the same methods can be used to examine relationships between other system parameters and variables. Imports and authentication import os import json import itertools import requests import numpy as np from dotenv import load_dotenv from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse import matplotlib.pyplot as plt import matplotlib.ticker as ticker # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/' # Headers must be included to authenticate requests headers = { 'Authorization' : f 'Token { TOKEN } ' } Download case file def download_casefile ( base_url , headers , case_id ): \"\"\"Download case file and save to disk\"\"\" # URL to download case file url = base_url + f 'data/casefile/ { case_id } ' print ( \"Download case file URL:\" , url ) # Download case file and save to disk response = requests . get ( url = url , headers = headers ) casefile = response . json () filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'w' ) as f : json . dump ( casefile , f ) return casefile def load_casefile ( case_id ): \"\"\"Load case file\"\"\" filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'r' ) as f : casefile = json . load ( f ) return casefile # Download case file download_casefile ( base_url = base_url , headers = headers , case_id = '20201101001' ) # Load case file casefile = load_casefile ( case_id = '20201101001' ) Download case file URL: https://dispatch.envector.com/api/v1/data/casefile/20201101001 Approach As in the previous tutorial the downloaded case file will be treated as our canonical 'source of truth'. This 'base' case file will always be loaded prior to performing updates. The following two functions are used to update Demand Forecast parameters within a case file. def update_region_demand_forecast ( casefile , region_id , value ): \"\"\" Load case file and update demand forecast for a given region Parameter --------- casefile : dict Case information region_id : str Region for which Demand Forecast should be modified value : float New value for Demand Forecast parameter Returns ------- casefile : dict Case file with updated Demand Forecast parameter \"\"\" # Construct JSON path expression expression = ( f \"NEMSPDCaseFile \\ .NemSpdInputs \\ .PeriodCollection \\ .Period \\ .RegionPeriodCollection \\ .RegionPeriod[?(@RegionID==' { region_id } ')] \\ .@DF\" ) jsonpath_expr = parse ( expression ) # Update value jsonpath_expr . update ( casefile , value ) return casefile def update_casefile ( case_id , region_1 , value_1 , region_2 , value_2 ): \"\"\" Update Demand Forecast parameters in two regions Parameters ---------- case_id : str Case ID for base case file region_1 : str First NEM region for which Demand Forecast should be updated value_1 : float New Demand Forecast value for region_1 region_2 : str Second NEM region for which Demand Forecast should be updated value_2 : float New Demand Forecast value for region_2 Returns ------- casefile : dict Updated case file \"\"\" # Load 'base' case file casefile = load_casefile ( case_id = case_id ) # Update parameters in both regions casefile = update_region_demand_forecast ( casefile = casefile , region_id = region_1 , value = value_1 ) casefile = update_region_demand_forecast ( casefile = casefile , region_id = region_2 , value = value_2 ) return casefile Jobs can be submitted to the online queue, with job IDs recorded so it's possible to map job results to parameters. def submit_jobs ( base_url , headers , region_1 , region_2 , demand_forecasts ): \"\"\"Submit jobs to queue\"\"\" values = [ i for i in itertools . product ( demand_forecasts , demand_forecasts )] jobs = [] for value_1 , value_2 in values : # Construct request body - using augmented casefiles body = { \"casefile\" : update_casefile ( case_id = '20201101001' , region_1 = region_1 , value_1 = value_1 , region_2 = region_2 , value_2 = value_2 )} # Submit request and extract job ID url = base_url + 'jobs/create' response = requests . post ( url = url , headers = headers , json = body ) job_info = response . json () # Construct a map between the job ID, job info and the value of the parameter used in the analysis job_id = job_info . get ( 'job_id' ) parameters = { 'region_1' : region_1 , 'value_1' : value_1 , 'region_2' : region_2 , 'value_2' : value_2 } jobs . append ({ 'job_info' : job_info , 'parameters' : parameters }) return jobs # Create jobs with different Demand Forecast parameters demand_forecasts = [ i for i in range ( - 200 , 201 , 100 )] jobs = submit_jobs ( base_url = base_url , headers = headers , region_1 = 'SA1' , region_2 = 'VIC1' , demand_forecasts = demand_forecasts ) The status of all jobs can be checked by using the following endpoint: https://dispatch.envector.com/api/v1/jobs/status/list def get_status_list ( base_url , headers ): \"\"\"Get job status list\"\"\" url = base_url + 'jobs/status/list' response = requests . get ( url = url , headers = headers ) return response . json () # Get status of each job status = get_status_list ( base_url = base_url , headers = headers ) # Number of remaining jobs remaining_jobs = len ([ i for i in status if i . get ( 'status' ) != 'finished' ]) print ( 'Jobs remaining:' , remaining_jobs ) # Only print the first three jobs (to save space) status [: 3 ] Jobs remaining: 0 [{'job_id': '27bd2dbc-f02f-4cb3-9afa-06d139563bac', 'status': 'finished', 'created_at': '2021-03-30T07:13:02.835957Z', 'enqueued_at': '2021-03-30T07:13:03.030410Z', 'started_at': '2021-03-30T07:25:05.961313Z', 'ended_at': '2021-03-30T07:25:41.337840Z', 'timeout': '180', 'label': None}, {'job_id': 'e6de7c3b-7d41-4368-84b3-263fe1bb7eb7', 'status': 'finished', 'created_at': '2021-03-30T07:13:01.427608Z', 'enqueued_at': '2021-03-30T07:13:01.619619Z', 'started_at': '2021-03-30T07:24:30.010635Z', 'ended_at': '2021-03-30T07:25:05.805712Z', 'timeout': '180', 'label': None}, {'job_id': 'c69efbe-94db-418b-b860-6ba9ad2b0b9a', 'status': 'finished', 'created_at': '2021-03-30T07:13:00.276323Z', 'enqueued_at': '2021-03-30T07:13:00.472272Z', 'started_at': '2021-03-30T07:23:40.928030Z', 'ended_at': '2021-03-30T07:24:29.853803Z', 'timeout': '180', 'label': None}] Retrieve results Once the jobs have finished results can be retrieved from the queue. def get_job_results ( base_url , headers , job_ids ): \"\"\"Get job results\"\"\" results = [] for job_id in job_ids : # Construct URL used to obtain results url = base_url + f 'jobs/ { job_id } /results' print ( \"Job results URL:\" , url ) # Submit request and retrieve job results response = requests . get ( url = url , headers = headers ) results . append ( response . json ()) return results # Get all job IDs for which results should be returned job_ids = [ i . get ( 'job_info' ) . get ( 'job_id' ) for i in jobs ] # Load job results job_results = get_job_results ( base_url = base_url , headers = headers , job_ids = job_ids ) Job results URL: https://dispatch.envector.com/api/v1/jobs/1296572a-39f8-4cc3-a096-b84e1c81447a/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6c8bc245-2821-4afb-89ad-7702b07ad4d4/results Job results URL: https://dispatch.envector.com/api/v1/jobs/8a601e7e-a7c6-48d9-9815-52519ae68440/results Job results URL: https://dispatch.envector.com/api/v1/jobs/5d1bf2d8-0826-4a9c-852e-ad51ad3c15ac/results Job results URL: https://dispatch.envector.com/api/v1/jobs/847f151b-96d8-46bd-8460-88773aaabdd9/results Job results URL: https://dispatch.envector.com/api/v1/jobs/740f9614-e3d9-402a-9229-237ea03ded07/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9387a290-8807-4790-91ea-0e80e0ef33f8/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9aaf5979-2d5f-4c74-b613-83a6832a618b/results Job results URL: https://dispatch.envector.com/api/v1/jobs/1ef75782-e4ed-49ae-ba9d-0483506cabf5/results Job results URL: https://dispatch.envector.com/api/v1/jobs/3b271233-bec1-4b64-9412-4e132b61109a/results Job results URL: https://dispatch.envector.com/api/v1/jobs/b050d586-464c-4868-9177-2c5717f2098f/results Job results URL: https://dispatch.envector.com/api/v1/jobs/c1712a50-91e8-441e-be30-d388552c8bba/results Job results URL: https://dispatch.envector.com/api/v1/jobs/eea1aa21-f6c6-426d-879a-26a12f7f57ae/results Job results URL: https://dispatch.envector.com/api/v1/jobs/4b7f866a-19f3-41a5-bb9d-3c1883ada1d0/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6952a4f0-c31a-43ed-8505-ac011b3f78c3/results Job results URL: https://dispatch.envector.com/api/v1/jobs/52d34171-1315-42b7-8a7b-9f63e2535500/results Job results URL: https://dispatch.envector.com/api/v1/jobs/e295ed4d-b6d8-4584-a406-0955762ef5e2/results Job results URL: https://dispatch.envector.com/api/v1/jobs/f847228d-4418-40ce-8e5e-c4d781b42214/results Job results URL: https://dispatch.envector.com/api/v1/jobs/ad51c5df-b17a-40f3-824b-97f6b112abea/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6de17032-8c8f-40a4-aaef-77e7ef1a2cbb/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6fd8ae7c-afca-4404-8acb-7d3f7f5792f2/results Job results URL: https://dispatch.envector.com/api/v1/jobs/103501cd-5476-4dbb-96bf-0913719dfe41/results Job results URL: https://dispatch.envector.com/api/v1/jobs/bc69efbe-94db-418b-b860-6ba9ad2b0b9a/results Job results URL: https://dispatch.envector.com/api/v1/jobs/e6de7c3b-7d41-4368-84b3-263fe1bb7eb7/results Job results URL: https://dispatch.envector.com/api/v1/jobs/27bd2dbc-f02f-4cb3-9afa-06d139563bac/results Map parameters to job IDs The first step is to map job IDs to job parameters. def get_job_parameters ( jobs ): \"\"\"Extract job parameters and map to job ID\"\"\" return { job . get ( 'job_info' ) . get ( 'job_id' ): job . get ( 'parameters' ) for job in jobs } job_parameters = get_job_parameters ( jobs = jobs ) Optionally save results. It is good practice to save results after retrieving them from the queue. Re-analysing results simply requires loading the saved results, rather than having to re-run jobs. import pickle def save_results ( job_parameters , job_results ): \"\"\"Save results to notebook directory\"\"\" output_dir = os . path . abspath ( os . path . join ( os . path . curdir , 'output' )) with open ( os . path . join ( output_dir , 'job_results.pickle' ), 'wb' ) as f : pickle . dump ( job_results , f ) with open ( os . path . join ( output_dir , 'job_parameters.pickle' ), 'wb' ) as f : pickle . dump ( job_parameters , f ) def load_results (): \"\"\"Save results to notebook directory\"\"\" output_dir = os . path . abspath ( os . path . join ( os . path . curdir , 'output' )) with open ( os . path . join ( output_dir , 'job_results.pickle' ), 'rb' ) as f : pickle . dump ( job_results , f ) with open ( os . path . join ( output_dir , 'job_parameters.pickle' ), 'rb' ) as f : pickle . dump ( job_parameters , f ) return job_parameters , job_results # Save / load results if required save_results ( job_parameters = job_parameters , job_results = job_results ) # job_parameters, job_results = load_results() Map results to job IDs The next step is to map results to job IDs. The following function searches a results dictionary for a target value corresponding to a given JSON path expression. def get_target_value ( results , expression ): \"\"\"Extract value from results dictionary given a JSON path expression\"\"\" jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( results )] # Only one value should be returned if len ( values ) != 1 : raise Exception ( \"Should only return 1 value, encountered\" , len ( values )) return values [ 0 ] Functions can now be used to extract target values (energy prices in South Australia and power flow over the Heywood interconnector) and map them to their respective job IDs. def get_sa_energy_price ( job_results ): \"\"\"Extract energy price from results dictionary\"\"\" expression = ( f \"results \\ .output \\ .RegionSolution[?(@RegionID='SA1')] \\ .@EnergyPrice\" ) prices = { i . get ( 'job_id' ): get_target_value ( results = i , expression = expression ) for i in job_results } return prices def get_v_sa_flow ( job_results ): \"\"\"Extract V-SA (Heywood) interconnector flow\"\"\" expression = ( f \"results \\ .output \\ .InterconnectorSolution[?(@InterconnectorID='V-SA')] \\ .@Flow\" ) flow = { i . get ( 'job_id' ): get_target_value ( results = i , expression = expression ) for i in job_results } return flow Plotting A heatmap can be used to visualise the results in three dimensions. The horizontal and vertical axes will display the Demand Forecast parameters used when running the model, while colour will indicate value of the variable under investigation. def get_plot_data ( job_parameters , job_results , func ): \"\"\" Organise plot data Parameters ---------- job_parameters : dict Parameters used when augmenting case files job_results : list Contains solution to mathematical program reported by worker func : function Function used to extract values from job_results Returns ------- x : numpy array x-axis values used in plot y : numpy array y-axis values used in plot z : numpy array z-axis values used in plot \"\"\" # Extract job results - dict indexed by job ID {job_id: target_value, ...} values = func ( job_results ) # Organise results {(DF_region_1, DF_region_2): target_value, ...} data = {( v . get ( 'value_1' ), v . get ( 'value_2' )): values . get ( job_id ) for job_id , v in job_parameters . items ()} # Extract x, y, z components x = np . array ([ k [ 0 ] for k in data . keys ()]) y = np . array ([ k [ 1 ] for k in data . keys ()]) z = np . array ([ v for v in data . values ()]) # Add shape information to array - required when plotting x . shape = ( 5 , 5 ) y . shape = ( 5 , 5 ) z . shape = ( 5 , 5 ) return x , y , z def format_tick_locations ( ax ): \"\"\"Adjust tick spacing\"\"\" ax . xaxis . set_major_locator ( ticker . MultipleLocator ( 100 )) ax . xaxis . set_minor_locator ( ticker . MultipleLocator ( 50 )) ax . yaxis . set_major_locator ( ticker . MultipleLocator ( 100 )) ax . yaxis . set_minor_locator ( ticker . MultipleLocator ( 50 )) return ax def plot_v_sa_flow ( job_parameters , job_results , shading = None ): \"\"\"V-SA interconnector flow as a function of SA and VIC demand forecasts\"\"\" X , Y , Z = get_plot_data ( job_parameters = job_parameters , job_results = job_results , func = get_v_sa_flow ) # Create heatmap and add colour bar fig , ax = plt . subplots () mesh = ax . pcolormesh ( X , Y , Z , shading = shading , cmap = 'inferno' ) cbar = plt . colorbar ( mesh ) # Format labels ax . set_title ( 'Heywood power flow' ) ax . set_xlabel ( 'SA Demand Forecast (MW)' ) ax . set_ylabel ( 'VIC Demand Forecast (MW)' ) cbar . set_label ( 'V-SA flow (MW)' ) ax = format_tick_locations ( ax = ax ) ax . grid ( linestyle = '--' ) plt . show () def plot_sa_energy_price ( job_parameters , job_results , shading = None ): \"\"\"SA energy price as a function of SA and VIC demand forecasts\"\"\" X , Y , Z = get_plot_data ( job_parameters = job_parameters , job_results = job_results , func = get_sa_energy_price ) # Create heatmap and add colour bar fig , ax = plt . subplots () mesh = ax . pcolormesh ( X , Y , Z , shading = shading , cmap = 'inferno' ) cbar = plt . colorbar ( mesh ) # Format labels ax . set_title ( 'SA energy price' ) ax . set_xlabel ( 'SA Demand Forecast (MW)' ) ax . set_ylabel ( 'VIC Demand Forecast (MW)' ) cbar . set_label ( 'SA energy price ($/MWh)' ) # Format ticks and add grid lines ax = format_tick_locations ( ax = ax ) ax . grid ( linestyle = '--' ) plt . show () # Create plots plot_v_sa_flow ( job_parameters = job_parameters , job_results = job_results , shading = 'auto' ) plot_sa_energy_price ( job_parameters = job_parameters , job_results = job_results , shading = 'auto' ) The resolution of the these plots can be increased by providing a more granual grid over which to explore the solution space. The trade-off is solution time - more jobs must be completed and processed. Interpolation can also be used to smooth the gradient, making it easier to visualise the results. # Create plots with interpolation plot_v_sa_flow ( job_parameters = job_parameters , job_results = job_results , shading = 'gouraud' ) plot_sa_energy_price ( job_parameters = job_parameters , job_results = job_results , shading = 'gouraud' ) Summary The Dispatch API allows users to explore relationships between the joint interaction of system parameters and system variables. When two system parameters are examined heatmaps can be used to visualise results in three dimensions. This type of scenario analysis can easily be extended to different system parameters and variables, demonstrating the flexibility provided by the Dispatch API when exploring the likely solution space of dispatch outcomes.","title":"Scenario analsyis - heatmap"},{"location":"tutorials/scenario-analysis-heatmap/#scenario-analysis-creating-a-heatmap","text":"The following sections extend the analysis presented in the previous tutorial . Instead of examining relationships between a single system parameter and a single system variable it is also worthwhile exploring how the joint interaction of two or more system parameters affects dispatch outcomes. Building on the preceeding tutorial, in addition to augmenting the Demand Forecast for South Australia, the Demand Forecast for Victoria will also be modified. The goal of the analysis is to investigate how jointly varying these parameters would likely impact power flow over the Heywood interconnector, and also energy prices in South Australia. Results will be presented in the form of heatmaps, allowing the data to be visually represented in three dimensions. Note the same methods can be used to examine relationships between other system parameters and variables.","title":"Scenario analysis - creating a heatmap"},{"location":"tutorials/scenario-analysis-heatmap/#imports-and-authentication","text":"import os import json import itertools import requests import numpy as np from dotenv import load_dotenv from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse import matplotlib.pyplot as plt import matplotlib.ticker as ticker # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/' # Headers must be included to authenticate requests headers = { 'Authorization' : f 'Token { TOKEN } ' }","title":"Imports and authentication"},{"location":"tutorials/scenario-analysis-heatmap/#download-case-file","text":"def download_casefile ( base_url , headers , case_id ): \"\"\"Download case file and save to disk\"\"\" # URL to download case file url = base_url + f 'data/casefile/ { case_id } ' print ( \"Download case file URL:\" , url ) # Download case file and save to disk response = requests . get ( url = url , headers = headers ) casefile = response . json () filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'w' ) as f : json . dump ( casefile , f ) return casefile def load_casefile ( case_id ): \"\"\"Load case file\"\"\" filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'r' ) as f : casefile = json . load ( f ) return casefile # Download case file download_casefile ( base_url = base_url , headers = headers , case_id = '20201101001' ) # Load case file casefile = load_casefile ( case_id = '20201101001' ) Download case file URL: https://dispatch.envector.com/api/v1/data/casefile/20201101001","title":"Download case file"},{"location":"tutorials/scenario-analysis-heatmap/#approach","text":"As in the previous tutorial the downloaded case file will be treated as our canonical 'source of truth'. This 'base' case file will always be loaded prior to performing updates. The following two functions are used to update Demand Forecast parameters within a case file. def update_region_demand_forecast ( casefile , region_id , value ): \"\"\" Load case file and update demand forecast for a given region Parameter --------- casefile : dict Case information region_id : str Region for which Demand Forecast should be modified value : float New value for Demand Forecast parameter Returns ------- casefile : dict Case file with updated Demand Forecast parameter \"\"\" # Construct JSON path expression expression = ( f \"NEMSPDCaseFile \\ .NemSpdInputs \\ .PeriodCollection \\ .Period \\ .RegionPeriodCollection \\ .RegionPeriod[?(@RegionID==' { region_id } ')] \\ .@DF\" ) jsonpath_expr = parse ( expression ) # Update value jsonpath_expr . update ( casefile , value ) return casefile def update_casefile ( case_id , region_1 , value_1 , region_2 , value_2 ): \"\"\" Update Demand Forecast parameters in two regions Parameters ---------- case_id : str Case ID for base case file region_1 : str First NEM region for which Demand Forecast should be updated value_1 : float New Demand Forecast value for region_1 region_2 : str Second NEM region for which Demand Forecast should be updated value_2 : float New Demand Forecast value for region_2 Returns ------- casefile : dict Updated case file \"\"\" # Load 'base' case file casefile = load_casefile ( case_id = case_id ) # Update parameters in both regions casefile = update_region_demand_forecast ( casefile = casefile , region_id = region_1 , value = value_1 ) casefile = update_region_demand_forecast ( casefile = casefile , region_id = region_2 , value = value_2 ) return casefile Jobs can be submitted to the online queue, with job IDs recorded so it's possible to map job results to parameters. def submit_jobs ( base_url , headers , region_1 , region_2 , demand_forecasts ): \"\"\"Submit jobs to queue\"\"\" values = [ i for i in itertools . product ( demand_forecasts , demand_forecasts )] jobs = [] for value_1 , value_2 in values : # Construct request body - using augmented casefiles body = { \"casefile\" : update_casefile ( case_id = '20201101001' , region_1 = region_1 , value_1 = value_1 , region_2 = region_2 , value_2 = value_2 )} # Submit request and extract job ID url = base_url + 'jobs/create' response = requests . post ( url = url , headers = headers , json = body ) job_info = response . json () # Construct a map between the job ID, job info and the value of the parameter used in the analysis job_id = job_info . get ( 'job_id' ) parameters = { 'region_1' : region_1 , 'value_1' : value_1 , 'region_2' : region_2 , 'value_2' : value_2 } jobs . append ({ 'job_info' : job_info , 'parameters' : parameters }) return jobs # Create jobs with different Demand Forecast parameters demand_forecasts = [ i for i in range ( - 200 , 201 , 100 )] jobs = submit_jobs ( base_url = base_url , headers = headers , region_1 = 'SA1' , region_2 = 'VIC1' , demand_forecasts = demand_forecasts ) The status of all jobs can be checked by using the following endpoint: https://dispatch.envector.com/api/v1/jobs/status/list def get_status_list ( base_url , headers ): \"\"\"Get job status list\"\"\" url = base_url + 'jobs/status/list' response = requests . get ( url = url , headers = headers ) return response . json () # Get status of each job status = get_status_list ( base_url = base_url , headers = headers ) # Number of remaining jobs remaining_jobs = len ([ i for i in status if i . get ( 'status' ) != 'finished' ]) print ( 'Jobs remaining:' , remaining_jobs ) # Only print the first three jobs (to save space) status [: 3 ] Jobs remaining: 0 [{'job_id': '27bd2dbc-f02f-4cb3-9afa-06d139563bac', 'status': 'finished', 'created_at': '2021-03-30T07:13:02.835957Z', 'enqueued_at': '2021-03-30T07:13:03.030410Z', 'started_at': '2021-03-30T07:25:05.961313Z', 'ended_at': '2021-03-30T07:25:41.337840Z', 'timeout': '180', 'label': None}, {'job_id': 'e6de7c3b-7d41-4368-84b3-263fe1bb7eb7', 'status': 'finished', 'created_at': '2021-03-30T07:13:01.427608Z', 'enqueued_at': '2021-03-30T07:13:01.619619Z', 'started_at': '2021-03-30T07:24:30.010635Z', 'ended_at': '2021-03-30T07:25:05.805712Z', 'timeout': '180', 'label': None}, {'job_id': 'c69efbe-94db-418b-b860-6ba9ad2b0b9a', 'status': 'finished', 'created_at': '2021-03-30T07:13:00.276323Z', 'enqueued_at': '2021-03-30T07:13:00.472272Z', 'started_at': '2021-03-30T07:23:40.928030Z', 'ended_at': '2021-03-30T07:24:29.853803Z', 'timeout': '180', 'label': None}]","title":"Approach"},{"location":"tutorials/scenario-analysis-heatmap/#retrieve-results","text":"Once the jobs have finished results can be retrieved from the queue. def get_job_results ( base_url , headers , job_ids ): \"\"\"Get job results\"\"\" results = [] for job_id in job_ids : # Construct URL used to obtain results url = base_url + f 'jobs/ { job_id } /results' print ( \"Job results URL:\" , url ) # Submit request and retrieve job results response = requests . get ( url = url , headers = headers ) results . append ( response . json ()) return results # Get all job IDs for which results should be returned job_ids = [ i . get ( 'job_info' ) . get ( 'job_id' ) for i in jobs ] # Load job results job_results = get_job_results ( base_url = base_url , headers = headers , job_ids = job_ids ) Job results URL: https://dispatch.envector.com/api/v1/jobs/1296572a-39f8-4cc3-a096-b84e1c81447a/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6c8bc245-2821-4afb-89ad-7702b07ad4d4/results Job results URL: https://dispatch.envector.com/api/v1/jobs/8a601e7e-a7c6-48d9-9815-52519ae68440/results Job results URL: https://dispatch.envector.com/api/v1/jobs/5d1bf2d8-0826-4a9c-852e-ad51ad3c15ac/results Job results URL: https://dispatch.envector.com/api/v1/jobs/847f151b-96d8-46bd-8460-88773aaabdd9/results Job results URL: https://dispatch.envector.com/api/v1/jobs/740f9614-e3d9-402a-9229-237ea03ded07/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9387a290-8807-4790-91ea-0e80e0ef33f8/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9aaf5979-2d5f-4c74-b613-83a6832a618b/results Job results URL: https://dispatch.envector.com/api/v1/jobs/1ef75782-e4ed-49ae-ba9d-0483506cabf5/results Job results URL: https://dispatch.envector.com/api/v1/jobs/3b271233-bec1-4b64-9412-4e132b61109a/results Job results URL: https://dispatch.envector.com/api/v1/jobs/b050d586-464c-4868-9177-2c5717f2098f/results Job results URL: https://dispatch.envector.com/api/v1/jobs/c1712a50-91e8-441e-be30-d388552c8bba/results Job results URL: https://dispatch.envector.com/api/v1/jobs/eea1aa21-f6c6-426d-879a-26a12f7f57ae/results Job results URL: https://dispatch.envector.com/api/v1/jobs/4b7f866a-19f3-41a5-bb9d-3c1883ada1d0/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6952a4f0-c31a-43ed-8505-ac011b3f78c3/results Job results URL: https://dispatch.envector.com/api/v1/jobs/52d34171-1315-42b7-8a7b-9f63e2535500/results Job results URL: https://dispatch.envector.com/api/v1/jobs/e295ed4d-b6d8-4584-a406-0955762ef5e2/results Job results URL: https://dispatch.envector.com/api/v1/jobs/f847228d-4418-40ce-8e5e-c4d781b42214/results Job results URL: https://dispatch.envector.com/api/v1/jobs/ad51c5df-b17a-40f3-824b-97f6b112abea/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6de17032-8c8f-40a4-aaef-77e7ef1a2cbb/results Job results URL: https://dispatch.envector.com/api/v1/jobs/6fd8ae7c-afca-4404-8acb-7d3f7f5792f2/results Job results URL: https://dispatch.envector.com/api/v1/jobs/103501cd-5476-4dbb-96bf-0913719dfe41/results Job results URL: https://dispatch.envector.com/api/v1/jobs/bc69efbe-94db-418b-b860-6ba9ad2b0b9a/results Job results URL: https://dispatch.envector.com/api/v1/jobs/e6de7c3b-7d41-4368-84b3-263fe1bb7eb7/results Job results URL: https://dispatch.envector.com/api/v1/jobs/27bd2dbc-f02f-4cb3-9afa-06d139563bac/results","title":"Retrieve results"},{"location":"tutorials/scenario-analysis-heatmap/#map-parameters-to-job-ids","text":"The first step is to map job IDs to job parameters. def get_job_parameters ( jobs ): \"\"\"Extract job parameters and map to job ID\"\"\" return { job . get ( 'job_info' ) . get ( 'job_id' ): job . get ( 'parameters' ) for job in jobs } job_parameters = get_job_parameters ( jobs = jobs ) Optionally save results. It is good practice to save results after retrieving them from the queue. Re-analysing results simply requires loading the saved results, rather than having to re-run jobs. import pickle def save_results ( job_parameters , job_results ): \"\"\"Save results to notebook directory\"\"\" output_dir = os . path . abspath ( os . path . join ( os . path . curdir , 'output' )) with open ( os . path . join ( output_dir , 'job_results.pickle' ), 'wb' ) as f : pickle . dump ( job_results , f ) with open ( os . path . join ( output_dir , 'job_parameters.pickle' ), 'wb' ) as f : pickle . dump ( job_parameters , f ) def load_results (): \"\"\"Save results to notebook directory\"\"\" output_dir = os . path . abspath ( os . path . join ( os . path . curdir , 'output' )) with open ( os . path . join ( output_dir , 'job_results.pickle' ), 'rb' ) as f : pickle . dump ( job_results , f ) with open ( os . path . join ( output_dir , 'job_parameters.pickle' ), 'rb' ) as f : pickle . dump ( job_parameters , f ) return job_parameters , job_results # Save / load results if required save_results ( job_parameters = job_parameters , job_results = job_results ) # job_parameters, job_results = load_results()","title":"Map parameters to job IDs"},{"location":"tutorials/scenario-analysis-heatmap/#map-results-to-job-ids","text":"The next step is to map results to job IDs. The following function searches a results dictionary for a target value corresponding to a given JSON path expression. def get_target_value ( results , expression ): \"\"\"Extract value from results dictionary given a JSON path expression\"\"\" jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( results )] # Only one value should be returned if len ( values ) != 1 : raise Exception ( \"Should only return 1 value, encountered\" , len ( values )) return values [ 0 ] Functions can now be used to extract target values (energy prices in South Australia and power flow over the Heywood interconnector) and map them to their respective job IDs. def get_sa_energy_price ( job_results ): \"\"\"Extract energy price from results dictionary\"\"\" expression = ( f \"results \\ .output \\ .RegionSolution[?(@RegionID='SA1')] \\ .@EnergyPrice\" ) prices = { i . get ( 'job_id' ): get_target_value ( results = i , expression = expression ) for i in job_results } return prices def get_v_sa_flow ( job_results ): \"\"\"Extract V-SA (Heywood) interconnector flow\"\"\" expression = ( f \"results \\ .output \\ .InterconnectorSolution[?(@InterconnectorID='V-SA')] \\ .@Flow\" ) flow = { i . get ( 'job_id' ): get_target_value ( results = i , expression = expression ) for i in job_results } return flow","title":"Map results to job IDs"},{"location":"tutorials/scenario-analysis-heatmap/#plotting","text":"A heatmap can be used to visualise the results in three dimensions. The horizontal and vertical axes will display the Demand Forecast parameters used when running the model, while colour will indicate value of the variable under investigation. def get_plot_data ( job_parameters , job_results , func ): \"\"\" Organise plot data Parameters ---------- job_parameters : dict Parameters used when augmenting case files job_results : list Contains solution to mathematical program reported by worker func : function Function used to extract values from job_results Returns ------- x : numpy array x-axis values used in plot y : numpy array y-axis values used in plot z : numpy array z-axis values used in plot \"\"\" # Extract job results - dict indexed by job ID {job_id: target_value, ...} values = func ( job_results ) # Organise results {(DF_region_1, DF_region_2): target_value, ...} data = {( v . get ( 'value_1' ), v . get ( 'value_2' )): values . get ( job_id ) for job_id , v in job_parameters . items ()} # Extract x, y, z components x = np . array ([ k [ 0 ] for k in data . keys ()]) y = np . array ([ k [ 1 ] for k in data . keys ()]) z = np . array ([ v for v in data . values ()]) # Add shape information to array - required when plotting x . shape = ( 5 , 5 ) y . shape = ( 5 , 5 ) z . shape = ( 5 , 5 ) return x , y , z def format_tick_locations ( ax ): \"\"\"Adjust tick spacing\"\"\" ax . xaxis . set_major_locator ( ticker . MultipleLocator ( 100 )) ax . xaxis . set_minor_locator ( ticker . MultipleLocator ( 50 )) ax . yaxis . set_major_locator ( ticker . MultipleLocator ( 100 )) ax . yaxis . set_minor_locator ( ticker . MultipleLocator ( 50 )) return ax def plot_v_sa_flow ( job_parameters , job_results , shading = None ): \"\"\"V-SA interconnector flow as a function of SA and VIC demand forecasts\"\"\" X , Y , Z = get_plot_data ( job_parameters = job_parameters , job_results = job_results , func = get_v_sa_flow ) # Create heatmap and add colour bar fig , ax = plt . subplots () mesh = ax . pcolormesh ( X , Y , Z , shading = shading , cmap = 'inferno' ) cbar = plt . colorbar ( mesh ) # Format labels ax . set_title ( 'Heywood power flow' ) ax . set_xlabel ( 'SA Demand Forecast (MW)' ) ax . set_ylabel ( 'VIC Demand Forecast (MW)' ) cbar . set_label ( 'V-SA flow (MW)' ) ax = format_tick_locations ( ax = ax ) ax . grid ( linestyle = '--' ) plt . show () def plot_sa_energy_price ( job_parameters , job_results , shading = None ): \"\"\"SA energy price as a function of SA and VIC demand forecasts\"\"\" X , Y , Z = get_plot_data ( job_parameters = job_parameters , job_results = job_results , func = get_sa_energy_price ) # Create heatmap and add colour bar fig , ax = plt . subplots () mesh = ax . pcolormesh ( X , Y , Z , shading = shading , cmap = 'inferno' ) cbar = plt . colorbar ( mesh ) # Format labels ax . set_title ( 'SA energy price' ) ax . set_xlabel ( 'SA Demand Forecast (MW)' ) ax . set_ylabel ( 'VIC Demand Forecast (MW)' ) cbar . set_label ( 'SA energy price ($/MWh)' ) # Format ticks and add grid lines ax = format_tick_locations ( ax = ax ) ax . grid ( linestyle = '--' ) plt . show () # Create plots plot_v_sa_flow ( job_parameters = job_parameters , job_results = job_results , shading = 'auto' ) plot_sa_energy_price ( job_parameters = job_parameters , job_results = job_results , shading = 'auto' ) The resolution of the these plots can be increased by providing a more granual grid over which to explore the solution space. The trade-off is solution time - more jobs must be completed and processed. Interpolation can also be used to smooth the gradient, making it easier to visualise the results. # Create plots with interpolation plot_v_sa_flow ( job_parameters = job_parameters , job_results = job_results , shading = 'gouraud' ) plot_sa_energy_price ( job_parameters = job_parameters , job_results = job_results , shading = 'gouraud' )","title":"Plotting"},{"location":"tutorials/scenario-analysis-heatmap/#summary","text":"The Dispatch API allows users to explore relationships between the joint interaction of system parameters and system variables. When two system parameters are examined heatmaps can be used to visualise results in three dimensions. This type of scenario analysis can easily be extended to different system parameters and variables, demonstrating the flexibility provided by the Dispatch API when exploring the likely solution space of dispatch outcomes.","title":"Summary"},{"location":"tutorials/scenario-analysis-line-plot/","text":"Scenario analysis - creating a line plot The ability to examine relationships between system parameters and system variables is a powerful capability offered by the Dispatch API. This notebook outlines a workflow that can be used to perform ex-post scenario analyses using historical case file data. While the following sections examine how changes to demand forecasts would likely influences prices in a given region, the same principles can be applied to examine other relationships. Imports and authentication import os import json import requests from dotenv import load_dotenv import matplotlib.pyplot as plt from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/' # Headers must be included to authenticate requests headers = { 'Authorization' : f 'Token { TOKEN } ' } Download case file We need some data to work with, so let's proceed by downloading a case file. def download_casefile ( base_url , headers , case_id ): \"\"\"Download case file and save to disk\"\"\" # URL to download case file url = base_url + f 'data/casefile/ { case_id } ' print ( \"Download case file URL:\" , url ) # Download case file and save to disk response = requests . get ( url = url , headers = headers ) # Load JSON response as Python dictionary casefile = response . json () # Save file filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'w' ) as f : json . dump ( casefile , f ) return casefile def load_casefile ( case_id ): \"\"\"Load case file\"\"\" filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'r' ) as f : casefile = json . load ( f ) return casefile # Download case file download_casefile ( base_url = base_url , headers = headers , case_id = '20201101001' ) # Load case file casefile = load_casefile ( case_id = '20201101001' ) Download case file URL: https://dispatch.envector.com/api/v1/data/casefile/20201101001 Approach It is always a good idea to separate data from logic. Let's treat the case file that we saved to disk as our canonical 'source of truth', with this 'base' case file loaded before performing each update. As this case file will never be overwritten we can be sure we're using the same data before making updates, thus reducing the possibilty of introducing unintended changes. The following function reads the base case file from disk then updates the Demand Forecast ( @DF ) parameter for South Australia. This allows us to investigate how prices respond to changes in anticipated demand. def update_region_demand_forecast ( case_id , region_id , value ): \"\"\"Load case file and update demand forecast for a given region\"\"\" # Load case file load_casefile ( case_id = case_id ) # Construct expression expression = ( f \"NEMSPDCaseFile \\ .NemSpdInputs \\ .PeriodCollection \\ .Period \\ .RegionPeriodCollection \\ .RegionPeriod[?(@RegionID==' { region_id } ')] \\ .@DF\" ) # Construct JSON path expression jsonpath_expr = parse ( expression ) # Update value _ = jsonpath_expr . update ( casefile , value ) return casefile Jobs are submitted to the online queue, with each job having a different @DF value. Job IDs will be used to map @DF parameters to results once they are available. def submit_jobs ( base_url , headers , region_id , values ): \"\"\"Submit jobs to online queue\"\"\" jobs = [] for i in values : # Construct request body - using augmented casefiles body = { \"casefile\" : update_region_demand_forecast ( case_id = '20201101001' , region_id = region_id , value = i )} # Submit request and extract job ID url = base_url + 'jobs/create' response = requests . post ( url = url , headers = headers , json = body ) job_info = response . json () # Construct a map between the job ID, job info and the value of the parameter used in the analysis jobs . append ({ 'job_info' : job_info , 'demand_forecast' : i }) return jobs # Demand forecast parameters values = [ - 50 , - 40 , - 30 , - 20 , - 10 , 0 , 10 , 20 , 30 , 40 , 50 ] jobs = submit_jobs ( base_url = base_url , headers = headers , region_id = 'SA1' , values = values ) We can check the status of all our jobs by using the following endpoint: https://dispatch.envector.com/api/v1/jobs/status/list def get_status ( base_url , headers ): \"\"\"Get status of all jobs\"\"\" url = base_url + 'jobs/status/list' response = requests . get ( url = url , headers = headers ) status = response . json () return status # Get job status list status = get_status ( base_url = base_url , headers = headers ) # Only printing the first three jobs (to save space) status [: 3 ] [{'job_id': 'f59b729a-7dd9-40fd-b049-51a18b3a1e46', 'status': 'finished', 'created_at': '2021-03-30T08:48:02.162896Z', 'enqueued_at': '2021-03-30T08:48:02.356483Z', 'started_at': '2021-03-30T08:52:03.755665Z', 'ended_at': '2021-03-30T08:52:33.031707Z', 'timeout': '180', 'label': None}, {'job_id': '90f430ed-b3b4-4b56-a879-07df10b22207', 'status': 'finished', 'created_at': '2021-03-30T08:48:01.100274Z', 'enqueued_at': '2021-03-30T08:48:01.291683Z', 'started_at': '2021-03-30T08:51:34.649039Z', 'ended_at': '2021-03-30T08:52:03.601137Z', 'timeout': '180', 'label': None}, {'job_id': '12d696bd-174c-450d-b791-6f09d2b1de69', 'status': 'finished', 'created_at': '2021-03-30T08:48:00.045059Z', 'enqueued_at': '2021-03-30T08:48:00.235622Z', 'started_at': '2021-03-30T08:51:10.889128Z', 'ended_at': '2021-03-30T08:51:34.493330Z', 'timeout': '180', 'label': None}] Retrieve results Once the jobs have finished their results can be retrieved from the queue. def get_job_results ( base_url , headers , job_ids ): \"\"\"Get job results\"\"\" results = [] for job_id in job_ids : # Construct URL used to obtain results url = base_url + f 'jobs/ { job_id } /results' print ( \"Job results URL:\" , url ) # Submit request and retrieve job results response = requests . get ( url = url , headers = headers ) results . append ( response . json ()) return results # Get all job IDs for which results should be returned job_ids = [ i . get ( 'job_info' ) . get ( 'job_id' ) for i in jobs ] # Retrieve job results from queue job_results = get_job_results ( base_url = base_url , headers = headers , job_ids = job_ids ) Job results URL: https://dispatch.envector.com/api/v1/jobs/2fadff43-062a-4f8e-9800-fc22b93ac944/results Job results URL: https://dispatch.envector.com/api/v1/jobs/57e16dc7-5432-433a-9931-0b6b4c8cda0d/results Job results URL: https://dispatch.envector.com/api/v1/jobs/c5297e65-84aa-4201-9a2e-7178ff4dc984/results Job results URL: https://dispatch.envector.com/api/v1/jobs/163bfb6f-c280-4c21-934a-071d9dd3f1e5/results Job results URL: https://dispatch.envector.com/api/v1/jobs/1ad65c5d-2d80-4cf7-adab-d96c07f3628e/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9eca7650-f6d7-4d0d-ac2c-2873f386fbf6/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9df0ef60-1204-47de-892f-9aa3b8d4f01f/results Job results URL: https://dispatch.envector.com/api/v1/jobs/af795b22-0ec3-4a09-aa8c-1bef4bf576b2/results Job results URL: https://dispatch.envector.com/api/v1/jobs/12d696bd-174c-450d-b791-6f09d2b1de69/results Job results URL: https://dispatch.envector.com/api/v1/jobs/90f430ed-b3b4-4b56-a879-07df10b22207/results Job results URL: https://dispatch.envector.com/api/v1/jobs/f59b729a-7dd9-40fd-b049-51a18b3a1e46/results The following function searches a results dictionary for the energy price corresponding to a given region. This will allow us to examine how the energy price changes as the @DF parameter is augmented. def get_region_energy_price ( results , region_id ): \"\"\"Extract energy price from results dictionary\"\"\" expression = ( f \"results \\ .output \\ .RegionSolution[?(@RegionID=' { region_id } ')] \\ .@EnergyPrice\" ) jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( results )] # Only one value should be returned if len ( values ) != 1 : msg = f \"Should only return 1 value, encountered: { len ( values ) } { region_id } \" raise Exception ( msg ) return values [ 0 ] Job IDs are used to map Demand Forecast parameters to price outcomes. def map_parameters_to_prices ( jobs , results , region_id ): \"\"\"Map demand forecast parameters to energy prices\"\"\" # Key = job_id, value = Demand Forecast parameter demand_forecast = { job . get ( 'job_info' ) . get ( 'job_id' ): job . get ( 'demand_forecast' ) for job in jobs } # Energy prices indexed by job ID prices = { result . get ( 'job_id' ): get_region_energy_price ( results = result , region_id = region_id ) for result in results } # Combine into list of tuples [(demand_forecast, price), ...] values = [( demand_forecast . get ( job_id ), prices . get ( job_id )) for job_id in prices . keys ()] return sorted ( values , key = lambda x : x [ 0 ]) # Price results price_results = map_parameters_to_prices ( jobs = jobs , results = job_results , region_id = 'SA1' ) The results can be plotted to reveal the relationship between @DF values and energy prices in South Australia. # Unzip for plotting x , y = zip ( * price_results ) # Plotting results fig , ax = plt . subplots () ax . plot ( x , y , 'o' , alpha = 0.7 , color = 'b' ) ax . plot ( x , y , '-' , alpha = 0.7 , color = 'r' ) ax . set_title ( 'SA energy price response to changes in Demand Forecast' ) ax . set_xlabel ( 'SA Demand Forecast (MW)' ) ax . set_ylabel ( 'SA Energy Price ($/MWh)' ) plt . show () The plot illustrates the range of @DF values over which the energy price in South Australia is unaffected, and also the @DF values which begin to alter prices. This type of analysis can help identify how sensitive prices are to changes in demand. Summary This notebook outlines a workflow that can be used to perform sensitivity analyses. Relationships between other parameters and variables can be readily investigated, making the Dispatch API a flexibile tool that can facilitate a number of different studies. For instance, one may wish to know how prices or other system variables are impacted by a contingency such as sudden reduction in interconnector power flow limits, or the tripping of a generator. While this tutorial has used historical data to perform an ex-post sensitivity analysis, the Dispatch API can also be used with customised case files. This lends the Dispatch API to a number of forecasting applications - user supplied forecasts for case file parameters could allow sensitivies to be computed in real time.","title":"Scenario analysis - line plot"},{"location":"tutorials/scenario-analysis-line-plot/#scenario-analysis-creating-a-line-plot","text":"The ability to examine relationships between system parameters and system variables is a powerful capability offered by the Dispatch API. This notebook outlines a workflow that can be used to perform ex-post scenario analyses using historical case file data. While the following sections examine how changes to demand forecasts would likely influences prices in a given region, the same principles can be applied to examine other relationships.","title":"Scenario analysis - creating a line plot"},{"location":"tutorials/scenario-analysis-line-plot/#imports-and-authentication","text":"import os import json import requests from dotenv import load_dotenv import matplotlib.pyplot as plt from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = '3zd62ngkjzkqleo3ibvjsnq359n23b4gjdvbk41f' TOKEN = os . getenv ( 'TOKEN' ) # Base URL endpoint for the Dispatch API base_url = 'https://dispatch.envector.com/api/v1/' # Headers must be included to authenticate requests headers = { 'Authorization' : f 'Token { TOKEN } ' }","title":"Imports and authentication"},{"location":"tutorials/scenario-analysis-line-plot/#download-case-file","text":"We need some data to work with, so let's proceed by downloading a case file. def download_casefile ( base_url , headers , case_id ): \"\"\"Download case file and save to disk\"\"\" # URL to download case file url = base_url + f 'data/casefile/ { case_id } ' print ( \"Download case file URL:\" , url ) # Download case file and save to disk response = requests . get ( url = url , headers = headers ) # Load JSON response as Python dictionary casefile = response . json () # Save file filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'w' ) as f : json . dump ( casefile , f ) return casefile def load_casefile ( case_id ): \"\"\"Load case file\"\"\" filename = f ' { case_id } _casefile.json' path_to_file = os . path . join ( os . path . curdir , 'output' , filename ) with open ( path_to_file , 'r' ) as f : casefile = json . load ( f ) return casefile # Download case file download_casefile ( base_url = base_url , headers = headers , case_id = '20201101001' ) # Load case file casefile = load_casefile ( case_id = '20201101001' ) Download case file URL: https://dispatch.envector.com/api/v1/data/casefile/20201101001","title":"Download case file"},{"location":"tutorials/scenario-analysis-line-plot/#approach","text":"It is always a good idea to separate data from logic. Let's treat the case file that we saved to disk as our canonical 'source of truth', with this 'base' case file loaded before performing each update. As this case file will never be overwritten we can be sure we're using the same data before making updates, thus reducing the possibilty of introducing unintended changes. The following function reads the base case file from disk then updates the Demand Forecast ( @DF ) parameter for South Australia. This allows us to investigate how prices respond to changes in anticipated demand. def update_region_demand_forecast ( case_id , region_id , value ): \"\"\"Load case file and update demand forecast for a given region\"\"\" # Load case file load_casefile ( case_id = case_id ) # Construct expression expression = ( f \"NEMSPDCaseFile \\ .NemSpdInputs \\ .PeriodCollection \\ .Period \\ .RegionPeriodCollection \\ .RegionPeriod[?(@RegionID==' { region_id } ')] \\ .@DF\" ) # Construct JSON path expression jsonpath_expr = parse ( expression ) # Update value _ = jsonpath_expr . update ( casefile , value ) return casefile Jobs are submitted to the online queue, with each job having a different @DF value. Job IDs will be used to map @DF parameters to results once they are available. def submit_jobs ( base_url , headers , region_id , values ): \"\"\"Submit jobs to online queue\"\"\" jobs = [] for i in values : # Construct request body - using augmented casefiles body = { \"casefile\" : update_region_demand_forecast ( case_id = '20201101001' , region_id = region_id , value = i )} # Submit request and extract job ID url = base_url + 'jobs/create' response = requests . post ( url = url , headers = headers , json = body ) job_info = response . json () # Construct a map between the job ID, job info and the value of the parameter used in the analysis jobs . append ({ 'job_info' : job_info , 'demand_forecast' : i }) return jobs # Demand forecast parameters values = [ - 50 , - 40 , - 30 , - 20 , - 10 , 0 , 10 , 20 , 30 , 40 , 50 ] jobs = submit_jobs ( base_url = base_url , headers = headers , region_id = 'SA1' , values = values ) We can check the status of all our jobs by using the following endpoint: https://dispatch.envector.com/api/v1/jobs/status/list def get_status ( base_url , headers ): \"\"\"Get status of all jobs\"\"\" url = base_url + 'jobs/status/list' response = requests . get ( url = url , headers = headers ) status = response . json () return status # Get job status list status = get_status ( base_url = base_url , headers = headers ) # Only printing the first three jobs (to save space) status [: 3 ] [{'job_id': 'f59b729a-7dd9-40fd-b049-51a18b3a1e46', 'status': 'finished', 'created_at': '2021-03-30T08:48:02.162896Z', 'enqueued_at': '2021-03-30T08:48:02.356483Z', 'started_at': '2021-03-30T08:52:03.755665Z', 'ended_at': '2021-03-30T08:52:33.031707Z', 'timeout': '180', 'label': None}, {'job_id': '90f430ed-b3b4-4b56-a879-07df10b22207', 'status': 'finished', 'created_at': '2021-03-30T08:48:01.100274Z', 'enqueued_at': '2021-03-30T08:48:01.291683Z', 'started_at': '2021-03-30T08:51:34.649039Z', 'ended_at': '2021-03-30T08:52:03.601137Z', 'timeout': '180', 'label': None}, {'job_id': '12d696bd-174c-450d-b791-6f09d2b1de69', 'status': 'finished', 'created_at': '2021-03-30T08:48:00.045059Z', 'enqueued_at': '2021-03-30T08:48:00.235622Z', 'started_at': '2021-03-30T08:51:10.889128Z', 'ended_at': '2021-03-30T08:51:34.493330Z', 'timeout': '180', 'label': None}]","title":"Approach"},{"location":"tutorials/scenario-analysis-line-plot/#retrieve-results","text":"Once the jobs have finished their results can be retrieved from the queue. def get_job_results ( base_url , headers , job_ids ): \"\"\"Get job results\"\"\" results = [] for job_id in job_ids : # Construct URL used to obtain results url = base_url + f 'jobs/ { job_id } /results' print ( \"Job results URL:\" , url ) # Submit request and retrieve job results response = requests . get ( url = url , headers = headers ) results . append ( response . json ()) return results # Get all job IDs for which results should be returned job_ids = [ i . get ( 'job_info' ) . get ( 'job_id' ) for i in jobs ] # Retrieve job results from queue job_results = get_job_results ( base_url = base_url , headers = headers , job_ids = job_ids ) Job results URL: https://dispatch.envector.com/api/v1/jobs/2fadff43-062a-4f8e-9800-fc22b93ac944/results Job results URL: https://dispatch.envector.com/api/v1/jobs/57e16dc7-5432-433a-9931-0b6b4c8cda0d/results Job results URL: https://dispatch.envector.com/api/v1/jobs/c5297e65-84aa-4201-9a2e-7178ff4dc984/results Job results URL: https://dispatch.envector.com/api/v1/jobs/163bfb6f-c280-4c21-934a-071d9dd3f1e5/results Job results URL: https://dispatch.envector.com/api/v1/jobs/1ad65c5d-2d80-4cf7-adab-d96c07f3628e/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9eca7650-f6d7-4d0d-ac2c-2873f386fbf6/results Job results URL: https://dispatch.envector.com/api/v1/jobs/9df0ef60-1204-47de-892f-9aa3b8d4f01f/results Job results URL: https://dispatch.envector.com/api/v1/jobs/af795b22-0ec3-4a09-aa8c-1bef4bf576b2/results Job results URL: https://dispatch.envector.com/api/v1/jobs/12d696bd-174c-450d-b791-6f09d2b1de69/results Job results URL: https://dispatch.envector.com/api/v1/jobs/90f430ed-b3b4-4b56-a879-07df10b22207/results Job results URL: https://dispatch.envector.com/api/v1/jobs/f59b729a-7dd9-40fd-b049-51a18b3a1e46/results The following function searches a results dictionary for the energy price corresponding to a given region. This will allow us to examine how the energy price changes as the @DF parameter is augmented. def get_region_energy_price ( results , region_id ): \"\"\"Extract energy price from results dictionary\"\"\" expression = ( f \"results \\ .output \\ .RegionSolution[?(@RegionID=' { region_id } ')] \\ .@EnergyPrice\" ) jsonpath_expr = parse ( expression ) values = [ match . value for match in jsonpath_expr . find ( results )] # Only one value should be returned if len ( values ) != 1 : msg = f \"Should only return 1 value, encountered: { len ( values ) } { region_id } \" raise Exception ( msg ) return values [ 0 ] Job IDs are used to map Demand Forecast parameters to price outcomes. def map_parameters_to_prices ( jobs , results , region_id ): \"\"\"Map demand forecast parameters to energy prices\"\"\" # Key = job_id, value = Demand Forecast parameter demand_forecast = { job . get ( 'job_info' ) . get ( 'job_id' ): job . get ( 'demand_forecast' ) for job in jobs } # Energy prices indexed by job ID prices = { result . get ( 'job_id' ): get_region_energy_price ( results = result , region_id = region_id ) for result in results } # Combine into list of tuples [(demand_forecast, price), ...] values = [( demand_forecast . get ( job_id ), prices . get ( job_id )) for job_id in prices . keys ()] return sorted ( values , key = lambda x : x [ 0 ]) # Price results price_results = map_parameters_to_prices ( jobs = jobs , results = job_results , region_id = 'SA1' ) The results can be plotted to reveal the relationship between @DF values and energy prices in South Australia. # Unzip for plotting x , y = zip ( * price_results ) # Plotting results fig , ax = plt . subplots () ax . plot ( x , y , 'o' , alpha = 0.7 , color = 'b' ) ax . plot ( x , y , '-' , alpha = 0.7 , color = 'r' ) ax . set_title ( 'SA energy price response to changes in Demand Forecast' ) ax . set_xlabel ( 'SA Demand Forecast (MW)' ) ax . set_ylabel ( 'SA Energy Price ($/MWh)' ) plt . show () The plot illustrates the range of @DF values over which the energy price in South Australia is unaffected, and also the @DF values which begin to alter prices. This type of analysis can help identify how sensitive prices are to changes in demand.","title":"Retrieve results"},{"location":"tutorials/scenario-analysis-line-plot/#summary","text":"This notebook outlines a workflow that can be used to perform sensitivity analyses. Relationships between other parameters and variables can be readily investigated, making the Dispatch API a flexibile tool that can facilitate a number of different studies. For instance, one may wish to know how prices or other system variables are impacted by a contingency such as sudden reduction in interconnector power flow limits, or the tripping of a generator. While this tutorial has used historical data to perform an ex-post sensitivity analysis, the Dispatch API can also be used with customised case files. This lends the Dispatch API to a number of forecasting applications - user supplied forecasts for case file parameters could allow sensitivies to be computed in real time.","title":"Summary"},{"location":"tutorials/validating-results/","text":"Validating results It is useful to know how well the Dispatch API approximates NEMDE outputs when presented with historical data. As NEMDE outputs are contained within the NemSpdOutput section of historical case files it is possible to backtest the Dispatch API's results against these data. The following sections discuss a feature of the Dispatch API that makes it easy to backtest results. Imports and authentication import os import json import requests import pandas as pd from dotenv import load_dotenv import matplotlib.pyplot as plt from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse import IPython.display as display # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = 'd97f0be5-df17-4332-91d8-16c6bbca0b6d' TOKEN = os . getenv ( 'TOKEN' ) # A valid API token must be included when making requests headers = { 'Authorization' : f 'Token { TOKEN } ' } # Base URL endpoint for the Dispatch API # base_url = 'https://dispatch.envector.com/api/v1/' base_url = 'http://dispatch.localhost/api/v1/' Submit validation job In the pervious tutorials case files were submitted when creating jobs. Alternatively, the Dispatch API can be backtested against NEMDE by specifying a case ID, and including an option that will append the NEMDE solution to the results returned. This makes it easier to compare the solution returned by the Dispatch API with the 'actual' solution returned by NEMDE. For example, if we sought to validate the model using data obtained from a case file with case ID 20201101001 the request body would be formulated as: body = { \"case_id\": \"20201101001\", \"options\": { \"solution_format\": \"validation\" } } This instructs the Dispatch API to create a job using data from the specified case, and compares the results obtained with those found in the NemSpdOutputs section of the case file (i.e. the Dispatch API's results are compared against the solution obtained by NEMDE). def submit_validation_job ( base_url , headers , case_id ): \"\"\" Validate Dispatch API results for a given case ID Parameters ---------- base_url : str Base URL for the Dispatch API headers : dict Contains auth token used to authenticate requests case_id : str Case ID for which validation should be performed e.g. '20201101001'. The format for case_id is as follows: {year}{month}{day}{interval_id} where interval_id is in [001, ..., 288]. Returns ------- job_info : dict Response obtained from API when job is submitted. Includes the job's ID. \"\"\" # Construct URL request body url = base_url + 'jobs/create' # Request body body = { 'case_id' : case_id , 'options' : { 'solution_format' : 'validation' } } # Make request headers = { 'Authorization' : f 'Token { TOKEN } ' } response = requests . post ( url = url , headers = headers , json = body ) # Information pertaining to the submitted job - includes job_id job_info = response . json () return job_info # Submit validation job to the queue job_info = submit_validation_job ( base_url = base_url , headers = headers , case_id = '20201101001' ) job_info {'job_id': '4d0a835a-f91c-4db1-96cd-6587a5b8d720', 'created_at': '2021-03-12T06:26:41.249334Z', 'enqueued_at': '2021-03-12T06:26:41.249445Z', 'timeout': 180, 'status': 'queued', 'label': None} Explore results First, let's retrieve results from the queue. def get_job_results ( base_url , headers , job_id ): \"\"\"Extract job results from the queue\"\"\" url = base_url + f 'jobs/ { job_id } /results' response = requests . get ( url = url , headers = headers ) return response . json () # Get job results from the queue job_id = job_info . get ( 'job_id' ) job_results = get_job_results ( base_url = base_url , headers = headers , job_id = job_id ) Pandas can be used to observe the difference between results obtained from the Dispatch API and results obtained from NEMDE. Results obtained from the Dispatch API are in the model column, while results corresponding to the NEMDE solution are in the column titled actual . Period solution This component of the solution provides the value of the objective function, along with aggregate metrics pertaining to constraint violations. period_solution = job_results . get ( 'results' ) . get ( 'output' ) . get ( 'PeriodSolution' ) # Convert to markdown to display results period_solution_md = pd . DataFrame ( period_solution ) . to_markdown ( index = False ) display . Markdown ( period_solution_md ) case_id intervention key model actual 20201101001 0 @TotalObjective -1.05408e+07 -1.05408e+07 20201101001 0 @TotalInterconnectorViolation 0 0 20201101001 0 @TotalGenericViolation 0 0 20201101001 0 @TotalRampRateViolation 0 0 20201101001 0 @TotalUnitMWCapacityViolation 0 0 20201101001 0 @TotalFastStartViolation 0 0 20201101001 0 @TotalMNSPRampRateViolation 0 0 20201101001 0 @TotalMNSPOfferViolation 0 0 20201101001 0 @TotalMNSPCapacityViolation 0 0 20201101001 0 @TotalUIGFViolation 0 0 Region solution Aggregate generation and load dispatched within each region, along with net power flow out of the region and the wholesale electricity price. region_solution = job_results . get ( 'results' ) . get ( 'output' ) . get ( 'RegionSolution' ) # Convert to markdown to display results region_solution_md = ( pd . DataFrame ( region_solution ) . head ( 20 ) . to_markdown ( index = False )) display . Markdown ( region_solution_md ) region_id intervention case_id key model actual NSW1 0 20201101001 @DispatchedGeneration 5818.37 5818.37 NSW1 0 20201101001 @DispatchedLoad 0 0 NSW1 0 20201101001 @FixedDemand 5654.29 5654.29 NSW1 0 20201101001 @NetExport 164.078 164.08 NSW1 0 20201101001 @SurplusGeneration 0 0 NSW1 0 20201101001 @EnergyPrice 41.6999 41.6997 NSW1 0 20201101001 @R6Dispatch 213 213 NSW1 0 20201101001 @R60Dispatch 196 196 NSW1 0 20201101001 @R5Dispatch 68 52 NSW1 0 20201101001 @R5RegDispatch 118.172 118.17 NSW1 0 20201101001 @L6Dispatch 112.354 112.35 NSW1 0 20201101001 @L60Dispatch 173 173 NSW1 0 20201101001 @L5Dispatch 78.968 78.97 NSW1 0 20201101001 @L5RegDispatch 34 34 NSW1 0 20201101001 @ClearedDemand 5660.54 5660.54 QLD1 0 20201101001 @DispatchedGeneration 5232.56 5232.56 QLD1 0 20201101001 @DispatchedLoad 0 0 QLD1 0 20201101001 @FixedDemand 5113.69 5113.69 QLD1 0 20201101001 @NetExport 118.868 118.87 QLD1 0 20201101001 @SurplusGeneration 0 0 Trader solution Dispatch targets for each trade type are reported. Ramp rates and fast start unit parameters are also included for some traders. trader_solution = job_results . get ( 'results' ) . get ( 'output' ) . get ( 'TraderSolution' ) # Convert to markdown to display results trader_solution_md = ( pd . DataFrame ( trader_solution ) . head ( 20 ) . to_markdown ( index = False )) display . Markdown ( trader_solution_md ) case_id intervention trader_id key model actual 20201101001 0 AGLHAL @R6Target 0 0 20201101001 0 AGLHAL @R60Target 0 0 20201101001 0 AGLHAL @R5Target 0 0 20201101001 0 AGLHAL @R5RegTarget 0 0 20201101001 0 AGLHAL @L6Target 0 0 20201101001 0 AGLHAL @L60Target 0 0 20201101001 0 AGLHAL @L5Target 0 0 20201101001 0 AGLHAL @L5RegTarget 0 0 20201101001 0 AGLHAL @R6Violation 0 0 20201101001 0 AGLHAL @R60Violation 0 0 20201101001 0 AGLHAL @R5Violation 0 0 20201101001 0 AGLHAL @R5RegViolation 0 0 20201101001 0 AGLHAL @L6Violation 0 0 20201101001 0 AGLHAL @L60Violation 0 0 20201101001 0 AGLHAL @L5Violation 0 0 20201101001 0 AGLHAL @L5RegViolation 0 0 20201101001 0 AGLHAL @EnergyTarget 0 0 20201101001 0 AGLHAL @RampUpRate 720 720 20201101001 0 AGLHAL @RampDnRate 720 720 20201101001 0 AGLHAL @FSTargetMode 0 0 Interconnector solution Power flow over each interconnector along with its associated losses are reported. The amount by which power flow constraints are violated is given by the value corresponding to the @Deficit key. interconnector_solution = ( job_results . get ( 'results' ) . get ( 'output' ) . get ( 'InterconnectorSolution' )) # Convert to markdown to display results interconnector_solution_md = ( pd . DataFrame ( interconnector_solution ) . head ( 20 ) . to_markdown ( index = False )) display . Markdown ( interconnector_solution_md ) interconnector_id case_id intervention key model actual N-Q-MNSP1 20201101001 0 @Flow -33 -33 N-Q-MNSP1 20201101001 0 @Losses -0.591673 -0.59167 N-Q-MNSP1 20201101001 0 @Deficit 0 0 NSW1-QLD1 20201101001 0 @Flow -86.0011 -86.0011 NSW1-QLD1 20201101001 0 @Losses 0.306671 0.30667 NSW1-QLD1 20201101001 0 @Deficit 0 0 T-V-MNSP1 20201101001 0 @Flow -222.507 -222.507 T-V-MNSP1 20201101001 0 @Losses 6.01955 6.01955 T-V-MNSP1 20201101001 0 @Deficit 0 0 V-S-MNSP1 20201101001 0 @Flow 45 45 V-S-MNSP1 20201101001 0 @Losses -0.856901 -0.8569 V-S-MNSP1 20201101001 0 @Deficit 0 0 V-SA 20201101001 0 @Flow 50 50 V-SA 20201101001 0 @Losses 0.60394 0.60394 V-SA 20201101001 0 @Deficit 0 0 VIC1-NSW1 20201101001 0 @Flow -276.834 -276.834 VIC1-NSW1 20201101001 0 @Losses 10.8428 10.8428 VIC1-NSW1 20201101001 0 @Deficit 0 0 Constraint solution The right-hand side (RHS) value of each constraint along with the amount by which it is violated, given by @Deficit , is reported in the constraint solution. The Dispatch API obtains generic constraint RHS values from the NemSpdOutputs section of a case file when formulating the mathematical program to be solved. This is a limitation of the Dispatch API . Please the see the caveats section for more details. Consequently, there will be no difference between model and actual @RHS values for all constraints. However, the @Deficit attribute is obtained from the Dispatch API's solution, so differences may be observed for this key. constraint_solution = ( job_results . get ( 'results' ) . get ( 'output' ) . get ( 'ConstraintSolution' )) # Convert to markdown to display results constraint_solution_md = ( pd . DataFrame ( constraint_solution ) . head () . to_markdown ( index = False )) display . Markdown ( constraint_solution_md ) case_id intervention constraint_id key model actual 20201101001 0 #BBTHREE3_E @RHS 25 25 20201101001 0 #BBTHREE3_E @Deficit 0 0 20201101001 0 #BULGANA1_E @RHS 100 100 20201101001 0 #BULGANA1_E @Deficit 0 0 20201101001 0 #COOPGWF1_E @RHS 329 329 Evaluating the Dispatch API Let's use a few plots to see how dispatch targets obtained from the Dispatch API compare with results outputted by NEMDE. def plot_solution ( solution , key ): \"\"\"Plot 'model' vs 'actual' solution for a given key\"\"\" # Convert to DataFrame df = pd . DataFrame ( solution ) # Initialise figure fig , ax = plt . subplots () # Plot results for a given key ax = df . loc [ df [ 'key' ] == key , :] . plot . scatter ( ax = ax , x = 'model' , y = 'actual' ) # Plot line with slope = 1 min_value = df . loc [ df [ 'key' ] == key , [ 'model' , 'actual' ]] . min () . min () max_value = df . loc [ df [ 'key' ] == key , [ 'model' , 'actual' ]] . max () . max () line_style = { 'color' : 'k' , 'linestyle' : '--' , 'alpha' : 0.5 } ax . plot ([ min_value , max_value ], [ min_value , max_value ], ** line_style ) # Set title ax . set_title ( key ) ax . set_xlabel ( 'Model (MW)' ) ax . set_ylabel ( 'Actual (MW)' ) plt . show () # Check the @EnergyTarget solution for all traders plot_solution ( solution = trader_solution , key = '@EnergyTarget' ) Each point corresponds to a trader. The horizontal axis corresponds to the target output level obtained from the Dispatch API, while the vertical axis shows targets produced by NEMDE. The dashed line has a slope equal to one, indicating the region over which the Dispatch API's solution equals the NEMDE solution. Points close to the dashed line indicate close correspondence between the Dispatch API's solution and the solution obtained by NEMDE. Plots can be constructed for the remaining trade types: keys = [ '@R6Target' , '@R60Target' , '@R5Target' , '@R5RegTarget' , '@L6Target' , '@L60Target' , '@L5Target' , '@L5RegTarget' ] for i in keys : plot_solution ( solution = trader_solution , key = i ) Objective function value The value of the objective function at optimality provides a useful heuristic when comparing the solution obtained from the Dispatch API with the results outputted by NEMDE. Small perturbations to input parameters or constraint formulations can manifest as large differences in the objective function's value. It's unlikely there would be close correspondence between these values if the Dispatch API's formulation was a manifestly innaccurate approximation of NEMDE. Let's examine the objective function values: # objective = period_solution.loc['@TotalObjective'] objective = [ i for i in period_solution if i . get ( 'key' ) == '@TotalObjective' ][ 0 ] objective {'case_id': '20201101001', 'intervention': '0', 'key': '@TotalObjective', 'model': -10540805.66769616, 'actual': -10540790.07213} We can also compute the absolute and relative difference. difference = objective . get ( 'model' ) - objective . get ( 'actual' ) relative_difference = difference / objective . get ( 'actual' ) print ( \"Difference:\" , difference ) print ( \"Relative difference:\" , relative_difference ) Difference: -15.595566159114242 Relative difference: 1.4795443275498999e-06 The relative difference is very small at approximately 0.000148 %. At this level solver settings, such as tolerances, and floating point precision could be coming into play. Summary This notebook examined strategies that can be used to validate model outputs. Reasons for discrepancies between the Dispatch API's solution and results obtained from NEMDE were also discussed, including features of the NEMDE's mathematical formulation that may result in non-unique solutions being returned. Without the ability to examine the mathematical forumulation used by NEMDE definitive model validation is impossible. Instead, we must adopt a data-driven approach when evaluating the Dispatch API's performance. The model validation section extends the analysis presented above by comparing dispatch outcomes over thousands of dispatch intervals. This process of experimentation and followed by diagnostic analysis helps identify areas in which the Dispatch API's model formulation can be improved.","title":"Validating results"},{"location":"tutorials/validating-results/#validating-results","text":"It is useful to know how well the Dispatch API approximates NEMDE outputs when presented with historical data. As NEMDE outputs are contained within the NemSpdOutput section of historical case files it is possible to backtest the Dispatch API's results against these data. The following sections discuss a feature of the Dispatch API that makes it easy to backtest results.","title":"Validating results"},{"location":"tutorials/validating-results/#imports-and-authentication","text":"import os import json import requests import pandas as pd from dotenv import load_dotenv import matplotlib.pyplot as plt from jsonpath_ng import jsonpath from jsonpath_ng.ext import parse import IPython.display as display # Load environment variables load_dotenv () # Replace with your API token # E.g. TOKEN = 'd97f0be5-df17-4332-91d8-16c6bbca0b6d' TOKEN = os . getenv ( 'TOKEN' ) # A valid API token must be included when making requests headers = { 'Authorization' : f 'Token { TOKEN } ' } # Base URL endpoint for the Dispatch API # base_url = 'https://dispatch.envector.com/api/v1/' base_url = 'http://dispatch.localhost/api/v1/'","title":"Imports and authentication"},{"location":"tutorials/validating-results/#submit-validation-job","text":"In the pervious tutorials case files were submitted when creating jobs. Alternatively, the Dispatch API can be backtested against NEMDE by specifying a case ID, and including an option that will append the NEMDE solution to the results returned. This makes it easier to compare the solution returned by the Dispatch API with the 'actual' solution returned by NEMDE. For example, if we sought to validate the model using data obtained from a case file with case ID 20201101001 the request body would be formulated as: body = { \"case_id\": \"20201101001\", \"options\": { \"solution_format\": \"validation\" } } This instructs the Dispatch API to create a job using data from the specified case, and compares the results obtained with those found in the NemSpdOutputs section of the case file (i.e. the Dispatch API's results are compared against the solution obtained by NEMDE). def submit_validation_job ( base_url , headers , case_id ): \"\"\" Validate Dispatch API results for a given case ID Parameters ---------- base_url : str Base URL for the Dispatch API headers : dict Contains auth token used to authenticate requests case_id : str Case ID for which validation should be performed e.g. '20201101001'. The format for case_id is as follows: {year}{month}{day}{interval_id} where interval_id is in [001, ..., 288]. Returns ------- job_info : dict Response obtained from API when job is submitted. Includes the job's ID. \"\"\" # Construct URL request body url = base_url + 'jobs/create' # Request body body = { 'case_id' : case_id , 'options' : { 'solution_format' : 'validation' } } # Make request headers = { 'Authorization' : f 'Token { TOKEN } ' } response = requests . post ( url = url , headers = headers , json = body ) # Information pertaining to the submitted job - includes job_id job_info = response . json () return job_info # Submit validation job to the queue job_info = submit_validation_job ( base_url = base_url , headers = headers , case_id = '20201101001' ) job_info {'job_id': '4d0a835a-f91c-4db1-96cd-6587a5b8d720', 'created_at': '2021-03-12T06:26:41.249334Z', 'enqueued_at': '2021-03-12T06:26:41.249445Z', 'timeout': 180, 'status': 'queued', 'label': None}","title":"Submit validation job"},{"location":"tutorials/validating-results/#explore-results","text":"First, let's retrieve results from the queue. def get_job_results ( base_url , headers , job_id ): \"\"\"Extract job results from the queue\"\"\" url = base_url + f 'jobs/ { job_id } /results' response = requests . get ( url = url , headers = headers ) return response . json () # Get job results from the queue job_id = job_info . get ( 'job_id' ) job_results = get_job_results ( base_url = base_url , headers = headers , job_id = job_id ) Pandas can be used to observe the difference between results obtained from the Dispatch API and results obtained from NEMDE. Results obtained from the Dispatch API are in the model column, while results corresponding to the NEMDE solution are in the column titled actual .","title":"Explore results"},{"location":"tutorials/validating-results/#period-solution","text":"This component of the solution provides the value of the objective function, along with aggregate metrics pertaining to constraint violations. period_solution = job_results . get ( 'results' ) . get ( 'output' ) . get ( 'PeriodSolution' ) # Convert to markdown to display results period_solution_md = pd . DataFrame ( period_solution ) . to_markdown ( index = False ) display . Markdown ( period_solution_md ) case_id intervention key model actual 20201101001 0 @TotalObjective -1.05408e+07 -1.05408e+07 20201101001 0 @TotalInterconnectorViolation 0 0 20201101001 0 @TotalGenericViolation 0 0 20201101001 0 @TotalRampRateViolation 0 0 20201101001 0 @TotalUnitMWCapacityViolation 0 0 20201101001 0 @TotalFastStartViolation 0 0 20201101001 0 @TotalMNSPRampRateViolation 0 0 20201101001 0 @TotalMNSPOfferViolation 0 0 20201101001 0 @TotalMNSPCapacityViolation 0 0 20201101001 0 @TotalUIGFViolation 0 0","title":"Period solution"},{"location":"tutorials/validating-results/#region-solution","text":"Aggregate generation and load dispatched within each region, along with net power flow out of the region and the wholesale electricity price. region_solution = job_results . get ( 'results' ) . get ( 'output' ) . get ( 'RegionSolution' ) # Convert to markdown to display results region_solution_md = ( pd . DataFrame ( region_solution ) . head ( 20 ) . to_markdown ( index = False )) display . Markdown ( region_solution_md ) region_id intervention case_id key model actual NSW1 0 20201101001 @DispatchedGeneration 5818.37 5818.37 NSW1 0 20201101001 @DispatchedLoad 0 0 NSW1 0 20201101001 @FixedDemand 5654.29 5654.29 NSW1 0 20201101001 @NetExport 164.078 164.08 NSW1 0 20201101001 @SurplusGeneration 0 0 NSW1 0 20201101001 @EnergyPrice 41.6999 41.6997 NSW1 0 20201101001 @R6Dispatch 213 213 NSW1 0 20201101001 @R60Dispatch 196 196 NSW1 0 20201101001 @R5Dispatch 68 52 NSW1 0 20201101001 @R5RegDispatch 118.172 118.17 NSW1 0 20201101001 @L6Dispatch 112.354 112.35 NSW1 0 20201101001 @L60Dispatch 173 173 NSW1 0 20201101001 @L5Dispatch 78.968 78.97 NSW1 0 20201101001 @L5RegDispatch 34 34 NSW1 0 20201101001 @ClearedDemand 5660.54 5660.54 QLD1 0 20201101001 @DispatchedGeneration 5232.56 5232.56 QLD1 0 20201101001 @DispatchedLoad 0 0 QLD1 0 20201101001 @FixedDemand 5113.69 5113.69 QLD1 0 20201101001 @NetExport 118.868 118.87 QLD1 0 20201101001 @SurplusGeneration 0 0","title":"Region solution"},{"location":"tutorials/validating-results/#trader-solution","text":"Dispatch targets for each trade type are reported. Ramp rates and fast start unit parameters are also included for some traders. trader_solution = job_results . get ( 'results' ) . get ( 'output' ) . get ( 'TraderSolution' ) # Convert to markdown to display results trader_solution_md = ( pd . DataFrame ( trader_solution ) . head ( 20 ) . to_markdown ( index = False )) display . Markdown ( trader_solution_md ) case_id intervention trader_id key model actual 20201101001 0 AGLHAL @R6Target 0 0 20201101001 0 AGLHAL @R60Target 0 0 20201101001 0 AGLHAL @R5Target 0 0 20201101001 0 AGLHAL @R5RegTarget 0 0 20201101001 0 AGLHAL @L6Target 0 0 20201101001 0 AGLHAL @L60Target 0 0 20201101001 0 AGLHAL @L5Target 0 0 20201101001 0 AGLHAL @L5RegTarget 0 0 20201101001 0 AGLHAL @R6Violation 0 0 20201101001 0 AGLHAL @R60Violation 0 0 20201101001 0 AGLHAL @R5Violation 0 0 20201101001 0 AGLHAL @R5RegViolation 0 0 20201101001 0 AGLHAL @L6Violation 0 0 20201101001 0 AGLHAL @L60Violation 0 0 20201101001 0 AGLHAL @L5Violation 0 0 20201101001 0 AGLHAL @L5RegViolation 0 0 20201101001 0 AGLHAL @EnergyTarget 0 0 20201101001 0 AGLHAL @RampUpRate 720 720 20201101001 0 AGLHAL @RampDnRate 720 720 20201101001 0 AGLHAL @FSTargetMode 0 0","title":"Trader solution"},{"location":"tutorials/validating-results/#interconnector-solution","text":"Power flow over each interconnector along with its associated losses are reported. The amount by which power flow constraints are violated is given by the value corresponding to the @Deficit key. interconnector_solution = ( job_results . get ( 'results' ) . get ( 'output' ) . get ( 'InterconnectorSolution' )) # Convert to markdown to display results interconnector_solution_md = ( pd . DataFrame ( interconnector_solution ) . head ( 20 ) . to_markdown ( index = False )) display . Markdown ( interconnector_solution_md ) interconnector_id case_id intervention key model actual N-Q-MNSP1 20201101001 0 @Flow -33 -33 N-Q-MNSP1 20201101001 0 @Losses -0.591673 -0.59167 N-Q-MNSP1 20201101001 0 @Deficit 0 0 NSW1-QLD1 20201101001 0 @Flow -86.0011 -86.0011 NSW1-QLD1 20201101001 0 @Losses 0.306671 0.30667 NSW1-QLD1 20201101001 0 @Deficit 0 0 T-V-MNSP1 20201101001 0 @Flow -222.507 -222.507 T-V-MNSP1 20201101001 0 @Losses 6.01955 6.01955 T-V-MNSP1 20201101001 0 @Deficit 0 0 V-S-MNSP1 20201101001 0 @Flow 45 45 V-S-MNSP1 20201101001 0 @Losses -0.856901 -0.8569 V-S-MNSP1 20201101001 0 @Deficit 0 0 V-SA 20201101001 0 @Flow 50 50 V-SA 20201101001 0 @Losses 0.60394 0.60394 V-SA 20201101001 0 @Deficit 0 0 VIC1-NSW1 20201101001 0 @Flow -276.834 -276.834 VIC1-NSW1 20201101001 0 @Losses 10.8428 10.8428 VIC1-NSW1 20201101001 0 @Deficit 0 0","title":"Interconnector solution"},{"location":"tutorials/validating-results/#constraint-solution","text":"The right-hand side (RHS) value of each constraint along with the amount by which it is violated, given by @Deficit , is reported in the constraint solution. The Dispatch API obtains generic constraint RHS values from the NemSpdOutputs section of a case file when formulating the mathematical program to be solved. This is a limitation of the Dispatch API . Please the see the caveats section for more details. Consequently, there will be no difference between model and actual @RHS values for all constraints. However, the @Deficit attribute is obtained from the Dispatch API's solution, so differences may be observed for this key. constraint_solution = ( job_results . get ( 'results' ) . get ( 'output' ) . get ( 'ConstraintSolution' )) # Convert to markdown to display results constraint_solution_md = ( pd . DataFrame ( constraint_solution ) . head () . to_markdown ( index = False )) display . Markdown ( constraint_solution_md ) case_id intervention constraint_id key model actual 20201101001 0 #BBTHREE3_E @RHS 25 25 20201101001 0 #BBTHREE3_E @Deficit 0 0 20201101001 0 #BULGANA1_E @RHS 100 100 20201101001 0 #BULGANA1_E @Deficit 0 0 20201101001 0 #COOPGWF1_E @RHS 329 329","title":"Constraint solution"},{"location":"tutorials/validating-results/#evaluating-the-dispatch-api","text":"Let's use a few plots to see how dispatch targets obtained from the Dispatch API compare with results outputted by NEMDE. def plot_solution ( solution , key ): \"\"\"Plot 'model' vs 'actual' solution for a given key\"\"\" # Convert to DataFrame df = pd . DataFrame ( solution ) # Initialise figure fig , ax = plt . subplots () # Plot results for a given key ax = df . loc [ df [ 'key' ] == key , :] . plot . scatter ( ax = ax , x = 'model' , y = 'actual' ) # Plot line with slope = 1 min_value = df . loc [ df [ 'key' ] == key , [ 'model' , 'actual' ]] . min () . min () max_value = df . loc [ df [ 'key' ] == key , [ 'model' , 'actual' ]] . max () . max () line_style = { 'color' : 'k' , 'linestyle' : '--' , 'alpha' : 0.5 } ax . plot ([ min_value , max_value ], [ min_value , max_value ], ** line_style ) # Set title ax . set_title ( key ) ax . set_xlabel ( 'Model (MW)' ) ax . set_ylabel ( 'Actual (MW)' ) plt . show () # Check the @EnergyTarget solution for all traders plot_solution ( solution = trader_solution , key = '@EnergyTarget' ) Each point corresponds to a trader. The horizontal axis corresponds to the target output level obtained from the Dispatch API, while the vertical axis shows targets produced by NEMDE. The dashed line has a slope equal to one, indicating the region over which the Dispatch API's solution equals the NEMDE solution. Points close to the dashed line indicate close correspondence between the Dispatch API's solution and the solution obtained by NEMDE. Plots can be constructed for the remaining trade types: keys = [ '@R6Target' , '@R60Target' , '@R5Target' , '@R5RegTarget' , '@L6Target' , '@L60Target' , '@L5Target' , '@L5RegTarget' ] for i in keys : plot_solution ( solution = trader_solution , key = i )","title":"Evaluating the Dispatch API"},{"location":"tutorials/validating-results/#objective-function-value","text":"The value of the objective function at optimality provides a useful heuristic when comparing the solution obtained from the Dispatch API with the results outputted by NEMDE. Small perturbations to input parameters or constraint formulations can manifest as large differences in the objective function's value. It's unlikely there would be close correspondence between these values if the Dispatch API's formulation was a manifestly innaccurate approximation of NEMDE. Let's examine the objective function values: # objective = period_solution.loc['@TotalObjective'] objective = [ i for i in period_solution if i . get ( 'key' ) == '@TotalObjective' ][ 0 ] objective {'case_id': '20201101001', 'intervention': '0', 'key': '@TotalObjective', 'model': -10540805.66769616, 'actual': -10540790.07213} We can also compute the absolute and relative difference. difference = objective . get ( 'model' ) - objective . get ( 'actual' ) relative_difference = difference / objective . get ( 'actual' ) print ( \"Difference:\" , difference ) print ( \"Relative difference:\" , relative_difference ) Difference: -15.595566159114242 Relative difference: 1.4795443275498999e-06 The relative difference is very small at approximately 0.000148 %. At this level solver settings, such as tolerances, and floating point precision could be coming into play.","title":"Objective function value"},{"location":"tutorials/validating-results/#summary","text":"This notebook examined strategies that can be used to validate model outputs. Reasons for discrepancies between the Dispatch API's solution and results obtained from NEMDE were also discussed, including features of the NEMDE's mathematical formulation that may result in non-unique solutions being returned. Without the ability to examine the mathematical forumulation used by NEMDE definitive model validation is impossible. Instead, we must adopt a data-driven approach when evaluating the Dispatch API's performance. The model validation section extends the analysis presented above by comparing dispatch outcomes over thousands of dispatch intervals. This process of experimentation and followed by diagnostic analysis helps identify areas in which the Dispatch API's model formulation can be improved.","title":"Summary"}]}